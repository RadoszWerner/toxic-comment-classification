{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T23:56:26.695066Z",
     "start_time": "2024-06-19T23:55:43.247199Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Radosz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Radosz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Radosz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'prepare_data' from 'd:\\\\Projects\\\\toxic-comment-classification\\\\prepare_data.py'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Bidirectional, GlobalMaxPool1D, LSTM\n",
    "\n",
    "import prepare_data as prep\n",
    "from prepare_data import DataPreprocessor\n",
    "from importlib import reload\n",
    "\n",
    "reload(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T23:57:01.304114Z",
     "start_time": "2024-06-19T23:56:32.377396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id                                       comment_text  \\\n",
      "0       0000997932d777bf  explanation\\nwhy the edits made under my usern...   \n",
      "1       000103f0d9cfb60f  d'aww! he matches this background colour i'm s...   \n",
      "2       000113f07ec002fd  hey man, i'm really not trying to edit war. it...   \n",
      "3       0001b41b1c6bb37e  \"\\nmore\\ni can't make any real suggestions on ...   \n",
      "4       0001d958c54c6e35  you, sir, are my hero. any chance you remember...   \n",
      "...                  ...                                                ...   \n",
      "159566  ffe987279560d7ff  \":::::and for the second time of asking, when ...   \n",
      "159567  ffea4adeee384e90  you should be ashamed of yourself \\n\\nthat is ...   \n",
      "159568  ffee36eab5c267c9  spitzer \\n\\numm, theres no actual article for ...   \n",
      "159569  fff125370e4aaaf3  and it looks like it was actually you who put ...   \n",
      "159570  fff46fc426af1f9a  \"\\nand ... i really don't think you understand...   \n",
      "\n",
      "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0           0             0        0       0       0              0  \n",
      "1           0             0        0       0       0              0  \n",
      "2           0             0        0       0       0              0  \n",
      "3           0             0        0       0       0              0  \n",
      "4           0             0        0       0       0              0  \n",
      "...       ...           ...      ...     ...     ...            ...  \n",
      "159566      0             0        0       0       0              0  \n",
      "159567      0             0        0       0       0              0  \n",
      "159568      0             0        0       0       0              0  \n",
      "159569      0             0        0       0       0              0  \n",
      "159570      0             0        0       0       0              0  \n",
      "\n",
      "[159571 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "prepData = DataPreprocessor(\"jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "\n",
    "prepData.load_data()\n",
    "prepData.preprocess_data()\n",
    "X, y = prepData.get_XY()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T23:57:10.932793Z",
     "start_time": "2024-06-19T23:57:07.958084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (127656, 150)\n",
      "X_test (31915, 150)\n",
      "y_train (127656, 6)\n",
      "y_test (31915, 6)\n"
     ]
    }
   ],
   "source": [
    "# Zmniana wartości klas w binarne\n",
    "\n",
    "mlb = LabelBinarizer()\n",
    "y_binary = mlb.fit_transform(y)\n",
    "\n",
    "X_notoken = X\n",
    "\n",
    "# Tokenizacja danych tekstowych\n",
    "max_words = 20000\n",
    "max_len = 150\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_seq, maxlen=max_len)\n",
    "\n",
    "# Podział metodą train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"y_test\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (12766, 150)\n",
      "X_test (3192, 150)\n",
      "y_train (12766, 6)\n",
      "y_test (3192, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train[::10]\n",
    "y_train=y_train[::10]\n",
    "X_test=X_test[::10]\n",
    "y_test=y_test[::10]\n",
    "\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T22:03:14.764839Z",
     "start_time": "2024-06-19T22:03:14.676098Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LR preparation\n",
    "\n",
    "# Dodać walidację krzyżową do każdego modelu oraz testy statystyczne\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions = {\n",
    "    'C': uniform(loc=0.01, scale=10),\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "random_search_LR = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(solver='lbfgs', max_iter=1000, verbose=True),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=4,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "def LR_Training_CV(y_label, X_padded, tokenizer, k=5):\n",
    "    # Perform parameter search on the entire dataset\n",
    "    X_text = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_padded]\n",
    "    \n",
    "    tfidf_vec = TfidfVectorizer(max_df=0.7)\n",
    "    X_vec = tfidf_vec.fit_transform(X_text)\n",
    "    \n",
    "    random_search_LR.fit(X_vec, y_label.values.ravel())\n",
    "    best_params = random_search_LR.best_params_\n",
    "    print('Best parameters from RandomizedSearchCV:', best_params)\n",
    "    \n",
    "    # Use the best parameters for cross-validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_y_tests = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_padded):\n",
    "        X_train_LR, X_test_LR = X_padded[train_index], X_padded[test_index]\n",
    "        y_train_LR, y_test_LR = y_label.iloc[train_index], y_label.iloc[test_index]\n",
    "        \n",
    "        X_train_LR = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_train_LR]\n",
    "        X_test_LR = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_test_LR]\n",
    "        \n",
    "        tfidf_vec = TfidfVectorizer(max_df=0.7)\n",
    "        X_train_LR_vec = tfidf_vec.fit_transform(X_train_LR)\n",
    "        X_test_LR_vec = tfidf_vec.transform(X_test_LR)\n",
    "        \n",
    "        model = LogisticRegression(solver='lbfgs', max_iter=1000, verbose=True, **best_params)\n",
    "        model.fit(X_train_LR_vec, y_train_LR.values.ravel())\n",
    "        \n",
    "        predictions = model.predict(X_test_LR_vec)\n",
    "        \n",
    "        all_predictions.extend(predictions)\n",
    "        all_y_tests.extend(y_test_LR.values)\n",
    "    \n",
    "    print(confusion_matrix(all_y_tests, all_predictions))\n",
    "    print(classification_report(all_y_tests, all_predictions))\n",
    "    accuracy = accuracy_score(all_y_tests, all_predictions)\n",
    "    report = classification_report(all_y_tests, all_predictions, output_dict=True)\n",
    "\n",
    "    return accuracy, report['weighted avg']['precision'], report['weighted avg']['recall'], report['weighted avg']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T22:05:57.289839Z",
     "start_time": "2024-06-19T22:03:18.493279Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training with Cross-Validation\n",
      "Toxic comments:\n",
      "Best parameters from RandomizedSearchCV: {'C': 7.3299394181140505, 'penalty': 'l2'}\n",
      "[[142621   1656]\n",
      " [  4909  10385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    144277\n",
      "           1       0.86      0.68      0.76     15294\n",
      "\n",
      "    accuracy                           0.96    159571\n",
      "   macro avg       0.91      0.83      0.87    159571\n",
      "weighted avg       0.96      0.96      0.96    159571\n",
      "\n",
      "Severe toxic comments:\n",
      "Best parameters from RandomizedSearchCV: {'C': 9.51714306409916, 'penalty': 'l2'}\n",
      "[[157524    452]\n",
      " [  1114    481]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    157976\n",
      "           1       0.52      0.30      0.38      1595\n",
      "\n",
      "    accuracy                           0.99    159571\n",
      "   macro avg       0.75      0.65      0.69    159571\n",
      "weighted avg       0.99      0.99      0.99    159571\n",
      "\n",
      "Obscene comments:\n",
      "Best parameters from RandomizedSearchCV: {'C': 9.51714306409916, 'penalty': 'l2'}\n",
      "[[150240    882]\n",
      " [  2567   5882]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    151122\n",
      "           1       0.87      0.70      0.77      8449\n",
      "\n",
      "    accuracy                           0.98    159571\n",
      "   macro avg       0.93      0.85      0.88    159571\n",
      "weighted avg       0.98      0.98      0.98    159571\n",
      "\n",
      "Threat comments:\n",
      "Best parameters from RandomizedSearchCV: {'C': 9.51714306409916, 'penalty': 'l2'}\n",
      "[[159027     66]\n",
      " [   382     96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    159093\n",
      "           1       0.59      0.20      0.30       478\n",
      "\n",
      "    accuracy                           1.00    159571\n",
      "   macro avg       0.80      0.60      0.65    159571\n",
      "weighted avg       1.00      1.00      1.00    159571\n",
      "\n",
      "Insult comments:\n",
      "Best parameters from RandomizedSearchCV: {'C': 7.3299394181140505, 'penalty': 'l2'}\n",
      "[[150438   1256]\n",
      " [  3356   4521]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    151694\n",
      "           1       0.78      0.57      0.66      7877\n",
      "\n",
      "    accuracy                           0.97    159571\n",
      "   macro avg       0.88      0.78      0.82    159571\n",
      "weighted avg       0.97      0.97      0.97    159571\n",
      "\n",
      "Identity hate comments:\n",
      "Best parameters from RandomizedSearchCV: {'C': 7.3299394181140505, 'penalty': 'l2'}\n",
      "[[157941    225]\n",
      " [  1016    389]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    158166\n",
      "           1       0.63      0.28      0.39      1405\n",
      "\n",
      "    accuracy                           0.99    159571\n",
      "   macro avg       0.81      0.64      0.69    159571\n",
      "weighted avg       0.99      0.99      0.99    159571\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9922228976443088, 0.99043807611676, 0.9922228976443088, 0.9907091476355341)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "\n",
    "print(\"Logistic Regression Training with Cross-Validation\")\n",
    "print(\"Toxic comments:\")\n",
    "LR_Training_CV(y[[\"toxic\"]], X_padded, tokenizer)\n",
    "print(\"Severe toxic comments:\")\n",
    "LR_Training_CV(y[[\"severe_toxic\"]], X_padded, tokenizer)\n",
    "print(\"Obscene comments:\")\n",
    "LR_Training_CV(y[[\"obscene\"]], X_padded, tokenizer)\n",
    "print(\"Threat comments:\")\n",
    "LR_Training_CV(y[[\"threat\"]], X_padded, tokenizer)\n",
    "print(\"Insult comments:\")\n",
    "LR_Training_CV(y[[\"insult\"]], X_padded, tokenizer)\n",
    "print(\"Identity hate comments:\")\n",
    "LR_Training_CV(y[[\"identity_hate\"]], X_padded, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T22:07:57.527035Z",
     "start_time": "2024-06-19T22:07:57.493046Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NB Preparation\n",
    "\n",
    "param_distributions = {\n",
    "    'alpha': uniform(loc=0, scale=1),\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "random_search_NB = RandomizedSearchCV(\n",
    "    estimator=MultinomialNB(),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=4,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "\n",
    "def NB_Training_CV(y_label, X_padded, tokenizer, k=5):\n",
    "    # Perform parameter search on the entire dataset\n",
    "    X_text = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_padded]\n",
    "\n",
    "    tfidf_vec = TfidfVectorizer(max_df=0.7)\n",
    "    X_vec = tfidf_vec.fit_transform(X_text)\n",
    "\n",
    "    random_search_NB.fit(X_vec, y_label.values.ravel())\n",
    "    best_params = random_search_NB.best_params_\n",
    "    print('Best parameters from RandomizedSearchCV:', best_params)\n",
    "\n",
    "    # Use the best parameters for cross-validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    all_predictions = []\n",
    "    all_y_tests = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_padded):\n",
    "        X_train_NB, X_test_NB = X_padded[train_index], X_padded[test_index]\n",
    "        y_train_NB, y_test_NB = y_label.iloc[train_index], y_label.iloc[test_index]\n",
    "\n",
    "        X_train_NB = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_train_NB]\n",
    "        X_test_NB = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_test_NB]\n",
    "\n",
    "        tfidf_vec = TfidfVectorizer(max_df=0.7)\n",
    "        X_train_NB_vec = tfidf_vec.fit_transform(X_train_NB)\n",
    "        X_test_NB_vec = tfidf_vec.transform(X_test_NB)\n",
    "\n",
    "        model = MultinomialNB(**best_params)\n",
    "        model.fit(X_train_NB_vec, y_train_NB.values.ravel())\n",
    "\n",
    "        predictions = model.predict(X_test_NB_vec)\n",
    "\n",
    "        all_predictions.extend(predictions)\n",
    "        all_y_tests.extend(y_test_NB.values)\n",
    "\n",
    "    print(confusion_matrix(all_y_tests, all_predictions))\n",
    "    print(classification_report(all_y_tests, all_predictions))\n",
    "\n",
    "     # Calculate and return metrics\n",
    "    report = classification_report(all_y_tests, all_predictions, output_dict=True)\n",
    "    accuracy = accuracy_score(all_y_tests, all_predictions)\n",
    "    print('Accuracy:', accuracy)\n",
    "    return accuracy, report['weighted avg']['precision'], report['weighted avg']['recall'], report['weighted avg']['f1-score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic comments NB:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.3745401188473625, 'fit_prior': True}\n",
      "[[143447    830]\n",
      " [  7270   8024]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    144277\n",
      "           1       0.91      0.52      0.66     15294\n",
      "\n",
      "    accuracy                           0.95    159571\n",
      "   macro avg       0.93      0.76      0.82    159571\n",
      "weighted avg       0.95      0.95      0.94    159571\n",
      "\n",
      "Accuracy: 0.9492388967920237\n",
      "toxic comments LR:\n",
      "Best parameters from RandomizedSearchCV: {'C': 7.3299394181140505, 'penalty': 'l2'}\n",
      "[[142621   1656]\n",
      " [  4909  10385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    144277\n",
      "           1       0.86      0.68      0.76     15294\n",
      "\n",
      "    accuracy                           0.96    159571\n",
      "   macro avg       0.91      0.83      0.87    159571\n",
      "weighted avg       0.96      0.96      0.96    159571\n",
      "\n",
      "severe_toxic comments NB:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.1834347898661638, 'fit_prior': False}\n",
      "[[146137  11839]\n",
      " [   122   1473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    157976\n",
      "           1       0.11      0.92      0.20      1595\n",
      "\n",
      "    accuracy                           0.93    159571\n",
      "   macro avg       0.55      0.92      0.58    159571\n",
      "weighted avg       0.99      0.93      0.95    159571\n",
      "\n",
      "Accuracy: 0.9250427709295549\n",
      "severe_toxic comments LR:\n",
      "Best parameters from RandomizedSearchCV: {'C': 9.51714306409916, 'penalty': 'l2'}\n",
      "[[157524    452]\n",
      " [  1114    481]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    157976\n",
      "           1       0.52      0.30      0.38      1595\n",
      "\n",
      "    accuracy                           0.99    159571\n",
      "   macro avg       0.75      0.65      0.69    159571\n",
      "weighted avg       0.99      0.99      0.99    159571\n",
      "\n",
      "obscene comments NB:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.3745401188473625, 'fit_prior': True}\n",
      "[[150524    598]\n",
      " [  3999   4450]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98    151122\n",
      "           1       0.88      0.53      0.66      8449\n",
      "\n",
      "    accuracy                           0.97    159571\n",
      "   macro avg       0.93      0.76      0.82    159571\n",
      "weighted avg       0.97      0.97      0.97    159571\n",
      "\n",
      "Accuracy: 0.9711915072287571\n",
      "obscene comments LR:\n",
      "Best parameters from RandomizedSearchCV: {'C': 9.51714306409916, 'penalty': 'l2'}\n",
      "[[150240    882]\n",
      " [  2567   5882]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    151122\n",
      "           1       0.87      0.70      0.77      8449\n",
      "\n",
      "    accuracy                           0.98    159571\n",
      "   macro avg       0.93      0.85      0.88    159571\n",
      "weighted avg       0.98      0.98      0.98    159571\n",
      "\n",
      "threat comments NB:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.1834347898661638, 'fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    'Regresja_Liniowa': {'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0},\n",
    "    'Naive_Bayes': {'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0},\n",
    "    'CNN': {'accuracy': 0.90, 'precision': 0.87, 'recall': 0.85, 'f1_score': 0.86},\n",
    "    'LSTM': {'accuracy': 0.89, 'precision': 0.85, 'recall': 0.84, 'f1_score': 0.84}\n",
    "}\n",
    "categories = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "for category in categories:\n",
    "    print(f\"{category} comments NB:\")\n",
    "    accuracy, precision, recall, f1_score = NB_Training_CV(y[[category]], X_padded, tokenizer)\n",
    "    results['Naive_Bayes']['accuracy'] += accuracy\n",
    "    results['Naive_Bayes']['precision'] += precision\n",
    "    results['Naive_Bayes']['recall'] += recall\n",
    "    results['Naive_Bayes']['f1_score'] += f1_score\n",
    "\n",
    "    print(f\"{category} comments LR:\")\n",
    "    accuracy, precision, recall, f1_score = LR_Training_CV(y[[category]], X_padded, tokenizer)\n",
    "    results['Regresja_Liniowa']['accuracy'] += accuracy\n",
    "    results['Regresja_Liniowa']['precision'] += precision\n",
    "    results['Regresja_Liniowa']['recall'] += recall\n",
    "    results['Regresja_Liniowa']['f1_score'] += f1_score\n",
    "\n",
    "# Średnie wyniki dla wszystkich kategorii\n",
    "results['Naive_Bayes']['accuracy'] /= len(categories)\n",
    "results['Naive_Bayes']['precision'] /= len(categories)\n",
    "results['Naive_Bayes']['recall'] /= len(categories)\n",
    "results['Naive_Bayes']['f1_score'] /= len(categories)\n",
    "results['Regresja_Liniowa']['accuracy'] /= len(categories)\n",
    "results['Regresja_Liniowa']['precision'] /= len(categories)\n",
    "results['Regresja_Liniowa']['recall'] /= len(categories)\n",
    "results['Regresja_Liniowa']['f1_score'] /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results for Naive Bayes:\")\n",
    "print(results['Naive_Bayes'])\n",
    "print(\"Results for Logistic Regression:\")\n",
    "print(results['Regresja_Liniowa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T22:09:02.055136Z",
     "start_time": "2024-06-19T22:08:01.176099Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Training with Cross-Validation\n",
      "Toxic comments:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.3745401188473625, 'fit_prior': True}\n",
      "[[143447    830]\n",
      " [  7270   8024]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    144277\n",
      "           1       0.91      0.52      0.66     15294\n",
      "\n",
      "    accuracy                           0.95    159571\n",
      "   macro avg       0.93      0.76      0.82    159571\n",
      "weighted avg       0.95      0.95      0.94    159571\n",
      "\n",
      "Severe toxic comments:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.1834347898661638, 'fit_prior': False}\n",
      "[[146137  11839]\n",
      " [   122   1473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    157976\n",
      "           1       0.11      0.92      0.20      1595\n",
      "\n",
      "    accuracy                           0.93    159571\n",
      "   macro avg       0.55      0.92      0.58    159571\n",
      "weighted avg       0.99      0.93      0.95    159571\n",
      "\n",
      "Obscene comments:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.3745401188473625, 'fit_prior': True}\n",
      "[[150524    598]\n",
      " [  3999   4450]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98    151122\n",
      "           1       0.88      0.53      0.66      8449\n",
      "\n",
      "    accuracy                           0.97    159571\n",
      "   macro avg       0.93      0.76      0.82    159571\n",
      "weighted avg       0.97      0.97      0.97    159571\n",
      "\n",
      "Threat comments:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.1834347898661638, 'fit_prior': False}\n",
      "[[148506  10587]\n",
      " [   111    367]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97    159093\n",
      "           1       0.03      0.77      0.06       478\n",
      "\n",
      "    accuracy                           0.93    159571\n",
      "   macro avg       0.52      0.85      0.51    159571\n",
      "weighted avg       1.00      0.93      0.96    159571\n",
      "\n",
      "Insult comments:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.3745401188473625, 'fit_prior': True}\n",
      "[[150866    828]\n",
      " [  4359   3518]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    151694\n",
      "           1       0.81      0.45      0.58      7877\n",
      "\n",
      "    accuracy                           0.97    159571\n",
      "   macro avg       0.89      0.72      0.78    159571\n",
      "weighted avg       0.96      0.97      0.96    159571\n",
      "\n",
      "Identity hate comments:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.1834347898661638, 'fit_prior': False}\n",
      "[[143381  14785]\n",
      " [   188   1217]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95    158166\n",
      "           1       0.08      0.87      0.14      1405\n",
      "\n",
      "    accuracy                           0.91    159571\n",
      "   macro avg       0.54      0.89      0.55    159571\n",
      "weighted avg       0.99      0.91      0.94    159571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "print(\"Naive Bayes Training with Cross-Validation\")\n",
    "print(\"Toxic comments:\")\n",
    "NB_Training_CV(y[[\"toxic\"]], X_padded, tokenizer)\n",
    "print(\"Severe toxic comments:\")\n",
    "NB_Training_CV(y[[\"severe_toxic\"]], X_padded, tokenizer)\n",
    "print(\"Obscene comments:\")\n",
    "NB_Training_CV(y[[\"obscene\"]], X_padded, tokenizer)\n",
    "print(\"Threat comments:\")\n",
    "NB_Training_CV(y[[\"threat\"]], X_padded, tokenizer)\n",
    "print(\"Insult comments:\")\n",
    "NB_Training_CV(y[[\"insult\"]], X_padded, tokenizer)\n",
    "print(\"Identity hate comments:\")\n",
    "NB_Training_CV(y[[\"identity_hate\"]], X_padded, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T21:06:03.838974Z",
     "start_time": "2024-06-19T21:06:03.817972Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_pred = tf.round(tf.clip_by_value(y_pred, 0, 1))\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred)\n",
    "    false_positives = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "    false_negatives = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives + tf.keras.backend.epsilon())\n",
    "    recall = true_positives / (true_positives + false_negatives + tf.keras.backend.epsilon())\n",
    "    \n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:13:01.622785Z",
     "start_time": "2024-06-20T00:06:19.165310Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     2     4 ... 12758 12763 12765]            \n",
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:16\u001b[0m 2s/step - accuracy: 0.7188 - loss: 0.6837\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 77ms/step - accuracy: 0.6953 - loss: 0.6718\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 77ms/step - accuracy: 0.6753 - loss: 0.6595\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - accuracy: 0.6598 - loss: 0.6457\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.6472 - loss: 0.6283\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.6409 - loss: 0.6084\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.6387 - loss: 0.5866 \n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.6384 - loss: 0.5687\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.6385 - loss: 0.5515\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.6396 - loss: 0.5360\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.6423 - loss: 0.5211\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.6453 - loss: 0.5073\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.6485 - loss: 0.4941\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.6518 - loss: 0.4814\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.6544 - loss: 0.4700\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.6564 - loss: 0.4595\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.6583 - loss: 0.4497\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.6601 - loss: 0.4405\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6610 - loss: 0.4319\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6615 - loss: 0.4238\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6612 - loss: 0.4161\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6604 - loss: 0.4089\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6589 - loss: 0.4020\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6569 - loss: 0.3956\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6547 - loss: 0.3896\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6524 - loss: 0.3837\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6503 - loss: 0.3782\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6481 - loss: 0.3729\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6460 - loss: 0.3680\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6442 - loss: 0.3632\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6425 - loss: 0.3586\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6413 - loss: 0.3542\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6403 - loss: 0.3501\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6396 - loss: 0.3461\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6391 - loss: 0.3422\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6388 - loss: 0.3385\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6387 - loss: 0.3350\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6387 - loss: 0.3316\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6389 - loss: 0.3283\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6392 - loss: 0.3252\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6395 - loss: 0.3223\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6399 - loss: 0.3194\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6403 - loss: 0.3168\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6408 - loss: 0.3143\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6412 - loss: 0.3119\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6416 - loss: 0.3096\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6420 - loss: 0.3074\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6424 - loss: 0.3053\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6428 - loss: 0.3033\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6431 - loss: 0.3014\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6435 - loss: 0.2995\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6439 - loss: 0.2977\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6443 - loss: 0.2959\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6446 - loss: 0.2941\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6450 - loss: 0.2923\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6453 - loss: 0.2906\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6457 - loss: 0.2889\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6461 - loss: 0.2872\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6465 - loss: 0.2856\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6470 - loss: 0.2840\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6475 - loss: 0.2825\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6480 - loss: 0.2810\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6486 - loss: 0.2795\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6492 - loss: 0.2781\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6499 - loss: 0.2767\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6506 - loss: 0.2753\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6513 - loss: 0.2739\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6521 - loss: 0.2726\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6529 - loss: 0.2713\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6537 - loss: 0.2701\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6545 - loss: 0.2688\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6553 - loss: 0.2676\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6561 - loss: 0.2664\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6569 - loss: 0.2653\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6577 - loss: 0.2641\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6584 - loss: 0.2630\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6591 - loss: 0.2619\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6598 - loss: 0.2609\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6605 - loss: 0.2598\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6611 - loss: 0.2588\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6617 - loss: 0.2577\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6623 - loss: 0.2567\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6628 - loss: 0.2558\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6633 - loss: 0.2548\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6638 - loss: 0.2539\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6642 - loss: 0.2529\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6647 - loss: 0.2520\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6651 - loss: 0.2511\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6656 - loss: 0.2502\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6661 - loss: 0.2494\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6665 - loss: 0.2485\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6670 - loss: 0.2477\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6675 - loss: 0.2469\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6680 - loss: 0.2461\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6684 - loss: 0.2453\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6689 - loss: 0.2445\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6694 - loss: 0.2437\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6699 - loss: 0.2430\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6704 - loss: 0.2422\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6709 - loss: 0.2415\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6714 - loss: 0.2408\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6719 - loss: 0.2401\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6724 - loss: 0.2394\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6728 - loss: 0.2387\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6733 - loss: 0.2380\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6737 - loss: 0.2373\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6742 - loss: 0.2366\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6747 - loss: 0.2360\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6751 - loss: 0.2353\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6756 - loss: 0.2347\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6761 - loss: 0.2341\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6765 - loss: 0.2335\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6770 - loss: 0.2328\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6774 - loss: 0.2322\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6779 - loss: 0.2316\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6783 - loss: 0.2310\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6787 - loss: 0.2304\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6791 - loss: 0.2298\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6794 - loss: 0.2293\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6798 - loss: 0.2287\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6801 - loss: 0.2281\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6805 - loss: 0.2276\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6808 - loss: 0.2270\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6811 - loss: 0.2264\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6815 - loss: 0.2259\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6818 - loss: 0.2253\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6822 - loss: 0.2248\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6825 - loss: 0.2243\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6829 - loss: 0.2237\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6833 - loss: 0.2232\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6836 - loss: 0.2227\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6840 - loss: 0.2222\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6844 - loss: 0.2217\n",
      "                                                     \n",
      "Epoch 1: val_loss improved from inf to 0.09657, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 92ms/step - accuracy: 0.6848 - loss: 0.2212 - val_accuracy: 0.9948 - val_loss: 0.0966\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 107ms/step - accuracy: 0.8594 - loss: 0.1210\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 127ms/step - accuracy: 0.8398 - loss: 0.1091\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 115ms/step - accuracy: 0.8203 - loss: 0.0999\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 105ms/step - accuracy: 0.7979 - loss: 0.0981\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.7752 - loss: 0.0957\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.7558 - loss: 0.0944 \n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - accuracy: 0.7390 - loss: 0.0924\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.7240 - loss: 0.0908\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.7103 - loss: 0.0897\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.6991 - loss: 0.0898\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.6901 - loss: 0.0900\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.6830 - loss: 0.0907\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.6773 - loss: 0.0910\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.6734 - loss: 0.0914\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.6711 - loss: 0.0916\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.6700 - loss: 0.0919\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.6696 - loss: 0.0922\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.6696 - loss: 0.0924\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.6700 - loss: 0.0926\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.6708 - loss: 0.0927\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.6715 - loss: 0.0928\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.6720 - loss: 0.0928\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.6725 - loss: 0.0927\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6730 - loss: 0.0926 \n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6735 - loss: 0.0924\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6740 - loss: 0.0922\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6746 - loss: 0.0921\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6753 - loss: 0.0920\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6761 - loss: 0.0920\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6769 - loss: 0.0919\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6780 - loss: 0.0918\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6791 - loss: 0.0917\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.6803 - loss: 0.0915\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.6817 - loss: 0.0914\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.6832 - loss: 0.0912\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.6847 - loss: 0.0910\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.6863 - loss: 0.0908\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.6880 - loss: 0.0906\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.6896 - loss: 0.0904\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.6913 - loss: 0.0901\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.6930 - loss: 0.0899\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6947 - loss: 0.0897\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6963 - loss: 0.0894\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6979 - loss: 0.0892\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6995 - loss: 0.0890\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7010 - loss: 0.0888\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7025 - loss: 0.0885\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7041 - loss: 0.0883\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7056 - loss: 0.0881\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7071 - loss: 0.0879\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.7086 - loss: 0.0876\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7101 - loss: 0.0874\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7116 - loss: 0.0872\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7131 - loss: 0.0870\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7144 - loss: 0.0868\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7157 - loss: 0.0865\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7170 - loss: 0.0863\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7182 - loss: 0.0861\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7193 - loss: 0.0859\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.7204 - loss: 0.0857\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.7215 - loss: 0.0855\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.7226 - loss: 0.0852\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.7237 - loss: 0.0850\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.7247 - loss: 0.0848\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.7258 - loss: 0.0846\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.7268 - loss: 0.0844\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7279 - loss: 0.0842\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7289 - loss: 0.0840\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7300 - loss: 0.0838\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7311 - loss: 0.0837\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7321 - loss: 0.0835\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7332 - loss: 0.0833\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7342 - loss: 0.0831\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.7353 - loss: 0.0829\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.7363 - loss: 0.0828\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.7374 - loss: 0.0826\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.7384 - loss: 0.0824\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7395 - loss: 0.0823\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7405 - loss: 0.0821\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7416 - loss: 0.0820\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7426 - loss: 0.0818\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7437 - loss: 0.0817\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7447 - loss: 0.0816\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7458 - loss: 0.0814\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7468 - loss: 0.0813\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7478 - loss: 0.0812\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7489 - loss: 0.0810\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7499 - loss: 0.0809\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7509 - loss: 0.0808\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7519 - loss: 0.0806\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7529 - loss: 0.0805\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7539 - loss: 0.0804\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7549 - loss: 0.0803\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7559 - loss: 0.0802\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7569 - loss: 0.0801\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7578 - loss: 0.0800\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7588 - loss: 0.0799\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7597 - loss: 0.0798\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7606 - loss: 0.0797\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7615 - loss: 0.0796\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7624 - loss: 0.0795\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7633 - loss: 0.0794\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7641 - loss: 0.0793\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7649 - loss: 0.0792\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7657 - loss: 0.0791\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7665 - loss: 0.0790\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7673 - loss: 0.0789\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7681 - loss: 0.0788\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7688 - loss: 0.0787\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7696 - loss: 0.0786\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7703 - loss: 0.0785\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7711 - loss: 0.0785\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7718 - loss: 0.0784\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7725 - loss: 0.0783\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7733 - loss: 0.0782\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7740 - loss: 0.0781\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7747 - loss: 0.0780\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7754 - loss: 0.0779\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7762 - loss: 0.0778\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7769 - loss: 0.0777\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7776 - loss: 0.0777\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7783 - loss: 0.0776\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7790 - loss: 0.0775\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7797 - loss: 0.0774\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7804 - loss: 0.0773\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7811 - loss: 0.0773\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7818 - loss: 0.0772\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7825 - loss: 0.0771\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7832 - loss: 0.0770\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7839 - loss: 0.0770\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7846 - loss: 0.0769\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7852 - loss: 0.0768\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7859 - loss: 0.0768\n",
      "                                                     \n",
      "Epoch 2: val_loss improved from 0.09657 to 0.05931, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.7866 - loss: 0.0767 - val_accuracy: 0.9948 - val_loss: 0.0593\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - accuracy: 0.9062 - loss: 0.0423\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9180 - loss: 0.0409 \n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.9175 - loss: 0.0413\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.9186 - loss: 0.0442\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.9136 - loss: 0.0449\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9029 - loss: 0.0447 \n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.8935 - loss: 0.0449\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.8853 - loss: 0.0451\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.8770 - loss: 0.0452\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.8698 - loss: 0.0455\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.8641 - loss: 0.0456\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.8590 - loss: 0.0456\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.8553 - loss: 0.0457\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.8524 - loss: 0.0457\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.8503 - loss: 0.0457\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.8489 - loss: 0.0458\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.8479 - loss: 0.0459\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.8473 - loss: 0.0460\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.8470 - loss: 0.0460\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.8471 - loss: 0.0461\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.8474 - loss: 0.0460\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.8478 - loss: 0.0460\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8482 - loss: 0.0459\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8487 - loss: 0.0458\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8492 - loss: 0.0457\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8497 - loss: 0.0456\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.8501 - loss: 0.0455\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.8506 - loss: 0.0454\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.8512 - loss: 0.0453\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.8518 - loss: 0.0453\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.8524 - loss: 0.0453\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.8531 - loss: 0.0452\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8538 - loss: 0.0451\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8545 - loss: 0.0451\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8552 - loss: 0.0450\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8559 - loss: 0.0449\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8566 - loss: 0.0448\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8573 - loss: 0.0448\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8580 - loss: 0.0448\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8586 - loss: 0.0447\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8593 - loss: 0.0447\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8599 - loss: 0.0447\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8606 - loss: 0.0447\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8612 - loss: 0.0447\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8617 - loss: 0.0447\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8623 - loss: 0.0447\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8629 - loss: 0.0446\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8635 - loss: 0.0446\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8641 - loss: 0.0446\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8647 - loss: 0.0446\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8653 - loss: 0.0447\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8659 - loss: 0.0447\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8665 - loss: 0.0447\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8671 - loss: 0.0447\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8676 - loss: 0.0447\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8681 - loss: 0.0447\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8687 - loss: 0.0447\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8691 - loss: 0.0447\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8696 - loss: 0.0447\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8700 - loss: 0.0446\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8704 - loss: 0.0446\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.8708 - loss: 0.0446\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.8712 - loss: 0.0446\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.8715 - loss: 0.0446\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8719 - loss: 0.0446\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8723 - loss: 0.0446\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8726 - loss: 0.0446\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8730 - loss: 0.0446\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8734 - loss: 0.0446\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8737 - loss: 0.0446\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8741 - loss: 0.0445\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8745 - loss: 0.0445\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8748 - loss: 0.0445\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8752 - loss: 0.0445\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8755 - loss: 0.0445\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8759 - loss: 0.0445\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8762 - loss: 0.0445\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8766 - loss: 0.0445\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8769 - loss: 0.0445\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8772 - loss: 0.0445\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8775 - loss: 0.0445\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8778 - loss: 0.0445\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8780 - loss: 0.0445\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8782 - loss: 0.0444\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8784 - loss: 0.0444\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8785 - loss: 0.0444\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8786 - loss: 0.0444\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8787 - loss: 0.0444\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8787 - loss: 0.0444\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8788 - loss: 0.0444\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8788 - loss: 0.0444\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8789 - loss: 0.0443\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8790 - loss: 0.0443\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8790 - loss: 0.0443\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8791 - loss: 0.0443\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8792 - loss: 0.0443\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8793 - loss: 0.0443\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8794 - loss: 0.0443\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8795 - loss: 0.0442\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8796 - loss: 0.0442\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8798 - loss: 0.0442\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8799 - loss: 0.0442\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8800 - loss: 0.0442\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8802 - loss: 0.0442\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8804 - loss: 0.0441\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8805 - loss: 0.0441\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8807 - loss: 0.0441\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8809 - loss: 0.0441\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8810 - loss: 0.0441\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8812 - loss: 0.0441\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8814 - loss: 0.0441\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8816 - loss: 0.0441\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8818 - loss: 0.0440\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8820 - loss: 0.0440\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8822 - loss: 0.0440\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8823 - loss: 0.0440\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8825 - loss: 0.0440\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8827 - loss: 0.0440\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8829 - loss: 0.0440\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8831 - loss: 0.0440\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8833 - loss: 0.0440\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8835 - loss: 0.0440\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8837 - loss: 0.0440\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8839 - loss: 0.0439\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8841 - loss: 0.0439\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8843 - loss: 0.0439\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8844 - loss: 0.0439\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8846 - loss: 0.0439\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8848 - loss: 0.0439\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8850 - loss: 0.0439\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8852 - loss: 0.0439\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8854 - loss: 0.0438\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8855 - loss: 0.0438\n",
      "                                                     \n",
      "Epoch 3: val_loss did not improve from 0.05931\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 88ms/step - accuracy: 0.8857 - loss: 0.0438 - val_accuracy: 0.9948 - val_loss: 0.0671\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 142ms/step\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "[    0     1     2 ... 12762 12763 12764]            \n",
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0450\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0415\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.9983 - loss: 0.0421\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9977 - loss: 0.0423\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9969 - loss: 0.0424\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.9961 - loss: 0.0423\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.9951 - loss: 0.0426\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9942 - loss: 0.0428\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9930 - loss: 0.0428\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9904 - loss: 0.0426\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.9878 - loss: 0.0428\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.9842 - loss: 0.0428\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9804 - loss: 0.0428 \n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9763 - loss: 0.0429\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9719 - loss: 0.0431\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.9677 - loss: 0.0433\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9634 - loss: 0.0434\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.9593 - loss: 0.0435\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9552 - loss: 0.0436\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9512 - loss: 0.0437\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.9474 - loss: 0.0437\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.9438 - loss: 0.0437\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.9403 - loss: 0.0437\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.9368 - loss: 0.0437\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9333 - loss: 0.0438\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9302 - loss: 0.0439\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9272 - loss: 0.0439\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9244 - loss: 0.0440\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9219 - loss: 0.0441\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9196 - loss: 0.0442\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9175 - loss: 0.0443\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9158 - loss: 0.0444\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9142 - loss: 0.0445\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9128 - loss: 0.0446\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9116 - loss: 0.0448\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9105 - loss: 0.0449\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9096 - loss: 0.0450\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9087 - loss: 0.0451\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9080 - loss: 0.0452\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9074 - loss: 0.0453\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9068 - loss: 0.0453\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9063 - loss: 0.0454\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9059 - loss: 0.0455\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9055 - loss: 0.0456\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9052 - loss: 0.0457\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9049 - loss: 0.0457\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9045 - loss: 0.0458\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9042 - loss: 0.0458\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9039 - loss: 0.0459\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9036 - loss: 0.0460\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9033 - loss: 0.0460\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9029 - loss: 0.0461\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9025 - loss: 0.0461\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9020 - loss: 0.0462\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9015 - loss: 0.0463\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9009 - loss: 0.0463\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9003 - loss: 0.0464\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.8996 - loss: 0.0464\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.8989 - loss: 0.0465\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.8982 - loss: 0.0466\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8974 - loss: 0.0466\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8967 - loss: 0.0467\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8960 - loss: 0.0467\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8954 - loss: 0.0468\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8947 - loss: 0.0468\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8941 - loss: 0.0469\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8935 - loss: 0.0469\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8929 - loss: 0.0470\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8924 - loss: 0.0470\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8918 - loss: 0.0471\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8913 - loss: 0.0471\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8909 - loss: 0.0471\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8904 - loss: 0.0472\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.8900 - loss: 0.0472\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8896 - loss: 0.0472\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8892 - loss: 0.0473\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8889 - loss: 0.0473\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8886 - loss: 0.0473\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8883 - loss: 0.0473\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8880 - loss: 0.0473\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8878 - loss: 0.0473\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8875 - loss: 0.0474\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8873 - loss: 0.0474\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8870 - loss: 0.0474\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8868 - loss: 0.0474\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8865 - loss: 0.0474\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8862 - loss: 0.0474\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8860 - loss: 0.0475\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8857 - loss: 0.0475\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8853 - loss: 0.0475\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8850 - loss: 0.0475\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8846 - loss: 0.0475\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8842 - loss: 0.0475\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8839 - loss: 0.0475\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8835 - loss: 0.0475\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8831 - loss: 0.0475\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8827 - loss: 0.0475\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8823 - loss: 0.0475\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8818 - loss: 0.0475\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8814 - loss: 0.0475\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8810 - loss: 0.0475\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8806 - loss: 0.0475\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8802 - loss: 0.0475\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8799 - loss: 0.0475\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8795 - loss: 0.0475\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8792 - loss: 0.0475\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8789 - loss: 0.0475\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8785 - loss: 0.0475\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8782 - loss: 0.0475\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8780 - loss: 0.0476\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8777 - loss: 0.0476\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8774 - loss: 0.0476\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8772 - loss: 0.0476\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8769 - loss: 0.0476\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8767 - loss: 0.0476\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8765 - loss: 0.0477\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8763 - loss: 0.0477\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8761 - loss: 0.0477\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8758 - loss: 0.0477\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8756 - loss: 0.0477\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8754 - loss: 0.0477\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8751 - loss: 0.0477\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8748 - loss: 0.0478\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8745 - loss: 0.0478\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8742 - loss: 0.0478\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8739 - loss: 0.0478\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8736 - loss: 0.0478\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8732 - loss: 0.0478\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8729 - loss: 0.0478\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8726 - loss: 0.0478\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8722 - loss: 0.0478\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8719 - loss: 0.0478\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8716 - loss: 0.0478\n",
      "                                                     \n",
      "Epoch 1: val_loss improved from inf to 0.04053, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.8713 - loss: 0.0478 - val_accuracy: 0.9944 - val_loss: 0.0405\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 96ms/step - accuracy: 0.8906 - loss: 0.0137\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.8984 - loss: 0.0224\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.9097 - loss: 0.0258\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9186 - loss: 0.0262\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.9243 - loss: 0.0268\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9282 - loss: 0.0271\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9315 - loss: 0.0276\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9339 - loss: 0.0285\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9364 - loss: 0.0291\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9387 - loss: 0.0296\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9408 - loss: 0.0299\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9428 - loss: 0.0301\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9446 - loss: 0.0302\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9463 - loss: 0.0302 \n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9478 - loss: 0.0301\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9490 - loss: 0.0300\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9502 - loss: 0.0299\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9512 - loss: 0.0298\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9522 - loss: 0.0298\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9530 - loss: 0.0297\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9538 - loss: 0.0296\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9545 - loss: 0.0295\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9551 - loss: 0.0295\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9557 - loss: 0.0295\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9562 - loss: 0.0294\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9567 - loss: 0.0294\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9571 - loss: 0.0293\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.9576 - loss: 0.0293\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.9580 - loss: 0.0293\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9584 - loss: 0.0293\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9588 - loss: 0.0293\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9592 - loss: 0.0293\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9596 - loss: 0.0293\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.9599 - loss: 0.0293\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9603 - loss: 0.0293\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9606 - loss: 0.0294\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9609 - loss: 0.0294\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9612 - loss: 0.0294\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9615 - loss: 0.0295\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9619 - loss: 0.0295\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9622 - loss: 0.0295\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9624 - loss: 0.0295\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9627 - loss: 0.0296\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9629 - loss: 0.0296\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9630 - loss: 0.0296\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9631 - loss: 0.0296\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9632 - loss: 0.0296\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9632 - loss: 0.0297\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9632 - loss: 0.0297\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9631 - loss: 0.0297\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9631 - loss: 0.0297\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9630 - loss: 0.0297\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9629 - loss: 0.0297\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9627 - loss: 0.0297\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9625 - loss: 0.0297\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9622 - loss: 0.0296\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9619 - loss: 0.0296\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9616 - loss: 0.0296\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9612 - loss: 0.0296\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9608 - loss: 0.0296\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9604 - loss: 0.0296\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9600 - loss: 0.0296\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9595 - loss: 0.0296\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9590 - loss: 0.0296\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9585 - loss: 0.0296\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9580 - loss: 0.0296\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9573 - loss: 0.0296\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9567 - loss: 0.0296\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9560 - loss: 0.0296\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9552 - loss: 0.0296\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9544 - loss: 0.0296\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9536 - loss: 0.0296\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9528 - loss: 0.0296\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9519 - loss: 0.0296\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9510 - loss: 0.0296\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9501 - loss: 0.0296\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9492 - loss: 0.0296\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9482 - loss: 0.0296\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9473 - loss: 0.0296\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9464 - loss: 0.0297\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9455 - loss: 0.0297\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9446 - loss: 0.0297\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9438 - loss: 0.0297\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9430 - loss: 0.0297\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9422 - loss: 0.0297\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9414 - loss: 0.0297\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9407 - loss: 0.0297\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9399 - loss: 0.0297\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9393 - loss: 0.0297\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9386 - loss: 0.0297\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9379 - loss: 0.0297\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9373 - loss: 0.0297\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9367 - loss: 0.0297\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9361 - loss: 0.0297\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9355 - loss: 0.0297\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9349 - loss: 0.0298\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9344 - loss: 0.0298\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9339 - loss: 0.0298\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9334 - loss: 0.0298\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9329 - loss: 0.0298\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9324 - loss: 0.0298\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9319 - loss: 0.0298\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9314 - loss: 0.0298\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9309 - loss: 0.0298\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9304 - loss: 0.0298\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9299 - loss: 0.0298\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9294 - loss: 0.0298\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9289 - loss: 0.0298\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9283 - loss: 0.0298\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9278 - loss: 0.0298\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9272 - loss: 0.0299\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9266 - loss: 0.0299\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9260 - loss: 0.0299\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9254 - loss: 0.0299\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9248 - loss: 0.0299\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9242 - loss: 0.0299\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9236 - loss: 0.0299\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9231 - loss: 0.0299\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9225 - loss: 0.0299\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9219 - loss: 0.0299\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9214 - loss: 0.0299\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9209 - loss: 0.0300\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9203 - loss: 0.0300\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9198 - loss: 0.0300\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9193 - loss: 0.0300\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9188 - loss: 0.0300\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9184 - loss: 0.0300\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9179 - loss: 0.0300\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9174 - loss: 0.0300\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9170 - loss: 0.0300\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9165 - loss: 0.0300\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9161 - loss: 0.0300\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9157 - loss: 0.0301\n",
      "                                                     \n",
      "Epoch 2: val_loss improved from 0.04053 to 0.03576, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.9153 - loss: 0.0301 - val_accuracy: 0.9944 - val_loss: 0.0358\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 129ms/step - accuracy: 0.8906 - loss: 0.0200\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9023 - loss: 0.0226 \n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 87ms/step - accuracy: 0.9054 - loss: 0.0222\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9115 - loss: 0.0219\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.9167 - loss: 0.0221\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9214 - loss: 0.0220\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.9241 - loss: 0.0223\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9265 - loss: 0.0229\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9273 - loss: 0.0233\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9279 - loss: 0.0235\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9282 - loss: 0.0237\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9284 - loss: 0.0240 \n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9290 - loss: 0.0241\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9296 - loss: 0.0243\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9304 - loss: 0.0244\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9312 - loss: 0.0246\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9319 - loss: 0.0247\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9327 - loss: 0.0247 \n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9334 - loss: 0.0248\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9340 - loss: 0.0248\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9346 - loss: 0.0248\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9351 - loss: 0.0248\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9355 - loss: 0.0248\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9359 - loss: 0.0248\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9360 - loss: 0.0249\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9362 - loss: 0.0249\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9363 - loss: 0.0250\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.9362 - loss: 0.0250\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.9361 - loss: 0.0251\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9358 - loss: 0.0252\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9355 - loss: 0.0253\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9351 - loss: 0.0253\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9346 - loss: 0.0254\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9340 - loss: 0.0254\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9334 - loss: 0.0254\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9327 - loss: 0.0255\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9320 - loss: 0.0255\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9314 - loss: 0.0256\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9308 - loss: 0.0256\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9302 - loss: 0.0256\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9297 - loss: 0.0257\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9293 - loss: 0.0258\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9288 - loss: 0.0258\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9284 - loss: 0.0259\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9281 - loss: 0.0259\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9278 - loss: 0.0259\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9276 - loss: 0.0260\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9274 - loss: 0.0260\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9272 - loss: 0.0260\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9271 - loss: 0.0261\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9269 - loss: 0.0261\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9269 - loss: 0.0261\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9268 - loss: 0.0262\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9268 - loss: 0.0262\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9267 - loss: 0.0262\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9267 - loss: 0.0262\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9266 - loss: 0.0263\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9266 - loss: 0.0263\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9265 - loss: 0.0263\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9265 - loss: 0.0263\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9264 - loss: 0.0263\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9264 - loss: 0.0264\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9264 - loss: 0.0264\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9263 - loss: 0.0264\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9263 - loss: 0.0264\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9262 - loss: 0.0265\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9262 - loss: 0.0265\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9261 - loss: 0.0265\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9261 - loss: 0.0265\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.9260 - loss: 0.0265\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9260 - loss: 0.0265\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9259 - loss: 0.0265\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9259 - loss: 0.0265\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9258 - loss: 0.0265\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.9258 - loss: 0.0265\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9257 - loss: 0.0266\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9257 - loss: 0.0266\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9256 - loss: 0.0266\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9256 - loss: 0.0266\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9255 - loss: 0.0266\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9255 - loss: 0.0266\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9253 - loss: 0.0265\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9252 - loss: 0.0265\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9252 - loss: 0.0265\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9251 - loss: 0.0265\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9250 - loss: 0.0265\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9249 - loss: 0.0265\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9249 - loss: 0.0265\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9248 - loss: 0.0265\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9247 - loss: 0.0265\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9247 - loss: 0.0265\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9246 - loss: 0.0265\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9246 - loss: 0.0265\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9246 - loss: 0.0265\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9245 - loss: 0.0265\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9245 - loss: 0.0265\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9245 - loss: 0.0265\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9244 - loss: 0.0265\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9244 - loss: 0.0265\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9243 - loss: 0.0265\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9243 - loss: 0.0265\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9242 - loss: 0.0265\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9241 - loss: 0.0264\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9240 - loss: 0.0264\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9240 - loss: 0.0264\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9239 - loss: 0.0264\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9238 - loss: 0.0264\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9237 - loss: 0.0264\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9236 - loss: 0.0264\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9236 - loss: 0.0264\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9235 - loss: 0.0264\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9234 - loss: 0.0264\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9233 - loss: 0.0264\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9233 - loss: 0.0264\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9232 - loss: 0.0264\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9232 - loss: 0.0264\n",
      "                                                     \n",
      "Epoch 3: val_loss did not improve from 0.03576\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.9231 - loss: 0.0264 - val_accuracy: 0.9944 - val_loss: 0.0383\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step \n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\n",
      "[    0     3     8 ... 12762 12764 12765]            \n",
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.9062 - loss: 0.0305\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.9219 - loss: 0.0260\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.9253 - loss: 0.0276\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.9255 - loss: 0.0282\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.9254 - loss: 0.0289\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9235 - loss: 0.0293\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9210 - loss: 0.0300\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9194 - loss: 0.0306\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9176 - loss: 0.0310\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9158 - loss: 0.0312\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9140 - loss: 0.0314\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9125 - loss: 0.0319\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9108 - loss: 0.0324\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9085 - loss: 0.0328 \n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9052 - loss: 0.0331\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9018 - loss: 0.0333 \n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8985 - loss: 0.0335\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8949 - loss: 0.0336\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8911 - loss: 0.0338\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8873 - loss: 0.0339\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8838 - loss: 0.0340\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8804 - loss: 0.0341\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8774 - loss: 0.0342\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8746 - loss: 0.0343\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.8721 - loss: 0.0343\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.8699 - loss: 0.0344\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.8680 - loss: 0.0344\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8661 - loss: 0.0344\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8644 - loss: 0.0344\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8628 - loss: 0.0344\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8614 - loss: 0.0344\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.8601 - loss: 0.0344\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8588 - loss: 0.0344\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8575 - loss: 0.0344\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8563 - loss: 0.0344\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8550 - loss: 0.0344\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.8536 - loss: 0.0344\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.8522 - loss: 0.0343\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 87ms/step - accuracy: 0.8507 - loss: 0.0343\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 87ms/step - accuracy: 0.8491 - loss: 0.0343\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8476 - loss: 0.0343\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8460 - loss: 0.0343\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8444 - loss: 0.0343\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8428 - loss: 0.0342\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8413 - loss: 0.0342\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8398 - loss: 0.0342\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8384 - loss: 0.0342\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8369 - loss: 0.0342\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8355 - loss: 0.0342\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8341 - loss: 0.0342\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.8327 - loss: 0.0342\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.8313 - loss: 0.0342\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8298 - loss: 0.0341\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8283 - loss: 0.0341\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8268 - loss: 0.0341\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8252 - loss: 0.0341\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8236 - loss: 0.0340\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8220 - loss: 0.0340\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8203 - loss: 0.0340\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8186 - loss: 0.0340\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8169 - loss: 0.0339\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8152 - loss: 0.0339\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8135 - loss: 0.0339\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8118 - loss: 0.0338\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8101 - loss: 0.0338\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8084 - loss: 0.0338\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8068 - loss: 0.0338\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8052 - loss: 0.0338\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8037 - loss: 0.0338\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8022 - loss: 0.0338\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8008 - loss: 0.0338\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7994 - loss: 0.0338\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.7981 - loss: 0.0338\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.7968 - loss: 0.0338\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.7955 - loss: 0.0338\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.7942 - loss: 0.0338\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7930 - loss: 0.0338\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7917 - loss: 0.0337\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7904 - loss: 0.0337\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7892 - loss: 0.0337\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7879 - loss: 0.0337\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7867 - loss: 0.0337\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7855 - loss: 0.0337\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7844 - loss: 0.0337\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7833 - loss: 0.0337\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7823 - loss: 0.0337\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7813 - loss: 0.0337\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7803 - loss: 0.0337\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.7794 - loss: 0.0337\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7785 - loss: 0.0337\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7776 - loss: 0.0337\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7767 - loss: 0.0337\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7759 - loss: 0.0337\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7750 - loss: 0.0336\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7742 - loss: 0.0336\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7735 - loss: 0.0336\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7727 - loss: 0.0336\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7720 - loss: 0.0336\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7713 - loss: 0.0336\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7706 - loss: 0.0336\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7700 - loss: 0.0336\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7693 - loss: 0.0336\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7687 - loss: 0.0336\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7681 - loss: 0.0336\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7675 - loss: 0.0336\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7669 - loss: 0.0336\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7663 - loss: 0.0336\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7657 - loss: 0.0336\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7652 - loss: 0.0336\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7646 - loss: 0.0336\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.7641 - loss: 0.0336\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.7636 - loss: 0.0336\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.7631 - loss: 0.0335\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7627 - loss: 0.0335\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7622 - loss: 0.0335\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7617 - loss: 0.0335\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7613 - loss: 0.0335\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7608 - loss: 0.0335\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7604 - loss: 0.0335\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7600 - loss: 0.0335\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7596 - loss: 0.0335\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7592 - loss: 0.0334\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7588 - loss: 0.0334\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7584 - loss: 0.0334\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7580 - loss: 0.0334\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7576 - loss: 0.0334\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7573 - loss: 0.0334\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7569 - loss: 0.0334\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7566 - loss: 0.0334\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7563 - loss: 0.0334\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7559 - loss: 0.0333\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7556 - loss: 0.0333\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7553 - loss: 0.0333\n",
      "                                                     \n",
      "Epoch 1: val_loss improved from inf to 0.02188, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 98ms/step - accuracy: 0.7550 - loss: 0.0333 - val_accuracy: 0.7596 - val_loss: 0.0219\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - accuracy: 0.7969 - loss: 0.0173\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.7695 - loss: 0.0206 \n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.7457 - loss: 0.0221\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.7253 - loss: 0.0217\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.7083 - loss: 0.0222\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.6953 - loss: 0.0224\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.6827 - loss: 0.0223\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.6726 - loss: 0.0225\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.6644 - loss: 0.0228\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.6583 - loss: 0.0231\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.6528 - loss: 0.0233\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.6479 - loss: 0.0234\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.6444 - loss: 0.0235\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.6412 - loss: 0.0236\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.6390 - loss: 0.0237\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.6375 - loss: 0.0238\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.6363 - loss: 0.0238 \n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.6355 - loss: 0.0239\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.6354 - loss: 0.0240\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.6358 - loss: 0.0240\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.6367 - loss: 0.0240\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.6379 - loss: 0.0240\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.6391 - loss: 0.0240\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.6404 - loss: 0.0240\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.6417 - loss: 0.0241\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.6430 - loss: 0.0241\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.6443 - loss: 0.0241\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6456 - loss: 0.0241\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6469 - loss: 0.0241\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6484 - loss: 0.0241\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6499 - loss: 0.0241\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6514 - loss: 0.0241\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6529 - loss: 0.0241\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6545 - loss: 0.0241\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.6562 - loss: 0.0241\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6578 - loss: 0.0241\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6594 - loss: 0.0241\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.6611 - loss: 0.0241\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.6627 - loss: 0.0241\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.6643 - loss: 0.0241\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6660 - loss: 0.0241\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6676 - loss: 0.0241\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6692 - loss: 0.0240\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6707 - loss: 0.0240\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6722 - loss: 0.0240\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6736 - loss: 0.0240\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6750 - loss: 0.0240\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6764 - loss: 0.0240\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6778 - loss: 0.0240\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6792 - loss: 0.0240\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6806 - loss: 0.0240\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6820 - loss: 0.0240\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.6833 - loss: 0.0240\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.6847 - loss: 0.0240\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6860 - loss: 0.0240\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6873 - loss: 0.0240\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6886 - loss: 0.0240\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6898 - loss: 0.0239\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6910 - loss: 0.0239\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6921 - loss: 0.0239\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6931 - loss: 0.0239\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6941 - loss: 0.0239\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6950 - loss: 0.0239\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6959 - loss: 0.0238\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.6966 - loss: 0.0238\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.6974 - loss: 0.0238\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.6982 - loss: 0.0238\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.6989 - loss: 0.0238\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.6996 - loss: 0.0237\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7003 - loss: 0.0237\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7010 - loss: 0.0237\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7017 - loss: 0.0237\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7023 - loss: 0.0237\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7029 - loss: 0.0237\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.7034 - loss: 0.0237\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7038 - loss: 0.0236\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7042 - loss: 0.0236\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7045 - loss: 0.0236\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7047 - loss: 0.0236\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7049 - loss: 0.0236\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7050 - loss: 0.0236\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7051 - loss: 0.0235\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7051 - loss: 0.0235\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7051 - loss: 0.0235\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7050 - loss: 0.0235\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7050 - loss: 0.0235\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7048 - loss: 0.0234\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7047 - loss: 0.0234\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7045 - loss: 0.0234\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7043 - loss: 0.0234\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7041 - loss: 0.0234\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7039 - loss: 0.0233\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7037 - loss: 0.0233\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7035 - loss: 0.0233\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7033 - loss: 0.0233\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7032 - loss: 0.0233\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7030 - loss: 0.0233\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7029 - loss: 0.0232\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7027 - loss: 0.0232\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7026 - loss: 0.0232\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7025 - loss: 0.0232\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7024 - loss: 0.0232\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7023 - loss: 0.0232\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7022 - loss: 0.0232\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7021 - loss: 0.0232\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7020 - loss: 0.0232\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.7019 - loss: 0.0232\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.7018 - loss: 0.0232\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7017 - loss: 0.0232\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.7016 - loss: 0.0232\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.7015 - loss: 0.0232\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7014 - loss: 0.0232\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7012 - loss: 0.0232\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7011 - loss: 0.0232\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7010 - loss: 0.0231\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7008 - loss: 0.0231\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7007 - loss: 0.0231\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7005 - loss: 0.0231\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7003 - loss: 0.0231\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7000 - loss: 0.0231\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.6998 - loss: 0.0231\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6995 - loss: 0.0231\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6993 - loss: 0.0231\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6990 - loss: 0.0231\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6987 - loss: 0.0231\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6984 - loss: 0.0231\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6981 - loss: 0.0231\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6978 - loss: 0.0231\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6975 - loss: 0.0231\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6972 - loss: 0.0231\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6969 - loss: 0.0231\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6966 - loss: 0.0231\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6963 - loss: 0.0231\n",
      "                                                     \n",
      "Epoch 2: val_loss did not improve from 0.02188\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.6960 - loss: 0.0231 - val_accuracy: 0.6418 - val_loss: 0.0222\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 98ms/step - accuracy: 0.6094 - loss: 0.0163\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.6094 - loss: 0.0222\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 87ms/step - accuracy: 0.6076 - loss: 0.0222\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.6003 - loss: 0.0215\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.5921 - loss: 0.0208\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.5854 - loss: 0.0209\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.5818 - loss: 0.0211\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.5794 - loss: 0.0215\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.5754 - loss: 0.0217\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.5716 - loss: 0.0218\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.5681 - loss: 0.0218\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.5631 - loss: 0.0219\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.5581 - loss: 0.0220\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.5535 - loss: 0.0219\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.5492 - loss: 0.0219\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.5452 - loss: 0.0219\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.5415 - loss: 0.0219\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.5381 - loss: 0.0218 \n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.5350 - loss: 0.0218\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.5323 - loss: 0.0219\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5302 - loss: 0.0219\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5283 - loss: 0.0220\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5268 - loss: 0.0220\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5257 - loss: 0.0220\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5250 - loss: 0.0220\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5246 - loss: 0.0220\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5244 - loss: 0.0220\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.5245 - loss: 0.0220\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.5248 - loss: 0.0220\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.5252 - loss: 0.0219\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.5257 - loss: 0.0219\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.5262 - loss: 0.0219\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.5268 - loss: 0.0219\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.5273 - loss: 0.0219\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.5279 - loss: 0.0219\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.5285 - loss: 0.0219\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.5290 - loss: 0.0219\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.5295 - loss: 0.0219\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5297 - loss: 0.0219\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5297 - loss: 0.0219\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5296 - loss: 0.0219\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5292 - loss: 0.0220\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5288 - loss: 0.0220\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5282 - loss: 0.0220\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5275 - loss: 0.0220\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5267 - loss: 0.0220\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5258 - loss: 0.0220\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5249 - loss: 0.0220\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5240 - loss: 0.0220\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5231 - loss: 0.0220\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5222 - loss: 0.0220\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5215 - loss: 0.0220\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5207 - loss: 0.0220\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5200 - loss: 0.0220\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5195 - loss: 0.0220\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5190 - loss: 0.0220\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5188 - loss: 0.0219\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5186 - loss: 0.0219\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5186 - loss: 0.0219\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5187 - loss: 0.0219\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5188 - loss: 0.0219\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5190 - loss: 0.0218\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5193 - loss: 0.0218\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5197 - loss: 0.0218\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5201 - loss: 0.0218\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5206 - loss: 0.0217\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5210 - loss: 0.0217\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5214 - loss: 0.0217\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5218 - loss: 0.0217\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.5221 - loss: 0.0217\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.5224 - loss: 0.0217\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.5226 - loss: 0.0216\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.5227 - loss: 0.0216\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5229 - loss: 0.0216\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5229 - loss: 0.0216\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5230 - loss: 0.0216\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5230 - loss: 0.0216\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5230 - loss: 0.0215\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5230 - loss: 0.0215\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5230 - loss: 0.0215\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5231 - loss: 0.0215\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5231 - loss: 0.0215\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5232 - loss: 0.0215\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5233 - loss: 0.0214\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5233 - loss: 0.0214\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5234 - loss: 0.0214\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5235 - loss: 0.0214\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5236 - loss: 0.0214\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5238 - loss: 0.0213\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5239 - loss: 0.0213\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5240 - loss: 0.0213\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5242 - loss: 0.0213\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5243 - loss: 0.0213\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5244 - loss: 0.0213\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5245 - loss: 0.0212\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5246 - loss: 0.0212\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5247 - loss: 0.0212\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5247 - loss: 0.0212\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5247 - loss: 0.0212\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5248 - loss: 0.0211\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5248 - loss: 0.0211\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5247 - loss: 0.0211\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5247 - loss: 0.0211\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5246 - loss: 0.0211\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5245 - loss: 0.0211\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5244 - loss: 0.0210\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5243 - loss: 0.0210\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5242 - loss: 0.0210\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5240 - loss: 0.0210\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5238 - loss: 0.0210\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5237 - loss: 0.0209\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5235 - loss: 0.0209\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5233 - loss: 0.0209\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5231 - loss: 0.0209\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5228 - loss: 0.0209\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5226 - loss: 0.0209\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5223 - loss: 0.0209\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5221 - loss: 0.0208\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5218 - loss: 0.0208\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5215 - loss: 0.0208\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5212 - loss: 0.0208\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5209 - loss: 0.0208\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5205 - loss: 0.0208\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5202 - loss: 0.0208\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5199 - loss: 0.0207\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5195 - loss: 0.0207\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5192 - loss: 0.0207\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5188 - loss: 0.0207\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5185 - loss: 0.0207\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5182 - loss: 0.0207\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5178 - loss: 0.0207\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5175 - loss: 0.0206\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5172 - loss: 0.0206\n",
      "                                                     \n",
      "Epoch 3: val_loss did not improve from 0.02188\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.5169 - loss: 0.0206 - val_accuracy: 0.5309 - val_loss: 0.0226\n",
      "\n",
      "Epoch 3: early stopping                              \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step \n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "[    1     2     4 ... 12758 12763 12765]                                        \n",
      " 50%|█████     | 1/2 [02:00<02:00, 120.64s/trial, best loss: -0.4752855495018105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:33\u001b[0m 2s/step - accuracy: 0.2188 - loss: 0.6966\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.1084 - loss: 0.6813 \n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.0812 - loss: 0.6532\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.0705 - loss: 0.6044\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.0860 - loss: 0.5632\n",
      "\u001b[1m 26/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.1252 - loss: 0.5277\n",
      "\u001b[1m 30/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.1597 - loss: 0.5026\n",
      "\u001b[1m 35/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.1966 - loss: 0.4755\n",
      "\u001b[1m 40/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.2254 - loss: 0.4522\n",
      "\u001b[1m 45/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.2504 - loss: 0.4324\n",
      "\u001b[1m 50/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.2729 - loss: 0.4150\n",
      "\u001b[1m 55/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.2925 - loss: 0.4000\n",
      "\u001b[1m 60/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3102 - loss: 0.3869\n",
      "\u001b[1m 64/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3230 - loss: 0.3776\n",
      "\u001b[1m 69/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3380 - loss: 0.3670\n",
      "\u001b[1m 74/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3524 - loss: 0.3577\n",
      "\u001b[1m 79/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3662 - loss: 0.3493\n",
      "\u001b[1m 84/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3794 - loss: 0.3417\n",
      "\u001b[1m 89/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3917 - loss: 0.3347\n",
      "\u001b[1m 94/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4032 - loss: 0.3283\n",
      "\u001b[1m 99/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4143 - loss: 0.3224\n",
      "\u001b[1m104/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4249 - loss: 0.3169\n",
      "\u001b[1m109/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4350 - loss: 0.3118\n",
      "\u001b[1m112/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4409 - loss: 0.3089\n",
      "\u001b[1m116/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4484 - loss: 0.3052\n",
      "\u001b[1m120/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4557 - loss: 0.3017\n",
      "\u001b[1m125/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4644 - loss: 0.2976\n",
      "\u001b[1m130/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4725 - loss: 0.2938\n",
      "\u001b[1m135/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4800 - loss: 0.2902\n",
      "\u001b[1m140/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4868 - loss: 0.2867\n",
      "\u001b[1m145/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4934 - loss: 0.2834\n",
      "\u001b[1m149/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4985 - loss: 0.2809\n",
      "\u001b[1m153/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5034 - loss: 0.2785\n",
      "\u001b[1m158/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5094 - loss: 0.2755\n",
      "\u001b[1m162/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5139 - loss: 0.2733\n",
      "\u001b[1m167/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5192 - loss: 0.2705\n",
      "\u001b[1m172/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.2679\n",
      "\u001b[1m176/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5281 - loss: 0.2659\n",
      "\u001b[1m181/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5329 - loss: 0.2634\n",
      "\u001b[1m186/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5375 - loss: 0.2611\n",
      "\u001b[1m191/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5418 - loss: 0.2588\n",
      "\u001b[1m196/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5459 - loss: 0.2567\n",
      "\u001b[1m201/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5498 - loss: 0.2546\n",
      "\u001b[1m206/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5536 - loss: 0.2525\n",
      "\u001b[1m211/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5573 - loss: 0.2506\n",
      "\u001b[1m216/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5611 - loss: 0.2487\n",
      "\u001b[1m221/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5647 - loss: 0.2468\n",
      "\u001b[1m226/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5682 - loss: 0.2450\n",
      "\u001b[1m231/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5715 - loss: 0.2432\n",
      "\u001b[1m235/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5740 - loss: 0.2418\n",
      "\u001b[1m240/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5770 - loss: 0.2402\n",
      "\u001b[1m245/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5799 - loss: 0.2386\n",
      "\u001b[1m250/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5827 - loss: 0.2370\n",
      "\u001b[1m255/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5855 - loss: 0.2355\n",
      "\u001b[1m260/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5882 - loss: 0.2340\n",
      "\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5909 - loss: 0.2325\n",
      "                                                                                 \n",
      "Epoch 1: val_loss improved from inf to 0.09667, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.5920 - loss: 0.2319 - val_accuracy: 0.9948 - val_loss: 0.0967\n",
      "\n",
      "Epoch 2/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9062 - loss: 0.1011\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7820 - loss: 0.0849\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6944 - loss: 0.0803\n",
      "\u001b[1m 15/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6505 - loss: 0.0786\n",
      "\u001b[1m 19/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6241 - loss: 0.0783\n",
      "\u001b[1m 24/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6093 - loss: 0.0789\n",
      "\u001b[1m 29/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6118 - loss: 0.0795\n",
      "\u001b[1m 34/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6220 - loss: 0.0798\n",
      "\u001b[1m 39/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6342 - loss: 0.0804\n",
      "\u001b[1m 44/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6441 - loss: 0.0810\n",
      "\u001b[1m 48/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6495 - loss: 0.0813\n",
      "\u001b[1m 53/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6540 - loss: 0.0818\n",
      "\u001b[1m 57/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6567 - loss: 0.0820\n",
      "\u001b[1m 62/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6595 - loss: 0.0823\n",
      "\u001b[1m 67/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6624 - loss: 0.0826\n",
      "\u001b[1m 72/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6652 - loss: 0.0828\n",
      "\u001b[1m 77/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6686 - loss: 0.0829\n",
      "\u001b[1m 82/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6723 - loss: 0.0829\n",
      "\u001b[1m 87/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6763 - loss: 0.0830\n",
      "\u001b[1m 92/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6806 - loss: 0.0830\n",
      "\u001b[1m 96/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6841 - loss: 0.0831\n",
      "\u001b[1m101/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6884 - loss: 0.0832\n",
      "\u001b[1m106/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6924 - loss: 0.0832\n",
      "\u001b[1m110/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6953 - loss: 0.0832\n",
      "\u001b[1m114/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6982 - loss: 0.0832\n",
      "\u001b[1m118/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7009 - loss: 0.0832\n",
      "\u001b[1m123/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7043 - loss: 0.0833\n",
      "\u001b[1m128/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7075 - loss: 0.0833\n",
      "\u001b[1m133/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7105 - loss: 0.0833\n",
      "\u001b[1m137/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7130 - loss: 0.0833\n",
      "\u001b[1m142/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7160 - loss: 0.0832\n",
      "\u001b[1m147/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7190 - loss: 0.0832\n",
      "\u001b[1m152/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7220 - loss: 0.0831\n",
      "\u001b[1m157/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7250 - loss: 0.0830\n",
      "\u001b[1m161/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7274 - loss: 0.0829\n",
      "\u001b[1m165/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7297 - loss: 0.0828\n",
      "\u001b[1m169/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7320 - loss: 0.0827\n",
      "\u001b[1m174/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7348 - loss: 0.0826\n",
      "\u001b[1m177/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7365 - loss: 0.0825\n",
      "\u001b[1m181/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7387 - loss: 0.0824\n",
      "\u001b[1m186/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7414 - loss: 0.0823\n",
      "\u001b[1m191/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7441 - loss: 0.0821\n",
      "\u001b[1m196/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7466 - loss: 0.0819\n",
      "\u001b[1m200/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7486 - loss: 0.0818\n",
      "\u001b[1m205/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7511 - loss: 0.0816\n",
      "\u001b[1m210/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7535 - loss: 0.0814\n",
      "\u001b[1m214/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7554 - loss: 0.0813\n",
      "\u001b[1m219/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7578 - loss: 0.0811\n",
      "\u001b[1m224/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7601 - loss: 0.0809\n",
      "\u001b[1m229/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7623 - loss: 0.0807\n",
      "\u001b[1m234/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7645 - loss: 0.0806\n",
      "\u001b[1m239/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7665 - loss: 0.0804\n",
      "\u001b[1m244/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7684 - loss: 0.0802\n",
      "\u001b[1m249/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7703 - loss: 0.0800\n",
      "\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7720 - loss: 0.0799\n",
      "\u001b[1m258/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7734 - loss: 0.0797\n",
      "\u001b[1m263/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7752 - loss: 0.0796\n",
      "                                                                                 \n",
      "Epoch 2: val_loss improved from 0.09667 to 0.06179, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.7765 - loss: 0.0794 - val_accuracy: 0.9948 - val_loss: 0.0618\n",
      "\n",
      "Epoch 3/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0261\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9617 - loss: 0.0462\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9535 - loss: 0.0526\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9498 - loss: 0.0543\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9507 - loss: 0.0547\n",
      "\u001b[1m 26/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9530 - loss: 0.0542\n",
      "\u001b[1m 31/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9553 - loss: 0.0542\n",
      "\u001b[1m 36/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9576 - loss: 0.0541\n",
      "\u001b[1m 40/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9593 - loss: 0.0539\n",
      "\u001b[1m 44/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9609 - loss: 0.0537\n",
      "\u001b[1m 49/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9625 - loss: 0.0535\n",
      "\u001b[1m 54/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9638 - loss: 0.0531\n",
      "\u001b[1m 59/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: 0.0528\n",
      "\u001b[1m 63/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9659 - loss: 0.0525\n",
      "\u001b[1m 68/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9668 - loss: 0.0521\n",
      "\u001b[1m 73/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9677 - loss: 0.0517\n",
      "\u001b[1m 77/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9683 - loss: 0.0514\n",
      "\u001b[1m 81/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9687 - loss: 0.0510\n",
      "\u001b[1m 85/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9690 - loss: 0.0507\n",
      "\u001b[1m 90/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9693 - loss: 0.0503\n",
      "\u001b[1m 95/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9696 - loss: 0.0500\n",
      "\u001b[1m100/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0497\n",
      "\u001b[1m104/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0495\n",
      "\u001b[1m109/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0492\n",
      "\u001b[1m113/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0490\n",
      "\u001b[1m118/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0487\n",
      "\u001b[1m123/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0485\n",
      "\u001b[1m128/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0482\n",
      "\u001b[1m133/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0480\n",
      "\u001b[1m138/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9699 - loss: 0.0477\n",
      "\u001b[1m143/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9699 - loss: 0.0475\n",
      "\u001b[1m147/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0474\n",
      "\u001b[1m152/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9697 - loss: 0.0472\n",
      "\u001b[1m157/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9695 - loss: 0.0470\n",
      "\u001b[1m161/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9693 - loss: 0.0468\n",
      "\u001b[1m166/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9690 - loss: 0.0466\n",
      "\u001b[1m170/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9686 - loss: 0.0465\n",
      "\u001b[1m175/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9680 - loss: 0.0463\n",
      "\u001b[1m180/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9674 - loss: 0.0462\n",
      "\u001b[1m185/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9668 - loss: 0.0460\n",
      "\u001b[1m190/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9663 - loss: 0.0459\n",
      "\u001b[1m195/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9658 - loss: 0.0457\n",
      "\u001b[1m200/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9654 - loss: 0.0456\n",
      "\u001b[1m205/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: 0.0455\n",
      "\u001b[1m210/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9645 - loss: 0.0454\n",
      "\u001b[1m215/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9639 - loss: 0.0453\n",
      "\u001b[1m219/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9634 - loss: 0.0453\n",
      "\u001b[1m223/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9629 - loss: 0.0452\n",
      "\u001b[1m228/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9623 - loss: 0.0451\n",
      "\u001b[1m232/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9619 - loss: 0.0451\n",
      "\u001b[1m237/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9613 - loss: 0.0450\n",
      "\u001b[1m242/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9609 - loss: 0.0449\n",
      "\u001b[1m247/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9604 - loss: 0.0448\n",
      "\u001b[1m252/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9600 - loss: 0.0448\n",
      "\u001b[1m257/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9596 - loss: 0.0447\n",
      "\u001b[1m262/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9592 - loss: 0.0447\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9590 - loss: 0.0446\n",
      "                                                                                 \n",
      "Epoch 3: val_loss did not improve from 0.06179\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9589 - loss: 0.0446 - val_accuracy: 0.9948 - val_loss: 0.0649\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 104ms/step             \n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step      \n",
      "\n",
      "[    0     1     2 ... 12762 12763 12764]                                        \n",
      "Epoch 1/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0228\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0284\n",
      "\u001b[1m 10/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0328\n",
      "\u001b[1m 15/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9935 - loss: 0.0370\n",
      "\u001b[1m 20/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9881 - loss: 0.0397\n",
      "\u001b[1m 24/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9840 - loss: 0.0413\n",
      "\u001b[1m 29/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9774 - loss: 0.0426\n",
      "\u001b[1m 34/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9675 - loss: 0.0436\n",
      "\u001b[1m 39/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9541 - loss: 0.0442\n",
      "\u001b[1m 43/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9428 - loss: 0.0445\n",
      "\u001b[1m 48/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9302 - loss: 0.0447\n",
      "\u001b[1m 53/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9197 - loss: 0.0448\n",
      "\u001b[1m 58/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9110 - loss: 0.0448\n",
      "\u001b[1m 62/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9049 - loss: 0.0448\n",
      "\u001b[1m 67/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8977 - loss: 0.0448\n",
      "\u001b[1m 72/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8907 - loss: 0.0448\n",
      "\u001b[1m 76/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8853 - loss: 0.0448\n",
      "\u001b[1m 81/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8791 - loss: 0.0449\n",
      "\u001b[1m 86/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8739 - loss: 0.0450\n",
      "\u001b[1m 91/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8692 - loss: 0.0451\n",
      "\u001b[1m 95/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8656 - loss: 0.0452\n",
      "\u001b[1m100/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8611 - loss: 0.0453\n",
      "\u001b[1m105/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8571 - loss: 0.0454\n",
      "\u001b[1m108/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8549 - loss: 0.0454\n",
      "\u001b[1m112/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8525 - loss: 0.0455\n",
      "\u001b[1m117/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8499 - loss: 0.0456\n",
      "\u001b[1m122/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8478 - loss: 0.0456\n",
      "\u001b[1m127/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8460 - loss: 0.0457\n",
      "\u001b[1m131/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8445 - loss: 0.0457\n",
      "\u001b[1m136/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8428 - loss: 0.0458\n",
      "\u001b[1m141/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8412 - loss: 0.0458\n",
      "\u001b[1m146/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8398 - loss: 0.0458\n",
      "\u001b[1m151/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8385 - loss: 0.0458\n",
      "\u001b[1m156/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8374 - loss: 0.0458\n",
      "\u001b[1m161/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8367 - loss: 0.0458\n",
      "\u001b[1m165/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8362 - loss: 0.0458\n",
      "\u001b[1m170/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8358 - loss: 0.0458\n",
      "\u001b[1m174/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8355 - loss: 0.0458\n",
      "\u001b[1m179/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8352 - loss: 0.0459\n",
      "\u001b[1m184/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8349 - loss: 0.0459\n",
      "\u001b[1m188/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8348 - loss: 0.0459\n",
      "\u001b[1m192/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8347 - loss: 0.0459\n",
      "\u001b[1m196/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8347 - loss: 0.0459\n",
      "\u001b[1m201/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8348 - loss: 0.0459\n",
      "\u001b[1m206/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8349 - loss: 0.0459\n",
      "\u001b[1m211/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8352 - loss: 0.0459\n",
      "\u001b[1m216/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8355 - loss: 0.0459\n",
      "\u001b[1m221/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8358 - loss: 0.0459\n",
      "\u001b[1m226/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8360 - loss: 0.0459\n",
      "\u001b[1m231/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8362 - loss: 0.0459\n",
      "\u001b[1m236/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8365 - loss: 0.0460\n",
      "\u001b[1m241/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8367 - loss: 0.0460\n",
      "\u001b[1m246/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8371 - loss: 0.0460\n",
      "\u001b[1m251/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8374 - loss: 0.0460\n",
      "\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8376 - loss: 0.0460\n",
      "\u001b[1m258/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8379 - loss: 0.0461\n",
      "\u001b[1m263/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8383 - loss: 0.0461\n",
      "                                                                                 \n",
      "Epoch 1: val_loss improved from inf to 0.04076, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.8387 - loss: 0.0461 - val_accuracy: 0.9944 - val_loss: 0.0408\n",
      "\n",
      "Epoch 2/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.9688 - loss: 0.0328\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9590 - loss: 0.0432\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9393 - loss: 0.0427\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9145 - loss: 0.0427\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8956 - loss: 0.0427\n",
      "\u001b[1m 25/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8862 - loss: 0.0423\n",
      "\u001b[1m 30/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8795 - loss: 0.0416\n",
      "\u001b[1m 34/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8770 - loss: 0.0412\n",
      "\u001b[1m 39/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8763 - loss: 0.0409\n",
      "\u001b[1m 44/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8773 - loss: 0.0405\n",
      "\u001b[1m 49/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8790 - loss: 0.0402\n",
      "\u001b[1m 53/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8807 - loss: 0.0400\n",
      "\u001b[1m 58/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8829 - loss: 0.0397\n",
      "\u001b[1m 62/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8846 - loss: 0.0394\n",
      "\u001b[1m 67/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8868 - loss: 0.0391\n",
      "\u001b[1m 71/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8884 - loss: 0.0389\n",
      "\u001b[1m 75/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8900 - loss: 0.0386\n",
      "\u001b[1m 80/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8917 - loss: 0.0384\n",
      "\u001b[1m 85/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8931 - loss: 0.0382\n",
      "\u001b[1m 90/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8942 - loss: 0.0380\n",
      "\u001b[1m 94/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8945 - loss: 0.0379\n",
      "\u001b[1m 97/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8944 - loss: 0.0378\n",
      "\u001b[1m101/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8939 - loss: 0.0377\n",
      "\u001b[1m105/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8933 - loss: 0.0376\n",
      "\u001b[1m110/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8926 - loss: 0.0375\n",
      "\u001b[1m115/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8919 - loss: 0.0374\n",
      "\u001b[1m120/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8913 - loss: 0.0372\n",
      "\u001b[1m125/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8907 - loss: 0.0371\n",
      "\u001b[1m130/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8902 - loss: 0.0369\n",
      "\u001b[1m134/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8900 - loss: 0.0369\n",
      "\u001b[1m139/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8897 - loss: 0.0368\n",
      "\u001b[1m144/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8896 - loss: 0.0367\n",
      "\u001b[1m149/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8895 - loss: 0.0365\n",
      "\u001b[1m153/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8894 - loss: 0.0365\n",
      "\u001b[1m158/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8894 - loss: 0.0363\n",
      "\u001b[1m163/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8895 - loss: 0.0362\n",
      "\u001b[1m168/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8897 - loss: 0.0361\n",
      "\u001b[1m173/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8899 - loss: 0.0360\n",
      "\u001b[1m178/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8902 - loss: 0.0359\n",
      "\u001b[1m183/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8904 - loss: 0.0358\n",
      "\u001b[1m188/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8906 - loss: 0.0358\n",
      "\u001b[1m192/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8907 - loss: 0.0357\n",
      "\u001b[1m196/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8908 - loss: 0.0357\n",
      "\u001b[1m201/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8910 - loss: 0.0356\n",
      "\u001b[1m205/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8912 - loss: 0.0355\n",
      "\u001b[1m209/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8914 - loss: 0.0355\n",
      "\u001b[1m213/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8917 - loss: 0.0354\n",
      "\u001b[1m218/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8920 - loss: 0.0354\n",
      "\u001b[1m223/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8924 - loss: 0.0353\n",
      "\u001b[1m228/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8927 - loss: 0.0352\n",
      "\u001b[1m233/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8931 - loss: 0.0352\n",
      "\u001b[1m238/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8935 - loss: 0.0351\n",
      "\u001b[1m243/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8938 - loss: 0.0350\n",
      "\u001b[1m248/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8942 - loss: 0.0350\n",
      "\u001b[1m253/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8945 - loss: 0.0349\n",
      "\u001b[1m258/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8949 - loss: 0.0349\n",
      "\u001b[1m263/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8952 - loss: 0.0348\n",
      "                                                                                 \n",
      "Epoch 2: val_loss improved from 0.04076 to 0.03850, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8955 - loss: 0.0348 - val_accuracy: 0.9944 - val_loss: 0.0385\n",
      "\n",
      "Epoch 3/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9375 - loss: 0.0064\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9694 - loss: 0.0208\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9752 - loss: 0.0243\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9792 - loss: 0.0238\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0231\n",
      "\u001b[1m 26/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9829 - loss: 0.0229\n",
      "\u001b[1m 31/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9837 - loss: 0.0230\n",
      "\u001b[1m 36/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9839 - loss: 0.0232\n",
      "\u001b[1m 40/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9835 - loss: 0.0236\n",
      "\u001b[1m 45/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9829 - loss: 0.0239\n",
      "\u001b[1m 50/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9815 - loss: 0.0243\n",
      "\u001b[1m 55/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9795 - loss: 0.0247\n",
      "\u001b[1m 60/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9774 - loss: 0.0251\n",
      "\u001b[1m 64/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9758 - loss: 0.0253\n",
      "\u001b[1m 69/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9739 - loss: 0.0257\n",
      "\u001b[1m 73/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9728 - loss: 0.0259\n",
      "\u001b[1m 78/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9716 - loss: 0.0261\n",
      "\u001b[1m 83/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9706 - loss: 0.0263\n",
      "\u001b[1m 88/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0265\n",
      "\u001b[1m 93/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0267\n",
      "\u001b[1m 98/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9677 - loss: 0.0268\n",
      "\u001b[1m103/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9663 - loss: 0.0269\n",
      "\u001b[1m108/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: 0.0271\n",
      "\u001b[1m113/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9637 - loss: 0.0272\n",
      "\u001b[1m118/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9625 - loss: 0.0273\n",
      "\u001b[1m122/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9616 - loss: 0.0274\n",
      "\u001b[1m127/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9606 - loss: 0.0275\n",
      "\u001b[1m132/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9596 - loss: 0.0275\n",
      "\u001b[1m137/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9586 - loss: 0.0276\n",
      "\u001b[1m139/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9583 - loss: 0.0276\n",
      "\u001b[1m143/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9577 - loss: 0.0276\n",
      "\u001b[1m147/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9570 - loss: 0.0277\n",
      "\u001b[1m152/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9564 - loss: 0.0277\n",
      "\u001b[1m157/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9557 - loss: 0.0277\n",
      "\u001b[1m162/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9550 - loss: 0.0277\n",
      "\u001b[1m167/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9542 - loss: 0.0277\n",
      "\u001b[1m172/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9535 - loss: 0.0277\n",
      "\u001b[1m177/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9528 - loss: 0.0277\n",
      "\u001b[1m181/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9521 - loss: 0.0277\n",
      "\u001b[1m186/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9513 - loss: 0.0277\n",
      "\u001b[1m191/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9504 - loss: 0.0277\n",
      "\u001b[1m196/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9493 - loss: 0.0277\n",
      "\u001b[1m201/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9481 - loss: 0.0277\n",
      "\u001b[1m206/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9468 - loss: 0.0277\n",
      "\u001b[1m210/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9457 - loss: 0.0277\n",
      "\u001b[1m215/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9442 - loss: 0.0277\n",
      "\u001b[1m220/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9428 - loss: 0.0276\n",
      "\u001b[1m225/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9413 - loss: 0.0276\n",
      "\u001b[1m230/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9399 - loss: 0.0276\n",
      "\u001b[1m235/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9385 - loss: 0.0276\n",
      "\u001b[1m239/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9375 - loss: 0.0276\n",
      "\u001b[1m242/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9368 - loss: 0.0276\n",
      "\u001b[1m247/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9357 - loss: 0.0275\n",
      "\u001b[1m252/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9347 - loss: 0.0275\n",
      "\u001b[1m257/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9337 - loss: 0.0275\n",
      "\u001b[1m261/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9329 - loss: 0.0275\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9319 - loss: 0.0275\n",
      "                                                                                 \n",
      "Epoch 3: val_loss did not improve from 0.03850\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9317 - loss: 0.0275 - val_accuracy: 0.9854 - val_loss: 0.0413\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 16ms/step               \n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step       \n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step      \n",
      "\n",
      "[    0     3     8 ... 12762 12764 12765]                                        \n",
      "Epoch 1/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.8125 - loss: 0.0810\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8354 - loss: 0.0572\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8393 - loss: 0.0461\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8428 - loss: 0.0417\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8488 - loss: 0.0402\n",
      "\u001b[1m 26/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8555 - loss: 0.0398\n",
      "\u001b[1m 31/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8626 - loss: 0.0391\n",
      "\u001b[1m 35/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8679 - loss: 0.0388\n",
      "\u001b[1m 40/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8736 - loss: 0.0387\n",
      "\u001b[1m 45/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8767 - loss: 0.0385\n",
      "\u001b[1m 50/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8768 - loss: 0.0383\n",
      "\u001b[1m 54/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8751 - loss: 0.0381\n",
      "\u001b[1m 59/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8720 - loss: 0.0380\n",
      "\u001b[1m 63/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8692 - loss: 0.0378\n",
      "\u001b[1m 67/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8662 - loss: 0.0377\n",
      "\u001b[1m 70/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8636 - loss: 0.0376\n",
      "\u001b[1m 75/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8588 - loss: 0.0374\n",
      "\u001b[1m 80/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8534 - loss: 0.0372\n",
      "\u001b[1m 84/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8493 - loss: 0.0370\n",
      "\u001b[1m 89/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8451 - loss: 0.0368\n",
      "\u001b[1m 93/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8423 - loss: 0.0367\n",
      "\u001b[1m 98/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8395 - loss: 0.0366\n",
      "\u001b[1m103/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8372 - loss: 0.0364\n",
      "\u001b[1m107/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8359 - loss: 0.0363\n",
      "\u001b[1m112/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8346 - loss: 0.0362\n",
      "\u001b[1m117/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8338 - loss: 0.0361\n",
      "\u001b[1m121/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8333 - loss: 0.0360\n",
      "\u001b[1m126/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8327 - loss: 0.0359\n",
      "\u001b[1m131/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8320 - loss: 0.0358\n",
      "\u001b[1m135/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8314 - loss: 0.0357\n",
      "\u001b[1m139/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8308 - loss: 0.0356\n",
      "\u001b[1m144/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8302 - loss: 0.0355\n",
      "\u001b[1m148/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8299 - loss: 0.0354\n",
      "\u001b[1m152/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8298 - loss: 0.0353\n",
      "\u001b[1m156/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8297 - loss: 0.0353\n",
      "\u001b[1m160/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8297 - loss: 0.0352\n",
      "\u001b[1m165/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8298 - loss: 0.0351\n",
      "\u001b[1m170/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8300 - loss: 0.0350\n",
      "\u001b[1m175/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8303 - loss: 0.0350\n",
      "\u001b[1m180/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8307 - loss: 0.0349\n",
      "\u001b[1m185/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8312 - loss: 0.0349\n",
      "\u001b[1m189/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8317 - loss: 0.0348\n",
      "\u001b[1m194/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8322 - loss: 0.0347\n",
      "\u001b[1m198/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8325 - loss: 0.0347\n",
      "\u001b[1m203/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8329 - loss: 0.0346\n",
      "\u001b[1m208/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8332 - loss: 0.0345\n",
      "\u001b[1m213/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8335 - loss: 0.0345\n",
      "\u001b[1m218/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8337 - loss: 0.0344\n",
      "\u001b[1m223/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8339 - loss: 0.0343\n",
      "\u001b[1m228/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8342 - loss: 0.0343\n",
      "\u001b[1m232/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8343 - loss: 0.0342\n",
      "\u001b[1m235/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8345 - loss: 0.0342\n",
      "\u001b[1m239/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8347 - loss: 0.0342\n",
      "\u001b[1m244/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8348 - loss: 0.0341\n",
      "\u001b[1m249/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8349 - loss: 0.0341\n",
      "\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8349 - loss: 0.0341\n",
      "\u001b[1m258/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8347 - loss: 0.0340\n",
      "\u001b[1m263/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8343 - loss: 0.0340\n",
      "                                                                                 \n",
      "Epoch 1: val_loss improved from inf to 0.02507, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8339 - loss: 0.0340 - val_accuracy: 0.6280 - val_loss: 0.0251\n",
      "\n",
      "Epoch 2/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.6562 - loss: 0.0474\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7641 - loss: 0.0284\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8205 - loss: 0.0257\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8519 - loss: 0.0256\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8712 - loss: 0.0259\n",
      "\u001b[1m 26/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8843 - loss: 0.0257\n",
      "\u001b[1m 31/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8945 - loss: 0.0254\n",
      "\u001b[1m 36/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9023 - loss: 0.0252\n",
      "\u001b[1m 39/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9060 - loss: 0.0250\n",
      "\u001b[1m 43/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9096 - loss: 0.0247\n",
      "\u001b[1m 48/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9124 - loss: 0.0245\n",
      "\u001b[1m 53/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9129 - loss: 0.0244\n",
      "\u001b[1m 58/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9117 - loss: 0.0244\n",
      "\u001b[1m 63/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9096 - loss: 0.0244\n",
      "\u001b[1m 68/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9072 - loss: 0.0244\n",
      "\u001b[1m 73/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9050 - loss: 0.0243\n",
      "\u001b[1m 78/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9031 - loss: 0.0243\n",
      "\u001b[1m 83/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9012 - loss: 0.0244\n",
      "\u001b[1m 88/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8993 - loss: 0.0245\n",
      "\u001b[1m 93/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8969 - loss: 0.0246\n",
      "\u001b[1m 98/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8940 - loss: 0.0246\n",
      "\u001b[1m103/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8915 - loss: 0.0247\n",
      "\u001b[1m108/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8891 - loss: 0.0247\n",
      "\u001b[1m113/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8864 - loss: 0.0248\n",
      "\u001b[1m118/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8833 - loss: 0.0249\n",
      "\u001b[1m122/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8805 - loss: 0.0249\n",
      "\u001b[1m126/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8776 - loss: 0.0249\n",
      "\u001b[1m131/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8741 - loss: 0.0250\n",
      "\u001b[1m136/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8709 - loss: 0.0250\n",
      "\u001b[1m141/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8679 - loss: 0.0251\n",
      "\u001b[1m146/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8652 - loss: 0.0251\n",
      "\u001b[1m151/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8627 - loss: 0.0251\n",
      "\u001b[1m156/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8604 - loss: 0.0251\n",
      "\u001b[1m161/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8583 - loss: 0.0251\n",
      "\u001b[1m166/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8565 - loss: 0.0252\n",
      "\u001b[1m171/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8547 - loss: 0.0252\n",
      "\u001b[1m176/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8530 - loss: 0.0252\n",
      "\u001b[1m181/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8511 - loss: 0.0252\n",
      "\u001b[1m186/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8494 - loss: 0.0253\n",
      "\u001b[1m191/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8478 - loss: 0.0253\n",
      "\u001b[1m196/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8464 - loss: 0.0253\n",
      "\u001b[1m200/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8454 - loss: 0.0253\n",
      "\u001b[1m204/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8444 - loss: 0.0253\n",
      "\u001b[1m209/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8432 - loss: 0.0253\n",
      "\u001b[1m214/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8419 - loss: 0.0253\n",
      "\u001b[1m219/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8407 - loss: 0.0254\n",
      "\u001b[1m224/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8397 - loss: 0.0254\n",
      "\u001b[1m229/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8387 - loss: 0.0254\n",
      "\u001b[1m234/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8379 - loss: 0.0254\n",
      "\u001b[1m239/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8370 - loss: 0.0254\n",
      "\u001b[1m244/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8362 - loss: 0.0254\n",
      "\u001b[1m249/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8354 - loss: 0.0254\n",
      "\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8346 - loss: 0.0254\n",
      "\u001b[1m259/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8338 - loss: 0.0254\n",
      "\u001b[1m264/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8330 - loss: 0.0254\n",
      "                                                                                 \n",
      "Epoch 2: val_loss improved from 0.02507 to 0.02316, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8326 - loss: 0.0254 - val_accuracy: 0.9746 - val_loss: 0.0232\n",
      "\n",
      "Epoch 3/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.8750 - loss: 0.0175\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8582 - loss: 0.0141\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8405 - loss: 0.0140\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8222 - loss: 0.0140\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8131 - loss: 0.0143\n",
      "\u001b[1m 25/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8082 - loss: 0.0148\n",
      "\u001b[1m 30/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8032 - loss: 0.0155\n",
      "\u001b[1m 35/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7982 - loss: 0.0160\n",
      "\u001b[1m 40/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7934 - loss: 0.0163\n",
      "\u001b[1m 45/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7889 - loss: 0.0165\n",
      "\u001b[1m 50/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7854 - loss: 0.0167\n",
      "\u001b[1m 55/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7834 - loss: 0.0169\n",
      "\u001b[1m 58/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7829 - loss: 0.0170\n",
      "\u001b[1m 62/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7828 - loss: 0.0171\n",
      "\u001b[1m 67/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7833 - loss: 0.0172\n",
      "\u001b[1m 72/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7846 - loss: 0.0173\n",
      "\u001b[1m 77/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7860 - loss: 0.0174\n",
      "\u001b[1m 82/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7873 - loss: 0.0175\n",
      "\u001b[1m 87/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7885 - loss: 0.0175\n",
      "\u001b[1m 92/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7894 - loss: 0.0177\n",
      "\u001b[1m 97/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7900 - loss: 0.0178\n",
      "\u001b[1m101/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7903 - loss: 0.0179\n",
      "\u001b[1m105/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7904 - loss: 0.0179\n",
      "\u001b[1m110/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7905 - loss: 0.0180\n",
      "\u001b[1m114/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7906 - loss: 0.0181\n",
      "\u001b[1m118/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7907 - loss: 0.0182\n",
      "\u001b[1m123/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7909 - loss: 0.0183\n",
      "\u001b[1m128/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7912 - loss: 0.0183\n",
      "\u001b[1m131/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7914 - loss: 0.0184\n",
      "\u001b[1m135/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7916 - loss: 0.0185\n",
      "\u001b[1m140/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7918 - loss: 0.0185\n",
      "\u001b[1m145/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7918 - loss: 0.0186\n",
      "\u001b[1m150/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7914 - loss: 0.0186\n",
      "\u001b[1m154/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7909 - loss: 0.0187\n",
      "\u001b[1m158/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7901 - loss: 0.0187\n",
      "\u001b[1m163/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7891 - loss: 0.0187\n",
      "\u001b[1m167/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7881 - loss: 0.0187\n",
      "\u001b[1m171/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7872 - loss: 0.0188\n",
      "\u001b[1m176/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7861 - loss: 0.0188\n",
      "\u001b[1m181/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7851 - loss: 0.0188\n",
      "\u001b[1m186/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7841 - loss: 0.0188\n",
      "\u001b[1m190/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7832 - loss: 0.0189\n",
      "\u001b[1m195/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7819 - loss: 0.0189\n",
      "\u001b[1m198/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7810 - loss: 0.0189\n",
      "\u001b[1m202/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7798 - loss: 0.0189\n",
      "\u001b[1m207/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7781 - loss: 0.0189\n",
      "\u001b[1m212/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7763 - loss: 0.0190\n",
      "\u001b[1m217/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7745 - loss: 0.0190\n",
      "\u001b[1m222/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7726 - loss: 0.0190\n",
      "\u001b[1m227/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7707 - loss: 0.0190\n",
      "\u001b[1m232/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7689 - loss: 0.0191\n",
      "\u001b[1m237/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7670 - loss: 0.0191\n",
      "\u001b[1m242/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7649 - loss: 0.0191\n",
      "\u001b[1m247/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7627 - loss: 0.0192\n",
      "\u001b[1m252/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7604 - loss: 0.0192\n",
      "\u001b[1m257/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7580 - loss: 0.0192\n",
      "\u001b[1m260/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7565 - loss: 0.0192\n",
      "\u001b[1m264/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7547 - loss: 0.0192\n",
      "                                                                                 \n",
      "Epoch 3: val_loss did not improve from 0.02316\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.7533 - loss: 0.0193 - val_accuracy: 0.7969 - val_loss: 0.0273\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 16ms/step               \n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step      \n",
      "\n",
      "100%|██████████| 2/2 [02:40<00:00, 80.45s/trial, best loss: -0.4752855495018105] \n",
      "Best hyperparameters: {'batch_size': 1, 'dense_units': 1, 'dropout_rate': 0.20693163905050424, 'embed_dim': 2, 'epochs': 0, 'filters': 2, 'kernel_size': 0, 'max_len': 1}\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter space\n",
    "space = {\n",
    "    'max_len': hp.choice('max_len', [100, 200, 300]),\n",
    "    'embed_dim': hp.choice('embed_dim', [64, 128, 256]),\n",
    "    'filters': hp.choice('filters', [64, 128, 256]),\n",
    "    'kernel_size': hp.choice('kernel_size', [3, 5, 7]),\n",
    "    'dense_units': hp.choice('dense_units', [64, 128, 256]),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'batch_size': hp.choice('batch_size', [32, 64, 128]),\n",
    "    'epochs': hp.choice('epochs', [3]),\n",
    "}\n",
    "\n",
    "def pad_sequences_custom(sequences, max_len):\n",
    "    return np.array([np.pad(seq, (0, max_len - len(seq)), mode='constant')[:max_len] for seq in sequences])\n",
    "\n",
    "def objective(params):\n",
    "    # Cross-validation setup\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    val_scores_cnn = []\n",
    "    \n",
    "    # Define the CNN model\n",
    "    inputs = Input(shape=(params['max_len'],))\n",
    "    embedding = Embedding(input_dim=max_words, output_dim=params['embed_dim'], input_length=params['max_len'])(inputs)\n",
    "    conv1 = Conv1D(filters=params['filters'], kernel_size=params['kernel_size'], activation='relu')(embedding)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "    conv2 = Conv1D(filters=params['filters'], kernel_size=params['kernel_size'], activation='relu')(pool1)\n",
    "    pool2 = GlobalMaxPooling1D()(conv2)\n",
    "    dense1 = Dense(params['dense_units'], activation='relu')(pool2)\n",
    "    dropout = Dropout(params['dropout_rate'])(dense1)\n",
    "    outputs = Dense(6, activation='sigmoid')(dropout)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        print(train_index)\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        # Adjust the input data to match max_len\n",
    "        X_train_fold = pad_sequences_custom(X_train_fold, params['max_len'])\n",
    "        X_val_fold = pad_sequences_custom(X_val_fold, params['max_len'])\n",
    "        \n",
    "        # Define callbacks\n",
    "        checkpoint = ModelCheckpoint('best_model_cnn.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=2, mode='min', verbose=1)\n",
    "\n",
    "        # Train the model\n",
    "        history_cnn = model.fit(X_train_fold, y_train_fold, epochs=params['epochs'], batch_size=params['batch_size'], validation_data=(X_val_fold, y_val_fold), callbacks=[checkpoint, early_stop])\n",
    "\n",
    "        # Evaluate the model\n",
    "        val_preds = model.predict(X_val_fold)\n",
    "        val_preds_binary = (val_preds > 0.5).astype(int)\n",
    "        f1 = f1_score(y_val_fold, val_preds_binary, average='macro')\n",
    "        val_scores_cnn.append(f1)\n",
    "\n",
    "    # Calculate the average F1 score over all folds\n",
    "    avg_f1 = np.mean(val_scores_cnn)\n",
    "    \n",
    "    # Return the negative average F1 score to minimize\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK}\n",
    "\n",
    "# Initialize Trials object to keep track of results\n",
    "trials = Trials()\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "best_cnn = fmin(objective, space, algo=tpe.rand.suggest, max_evals=2, trials=trials)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:', best_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     2     4 ... 12758 12763 12765]            \n",
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:44\u001b[0m 5s/step - accuracy: 0.0078 - loss: 0.6943\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 213ms/step - accuracy: 0.0117 - loss: 0.6907\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 250ms/step - accuracy: 0.0122 - loss: 0.6867\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 246ms/step - accuracy: 0.0135 - loss: 0.6817\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 234ms/step - accuracy: 0.0139 - loss: 0.6755\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 228ms/step - accuracy: 0.0142 - loss: 0.6677\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 224ms/step - accuracy: 0.0149 - loss: 0.6582\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 225ms/step - accuracy: 0.0155 - loss: 0.6475\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 227ms/step - accuracy: 0.0165 - loss: 0.6355\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 225ms/step - accuracy: 0.0182 - loss: 0.6235 \n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 223ms/step - accuracy: 0.0204 - loss: 0.6109\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - accuracy: 0.0226 - loss: 0.5983\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - accuracy: 0.0252 - loss: 0.5860\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 219ms/step - accuracy: 0.0283 - loss: 0.5742\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.0316 - loss: 0.5627\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.0351 - loss: 0.5517\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 217ms/step - accuracy: 0.0393 - loss: 0.5414\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 217ms/step - accuracy: 0.0441 - loss: 0.5317\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 0.0494 - loss: 0.5225\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 0.0552 - loss: 0.5136\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 215ms/step - accuracy: 0.0612 - loss: 0.5052\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 216ms/step - accuracy: 0.0676 - loss: 0.4972\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 216ms/step - accuracy: 0.0740 - loss: 0.4896\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - accuracy: 0.0806 - loss: 0.4826\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - accuracy: 0.0871 - loss: 0.4757\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.0936 - loss: 0.4692\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 0.1001 - loss: 0.4630\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 0.1065 - loss: 0.4570\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.1128 - loss: 0.4513\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.1189 - loss: 0.4458\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 213ms/step - accuracy: 0.1249 - loss: 0.4405\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 213ms/step - accuracy: 0.1307 - loss: 0.4355\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - accuracy: 0.1363 - loss: 0.4305\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - accuracy: 0.1417 - loss: 0.4258\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - accuracy: 0.1469 - loss: 0.4213\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 213ms/step - accuracy: 0.1520 - loss: 0.4168\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 213ms/step - accuracy: 0.1570 - loss: 0.4126\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 212ms/step - accuracy: 0.1619 - loss: 0.4085\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 212ms/step - accuracy: 0.1667 - loss: 0.4045\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - accuracy: 0.1714 - loss: 0.4007\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - accuracy: 0.1760 - loss: 0.3970\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - accuracy: 0.1805 - loss: 0.3935\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - accuracy: 0.1850 - loss: 0.3901\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - accuracy: 0.1893 - loss: 0.3868\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 213ms/step - accuracy: 0.1935 - loss: 0.3836\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 213ms/step - accuracy: 0.1976 - loss: 0.3805\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - accuracy: 0.2016 - loss: 0.3776\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - accuracy: 0.2055 - loss: 0.3747\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - accuracy: 0.2093 - loss: 0.3718\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.2130 - loss: 0.3691\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.2167 - loss: 0.3665\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.2202 - loss: 0.3639\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.2237 - loss: 0.3614\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.2271 - loss: 0.3590\n",
      "                                                     \n",
      "Epoch 1: val_loss improved from inf to 0.16594, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 239ms/step - accuracy: 0.2303 - loss: 0.3567 - val_accuracy: 0.9941 - val_loss: 0.1659\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - accuracy: 0.6328 - loss: 0.1195\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - accuracy: 0.6562 - loss: 0.1261\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.6606 - loss: 0.1296\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 218ms/step - accuracy: 0.6585 - loss: 0.1327\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 212ms/step - accuracy: 0.6546 - loss: 0.1366\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.6495 - loss: 0.1388\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.6447 - loss: 0.1402\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 220ms/step - accuracy: 0.6402 - loss: 0.1412\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - accuracy: 0.6357 - loss: 0.1419 \n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - accuracy: 0.6320 - loss: 0.1422\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - accuracy: 0.6293 - loss: 0.1418\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 225ms/step - accuracy: 0.6270 - loss: 0.1416\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 225ms/step - accuracy: 0.6257 - loss: 0.1415\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 224ms/step - accuracy: 0.6247 - loss: 0.1417\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 223ms/step - accuracy: 0.6237 - loss: 0.1424\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 221ms/step - accuracy: 0.6231 - loss: 0.1430\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 223ms/step - accuracy: 0.6224 - loss: 0.1436\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 224ms/step - accuracy: 0.6218 - loss: 0.1440\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.6213 - loss: 0.1444\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 222ms/step - accuracy: 0.6208 - loss: 0.1449\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.6203 - loss: 0.1452\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.6199 - loss: 0.1455\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.6191 - loss: 0.1457\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.6182 - loss: 0.1460\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.6173 - loss: 0.1464\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.6164 - loss: 0.1468\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - accuracy: 0.6156 - loss: 0.1471\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.6148 - loss: 0.1473\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.6142 - loss: 0.1475\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.6137 - loss: 0.1476\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - accuracy: 0.6133 - loss: 0.1478\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.6130 - loss: 0.1480\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.6127 - loss: 0.1482\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - accuracy: 0.6124 - loss: 0.1484\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.6121 - loss: 0.1486\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 0.6119 - loss: 0.1487\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 0.6117 - loss: 0.1489\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 0.6115 - loss: 0.1490\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 0.6114 - loss: 0.1491\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 0.6114 - loss: 0.1492\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6113 - loss: 0.1493\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6113 - loss: 0.1494\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6113 - loss: 0.1495\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6114 - loss: 0.1496\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.6114 - loss: 0.1497\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.6115 - loss: 0.1498\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.6115 - loss: 0.1499\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.6115 - loss: 0.1500\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.6115 - loss: 0.1501\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6115 - loss: 0.1502\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6115 - loss: 0.1503\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6114 - loss: 0.1504\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6114 - loss: 0.1504\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6114 - loss: 0.1505\n",
      "                                                     \n",
      "Epoch 2: val_loss improved from 0.16594 to 0.16447, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 235ms/step - accuracy: 0.6114 - loss: 0.1506 - val_accuracy: 0.9941 - val_loss: 0.1645\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 247ms/step - accuracy: 0.6094 - loss: 0.1144\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - accuracy: 0.6504 - loss: 0.1372\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - accuracy: 0.6576 - loss: 0.1409\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 211ms/step - accuracy: 0.6621 - loss: 0.1411\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 210ms/step - accuracy: 0.6616 - loss: 0.1426\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.6609 - loss: 0.1439\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - accuracy: 0.6607 - loss: 0.1436 \n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - accuracy: 0.6603 - loss: 0.1444\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - accuracy: 0.6601 - loss: 0.1449\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - accuracy: 0.6599 - loss: 0.1450\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.6594 - loss: 0.1452\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 211ms/step - accuracy: 0.6594 - loss: 0.1455\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 213ms/step - accuracy: 0.6594 - loss: 0.1457\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.6593 - loss: 0.1459\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 219ms/step - accuracy: 0.6592 - loss: 0.1459\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 219ms/step - accuracy: 0.6593 - loss: 0.1461\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.6596 - loss: 0.1463\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 220ms/step - accuracy: 0.6602 - loss: 0.1464\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 222ms/step - accuracy: 0.6611 - loss: 0.1465\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 222ms/step - accuracy: 0.6620 - loss: 0.1466\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 222ms/step - accuracy: 0.6631 - loss: 0.1466\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.6642 - loss: 0.1464\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.6650 - loss: 0.1463\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - accuracy: 0.6656 - loss: 0.1462\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.6660 - loss: 0.1462\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.6662 - loss: 0.1462\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - accuracy: 0.6662 - loss: 0.1461\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.6659 - loss: 0.1461\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.6656 - loss: 0.1461\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.6653 - loss: 0.1462\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.6650 - loss: 0.1461\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - accuracy: 0.6647 - loss: 0.1461\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 221ms/step - accuracy: 0.6645 - loss: 0.1462\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 221ms/step - accuracy: 0.6644 - loss: 0.1462\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 221ms/step - accuracy: 0.6643 - loss: 0.1462\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 0.6643 - loss: 0.1463\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 0.6644 - loss: 0.1463\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 0.6645 - loss: 0.1463\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 221ms/step - accuracy: 0.6646 - loss: 0.1463\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 221ms/step - accuracy: 0.6647 - loss: 0.1463\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6648 - loss: 0.1462\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6649 - loss: 0.1462\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6649 - loss: 0.1461\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - accuracy: 0.6650 - loss: 0.1461\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.6650 - loss: 0.1460\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.6650 - loss: 0.1459\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.6649 - loss: 0.1459\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - accuracy: 0.6649 - loss: 0.1458\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 0.6648 - loss: 0.1458\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6648 - loss: 0.1458\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6647 - loss: 0.1458\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6646 - loss: 0.1458\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.6646 - loss: 0.1458\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6645 - loss: 0.1458\n",
      "                                                     \n",
      "Epoch 3: val_loss improved from 0.16447 to 0.15471, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 239ms/step - accuracy: 0.6644 - loss: 0.1458 - val_accuracy: 0.9941 - val_loss: 0.1547\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 486ms/step\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step   \n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 27ms/step\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 27ms/step\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step\n",
      "\n",
      "[    0     1     2 ... 12762 12763 12764]            \n",
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 218ms/step - accuracy: 0.7031 - loss: 0.1081\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - accuracy: 0.7148 - loss: 0.1036\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - accuracy: 0.7153 - loss: 0.1023\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 200ms/step - accuracy: 0.7176 - loss: 0.1005 \n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 200ms/step - accuracy: 0.7182 - loss: 0.1017\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 201ms/step - accuracy: 0.7202 - loss: 0.1023\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 201ms/step - accuracy: 0.7210 - loss: 0.1029\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 201ms/step - accuracy: 0.7219 - loss: 0.1042\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 201ms/step - accuracy: 0.7217 - loss: 0.1055\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7211 - loss: 0.1065\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 206ms/step - accuracy: 0.7206 - loss: 0.1076\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.7205 - loss: 0.1084\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.7203 - loss: 0.1091\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 216ms/step - accuracy: 0.7201 - loss: 0.1097\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 217ms/step - accuracy: 0.7197 - loss: 0.1104\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 220ms/step - accuracy: 0.7195 - loss: 0.1113\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 223ms/step - accuracy: 0.7189 - loss: 0.1121\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 226ms/step - accuracy: 0.7182 - loss: 0.1129\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.7174 - loss: 0.1137\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.7165 - loss: 0.1144\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 233ms/step - accuracy: 0.7157 - loss: 0.1150\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 233ms/step - accuracy: 0.7147 - loss: 0.1157\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 238ms/step - accuracy: 0.7138 - loss: 0.1163\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 239ms/step - accuracy: 0.7127 - loss: 0.1169\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.7115 - loss: 0.1175\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 240ms/step - accuracy: 0.7102 - loss: 0.1181\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.7089 - loss: 0.1185\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.7077 - loss: 0.1190\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 239ms/step - accuracy: 0.7064 - loss: 0.1194\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 239ms/step - accuracy: 0.7051 - loss: 0.1198\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 238ms/step - accuracy: 0.7040 - loss: 0.1201\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 238ms/step - accuracy: 0.7030 - loss: 0.1204\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 238ms/step - accuracy: 0.7020 - loss: 0.1206\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 241ms/step - accuracy: 0.7011 - loss: 0.1209\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 241ms/step - accuracy: 0.7002 - loss: 0.1212\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 241ms/step - accuracy: 0.6995 - loss: 0.1214\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 239ms/step - accuracy: 0.6987 - loss: 0.1217\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - accuracy: 0.6981 - loss: 0.1219\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - accuracy: 0.6975 - loss: 0.1221\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - accuracy: 0.6971 - loss: 0.1223\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - accuracy: 0.6966 - loss: 0.1225\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - accuracy: 0.6963 - loss: 0.1226\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - accuracy: 0.6961 - loss: 0.1228\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - accuracy: 0.6959 - loss: 0.1229\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - accuracy: 0.6957 - loss: 0.1230\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 232ms/step - accuracy: 0.6955 - loss: 0.1232\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 231ms/step - accuracy: 0.6953 - loss: 0.1233\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 231ms/step - accuracy: 0.6951 - loss: 0.1234\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 230ms/step - accuracy: 0.6948 - loss: 0.1235\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6945 - loss: 0.1236\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6942 - loss: 0.1237\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6938 - loss: 0.1238\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6934 - loss: 0.1239\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.6930 - loss: 0.1240\n",
      "                                                     \n",
      "Epoch 1: val_loss improved from inf to 0.11279, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 244ms/step - accuracy: 0.6926 - loss: 0.1241 - val_accuracy: 0.9971 - val_loss: 0.1128\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - accuracy: 0.6094 - loss: 0.0896\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - accuracy: 0.6172 - loss: 0.0971\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - accuracy: 0.6259 - loss: 0.0974\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - accuracy: 0.6291 - loss: 0.0978\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - accuracy: 0.6320 - loss: 0.0989\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 205ms/step - accuracy: 0.6350 - loss: 0.0998 \n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 205ms/step - accuracy: 0.6382 - loss: 0.1010\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.6407 - loss: 0.1019\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - accuracy: 0.6417 - loss: 0.1022\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - accuracy: 0.6431 - loss: 0.1024\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.6447 - loss: 0.1025\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 208ms/step - accuracy: 0.6460 - loss: 0.1027\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.6476 - loss: 0.1032\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 206ms/step - accuracy: 0.6490 - loss: 0.1034\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.6501 - loss: 0.1036\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 208ms/step - accuracy: 0.6511 - loss: 0.1037\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.6520 - loss: 0.1038\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.6529 - loss: 0.1039\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.6539 - loss: 0.1039\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.6546 - loss: 0.1038\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - accuracy: 0.6555 - loss: 0.1038\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - accuracy: 0.6563 - loss: 0.1038\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.6570 - loss: 0.1037\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.6576 - loss: 0.1037\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.6583 - loss: 0.1036\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.6588 - loss: 0.1036\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.6592 - loss: 0.1036\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - accuracy: 0.6596 - loss: 0.1036\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.6598 - loss: 0.1036\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.6602 - loss: 0.1036\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.6604 - loss: 0.1036\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.6607 - loss: 0.1036\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.6608 - loss: 0.1036\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - accuracy: 0.6609 - loss: 0.1036\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.6610 - loss: 0.1035\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.6611 - loss: 0.1035\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.6611 - loss: 0.1034\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.6610 - loss: 0.1033\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.6610 - loss: 0.1033\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - accuracy: 0.6610 - loss: 0.1032\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.6611 - loss: 0.1031\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.6611 - loss: 0.1031\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.6612 - loss: 0.1030\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.6613 - loss: 0.1029\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.6615 - loss: 0.1028\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.6617 - loss: 0.1027\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.6620 - loss: 0.1026\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.6622 - loss: 0.1025\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.6625 - loss: 0.1024\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6628 - loss: 0.1023\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6631 - loss: 0.1022\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6635 - loss: 0.1021\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6639 - loss: 0.1020\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6642 - loss: 0.1019\n",
      "                                                     \n",
      "Epoch 2: val_loss improved from 0.11279 to 0.09569, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 225ms/step - accuracy: 0.6646 - loss: 0.1018 - val_accuracy: 0.9971 - val_loss: 0.0957\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 267ms/step - accuracy: 0.7578 - loss: 0.0609\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 228ms/step - accuracy: 0.7637 - loss: 0.0594\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 220ms/step - accuracy: 0.7773 - loss: 0.0601\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 218ms/step - accuracy: 0.7861 - loss: 0.0636\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.7933 - loss: 0.0646\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.7976 - loss: 0.0648\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.8010 - loss: 0.0651\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.8034 - loss: 0.0652 \n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.8057 - loss: 0.0653\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - accuracy: 0.8077 - loss: 0.0656\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.8097 - loss: 0.0656\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 214ms/step - accuracy: 0.8115 - loss: 0.0655\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 213ms/step - accuracy: 0.8126 - loss: 0.0654\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 213ms/step - accuracy: 0.8136 - loss: 0.0656\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 212ms/step - accuracy: 0.8141 - loss: 0.0658\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 211ms/step - accuracy: 0.8144 - loss: 0.0659\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.8146 - loss: 0.0659\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.8148 - loss: 0.0662\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 212ms/step - accuracy: 0.8149 - loss: 0.0663\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.8149 - loss: 0.0665\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - accuracy: 0.8149 - loss: 0.0667\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.8149 - loss: 0.0669\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.8148 - loss: 0.0671\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.8145 - loss: 0.0672\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.8142 - loss: 0.0673\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.8138 - loss: 0.0673\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - accuracy: 0.8133 - loss: 0.0674\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - accuracy: 0.8128 - loss: 0.0676\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.8123 - loss: 0.0677\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.8118 - loss: 0.0678\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.8113 - loss: 0.0678\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.8107 - loss: 0.0679\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.8101 - loss: 0.0680\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.8094 - loss: 0.0680\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - accuracy: 0.8087 - loss: 0.0681\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 211ms/step - accuracy: 0.8080 - loss: 0.0681\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - accuracy: 0.8073 - loss: 0.0682\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - accuracy: 0.8066 - loss: 0.0682\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - accuracy: 0.8059 - loss: 0.0682\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - accuracy: 0.8052 - loss: 0.0682\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - accuracy: 0.8045 - loss: 0.0682\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - accuracy: 0.8038 - loss: 0.0682\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.8032 - loss: 0.0682\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.8025 - loss: 0.0681\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - accuracy: 0.8018 - loss: 0.0681\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - accuracy: 0.8012 - loss: 0.0681\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - accuracy: 0.8006 - loss: 0.0680\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.8000 - loss: 0.0680\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.7995 - loss: 0.0679\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7989 - loss: 0.0679\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7984 - loss: 0.0678\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7980 - loss: 0.0678\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7975 - loss: 0.0677\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7971 - loss: 0.0677\n",
      "                                                     \n",
      "Epoch 3: val_loss improved from 0.09569 to 0.08326, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 225ms/step - accuracy: 0.7966 - loss: 0.0676 - val_accuracy: 0.9971 - val_loss: 0.0833\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 39ms/step\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 27ms/step\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step\n",
      "\n",
      "[    0     3     8 ... 12762 12764 12765]            \n",
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - accuracy: 0.8281 - loss: 0.0549\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - accuracy: 0.8086 - loss: 0.0649\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.7908 - loss: 0.0662\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - accuracy: 0.7845 - loss: 0.0671\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.7829 - loss: 0.0678\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 206ms/step - accuracy: 0.7829 - loss: 0.0685 \n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.7834 - loss: 0.0693\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.7843 - loss: 0.0693\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.7840 - loss: 0.0690\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.7838 - loss: 0.0685\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.7833 - loss: 0.0681\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.7818 - loss: 0.0678\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 206ms/step - accuracy: 0.7803 - loss: 0.0676\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 206ms/step - accuracy: 0.7788 - loss: 0.0673\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.7774 - loss: 0.0672\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 208ms/step - accuracy: 0.7761 - loss: 0.0670\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.7751 - loss: 0.0667\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.7743 - loss: 0.0665\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.7738 - loss: 0.0664\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.7735 - loss: 0.0663\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.7734 - loss: 0.0661\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.7735 - loss: 0.0659\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - accuracy: 0.7737 - loss: 0.0657\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.7740 - loss: 0.0656\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.7744 - loss: 0.0655\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.7747 - loss: 0.0654\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.7750 - loss: 0.0653\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.7753 - loss: 0.0653\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - accuracy: 0.7756 - loss: 0.0652\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - accuracy: 0.7760 - loss: 0.0651\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.7763 - loss: 0.0650\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.7766 - loss: 0.0649\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.7769 - loss: 0.0648\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.7772 - loss: 0.0647\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - accuracy: 0.7775 - loss: 0.0645\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - accuracy: 0.7778 - loss: 0.0645\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - accuracy: 0.7781 - loss: 0.0644\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - accuracy: 0.7784 - loss: 0.0643\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - accuracy: 0.7787 - loss: 0.0642\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.7790 - loss: 0.0642\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.7792 - loss: 0.0641\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.7794 - loss: 0.0640\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.7796 - loss: 0.0640\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.7798 - loss: 0.0639\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.7800 - loss: 0.0639\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - accuracy: 0.7803 - loss: 0.0639\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - accuracy: 0.7805 - loss: 0.0639\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.7807 - loss: 0.0638\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.7810 - loss: 0.0638\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7813 - loss: 0.0638\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7816 - loss: 0.0637\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7820 - loss: 0.0637\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7823 - loss: 0.0637\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7827 - loss: 0.0637\n",
      "                                                     \n",
      "Epoch 1: val_loss improved from inf to 0.07079, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 0.7831 - loss: 0.0636 - val_accuracy: 0.9947 - val_loss: 0.0708\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 232ms/step - accuracy: 0.8906 - loss: 0.0335\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - accuracy: 0.8984 - loss: 0.0308\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 224ms/step - accuracy: 0.8993 - loss: 0.0324\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 217ms/step - accuracy: 0.8986 - loss: 0.0344\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 216ms/step - accuracy: 0.8983 - loss: 0.0354\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.8965 - loss: 0.0357\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.8939 - loss: 0.0361 \n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.8910 - loss: 0.0366\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.8881 - loss: 0.0376\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.8853 - loss: 0.0383\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.8827 - loss: 0.0390\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 209ms/step - accuracy: 0.8807 - loss: 0.0395\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - accuracy: 0.8791 - loss: 0.0399\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - accuracy: 0.8778 - loss: 0.0403\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - accuracy: 0.8769 - loss: 0.0407\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.8762 - loss: 0.0410\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 0.8756 - loss: 0.0411\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 217ms/step - accuracy: 0.8751 - loss: 0.0413\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 218ms/step - accuracy: 0.8748 - loss: 0.0415\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 218ms/step - accuracy: 0.8744 - loss: 0.0416\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.8739 - loss: 0.0417\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.8736 - loss: 0.0417\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.8731 - loss: 0.0419\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.8727 - loss: 0.0420\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.8723 - loss: 0.0422\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.8719 - loss: 0.0423\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.8717 - loss: 0.0425\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.8714 - loss: 0.0427\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.8712 - loss: 0.0429\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.8711 - loss: 0.0431\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.8710 - loss: 0.0433\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - accuracy: 0.8709 - loss: 0.0434\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - accuracy: 0.8708 - loss: 0.0436\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.8709 - loss: 0.0438\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.8709 - loss: 0.0440\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 0.8710 - loss: 0.0442\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - accuracy: 0.8712 - loss: 0.0443\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - accuracy: 0.8713 - loss: 0.0444\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - accuracy: 0.8715 - loss: 0.0446\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - accuracy: 0.8716 - loss: 0.0447\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - accuracy: 0.8717 - loss: 0.0448\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - accuracy: 0.8718 - loss: 0.0449\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - accuracy: 0.8718 - loss: 0.0451\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - accuracy: 0.8718 - loss: 0.0452\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.8718 - loss: 0.0453\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.8718 - loss: 0.0453\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.8718 - loss: 0.0454\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.8718 - loss: 0.0455\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.8717 - loss: 0.0456\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.8717 - loss: 0.0457\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.8716 - loss: 0.0457\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.8715 - loss: 0.0458\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.8714 - loss: 0.0459\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.8714 - loss: 0.0459\n",
      "                                                     \n",
      "Epoch 2: val_loss did not improve from 0.07079\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - accuracy: 0.8713 - loss: 0.0460 - val_accuracy: 0.9947 - val_loss: 0.0768\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 38ms/step\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 31ms/step\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step\n",
      "\n",
      "[    1     2     4 ... 12758 12763 12765]                                         \n",
      " 50%|█████     | 1/2 [02:00<02:00, 120.79s/trial, best loss: -0.23911120151419962]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:37\u001b[0m 6s/step - accuracy: 0.0234 - loss: 0.6935\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.0234 - loss: 0.6898\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.0252 - loss: 0.6863\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.0282 - loss: 0.6827\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.0316 - loss: 0.6789\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.0344 - loss: 0.6753\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.0373 - loss: 0.6715\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.0399 - loss: 0.6675\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.0421 - loss: 0.6634\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.0436 - loss: 0.6594\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.0453 - loss: 0.6554\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.0469 - loss: 0.6513\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.0487 - loss: 0.6473\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.0505 - loss: 0.6433\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.0524 - loss: 0.6393\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.0539 - loss: 0.6353\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.0553 - loss: 0.6314\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.0566 - loss: 0.6275\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0579 - loss: 0.6236\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0591 - loss: 0.6197\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.0601 - loss: 0.6158\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.0610 - loss: 0.6120\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.0620 - loss: 0.6082\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0628 - loss: 0.6045\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0635 - loss: 0.6008\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0641 - loss: 0.5972\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0647 - loss: 0.5935\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0652 - loss: 0.5900\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0657 - loss: 0.5864\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.0662 - loss: 0.5829\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.0666 - loss: 0.5794\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.0670 - loss: 0.5760\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.0673 - loss: 0.5726\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.0676 - loss: 0.5692\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0680 - loss: 0.5659\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0683 - loss: 0.5626\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0686 - loss: 0.5594\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0689 - loss: 0.5562\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0692 - loss: 0.5530\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0695 - loss: 0.5498\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0697 - loss: 0.5467\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0700 - loss: 0.5437\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0703 - loss: 0.5406\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0706 - loss: 0.5376\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0710 - loss: 0.5346\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0713 - loss: 0.5317\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0717 - loss: 0.5288\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0720 - loss: 0.5259\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0724 - loss: 0.5231\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0729 - loss: 0.5204\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0734 - loss: 0.5177\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0739 - loss: 0.5150\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0745 - loss: 0.5123\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0751 - loss: 0.5098\n",
      "                                                                                  \n",
      "Epoch 1: val_loss improved from inf to 0.17395, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.0756 - loss: 0.5074 - val_accuracy: 0.9941 - val_loss: 0.1739\n",
      "\n",
      "Epoch 2/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.2969 - loss: 0.2034\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.3066 - loss: 0.2032 \n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.3190 - loss: 0.2004\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.3286 - loss: 0.1970\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.3345 - loss: 0.1950\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.3410 - loss: 0.1953\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3487 - loss: 0.1972\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3549 - loss: 0.1976\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3605 - loss: 0.1971\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3650 - loss: 0.1962\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3688 - loss: 0.1951\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.3717 - loss: 0.1946\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3742 - loss: 0.1940\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3766 - loss: 0.1939\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3787 - loss: 0.1936\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3806 - loss: 0.1936\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.3824 - loss: 0.1934\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3844 - loss: 0.1936\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.3860 - loss: 0.1936\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.3874 - loss: 0.1935\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.3890 - loss: 0.1933\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.3904 - loss: 0.1931\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3918 - loss: 0.1930\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3931 - loss: 0.1930\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3942 - loss: 0.1930\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3953 - loss: 0.1930\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3962 - loss: 0.1930\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3972 - loss: 0.1930\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3981 - loss: 0.1929\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.3991 - loss: 0.1929\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4000 - loss: 0.1928\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4009 - loss: 0.1928\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4017 - loss: 0.1927\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4025 - loss: 0.1927\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4032 - loss: 0.1926\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4040 - loss: 0.1926\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4048 - loss: 0.1925\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4056 - loss: 0.1925\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.4064 - loss: 0.1925\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.4071 - loss: 0.1924\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.4078 - loss: 0.1924\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4084 - loss: 0.1924\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4091 - loss: 0.1924\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4098 - loss: 0.1923\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4105 - loss: 0.1923\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4111 - loss: 0.1923\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4118 - loss: 0.1924\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4124 - loss: 0.1924\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4131 - loss: 0.1924\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4137 - loss: 0.1925\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4143 - loss: 0.1925\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4150 - loss: 0.1925\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4156 - loss: 0.1925\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4163 - loss: 0.1925\n",
      "                                                                                  \n",
      "Epoch 2: val_loss improved from 0.17395 to 0.16939, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.4169 - loss: 0.1925 - val_accuracy: 0.9941 - val_loss: 0.1694\n",
      "\n",
      "Epoch 3/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.3984 - loss: 0.1674\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.4297 - loss: 0.1738 \n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.4427 - loss: 0.1773\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4531 - loss: 0.1813\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4603 - loss: 0.1814\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4656 - loss: 0.1814\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4683 - loss: 0.1818\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.4710 - loss: 0.1815\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.4727 - loss: 0.1818\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.4743 - loss: 0.1824\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.4762 - loss: 0.1825\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.4775 - loss: 0.1826\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4786 - loss: 0.1827\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4798 - loss: 0.1828\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4808 - loss: 0.1829\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4813 - loss: 0.1829\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4819 - loss: 0.1828\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.4823 - loss: 0.1826\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4827 - loss: 0.1824\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4831 - loss: 0.1823\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4836 - loss: 0.1821\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4840 - loss: 0.1819\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4843 - loss: 0.1817\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4846 - loss: 0.1816\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4848 - loss: 0.1814\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4850 - loss: 0.1813\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4852 - loss: 0.1810\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4853 - loss: 0.1807\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4854 - loss: 0.1805\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.4854 - loss: 0.1802\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4852 - loss: 0.1799\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4851 - loss: 0.1797\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4850 - loss: 0.1794\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4848 - loss: 0.1793\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4847 - loss: 0.1792\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4846 - loss: 0.1792\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4845 - loss: 0.1792\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4845 - loss: 0.1792\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4844 - loss: 0.1792\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4843 - loss: 0.1792\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4843 - loss: 0.1792\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4843 - loss: 0.1792\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4843 - loss: 0.1792\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4843 - loss: 0.1792\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4843 - loss: 0.1792\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4844 - loss: 0.1791\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4844 - loss: 0.1791\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4845 - loss: 0.1790\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4846 - loss: 0.1790\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4847 - loss: 0.1789\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4849 - loss: 0.1788\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4850 - loss: 0.1788\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4851 - loss: 0.1787\n",
      "                                                                                  \n",
      "Epoch 3: val_loss improved from 0.16939 to 0.16440, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.4854 - loss: 0.1786 - val_accuracy: 0.9941 - val_loss: 0.1644\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 524ms/step             \n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step               \n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step       \n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step       \n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step       \n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step       \n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step       \n",
      "\n",
      "[    0     1     2 ... 12762 12763 12764]                                         \n",
      "Epoch 1/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.5156 - loss: 0.1658\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5215 - loss: 0.1673\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.5239 - loss: 0.1689\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.5194 - loss: 0.1696\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5158 - loss: 0.1719\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5138 - loss: 0.1730\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5133 - loss: 0.1742\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5115 - loss: 0.1751\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5096 - loss: 0.1754\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5083 - loss: 0.1753\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5075 - loss: 0.1751\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5066 - loss: 0.1744\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.5059 - loss: 0.1736\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5052 - loss: 0.1727\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5046 - loss: 0.1716\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5042 - loss: 0.1707\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5035 - loss: 0.1698\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5028 - loss: 0.1692\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5019 - loss: 0.1687\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5012 - loss: 0.1682\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5005 - loss: 0.1676\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.4997 - loss: 0.1672\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.4990 - loss: 0.1669\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.4983 - loss: 0.1665\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.4976 - loss: 0.1661\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.4969 - loss: 0.1657\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.4963 - loss: 0.1654\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.4957 - loss: 0.1651\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.4952 - loss: 0.1650\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4947 - loss: 0.1648\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4943 - loss: 0.1646\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4940 - loss: 0.1644\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4938 - loss: 0.1642\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4936 - loss: 0.1640\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4935 - loss: 0.1638\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4935 - loss: 0.1636\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4935 - loss: 0.1634\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4936 - loss: 0.1632\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4937 - loss: 0.1630\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4938 - loss: 0.1628\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4940 - loss: 0.1626\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4942 - loss: 0.1624\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4944 - loss: 0.1622\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4946 - loss: 0.1619\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4948 - loss: 0.1617\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4950 - loss: 0.1615\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4952 - loss: 0.1613\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4954 - loss: 0.1610\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.4957 - loss: 0.1608\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4960 - loss: 0.1605\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4963 - loss: 0.1603\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4965 - loss: 0.1601\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4968 - loss: 0.1599\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4970 - loss: 0.1598\n",
      "                                                                                  \n",
      "Epoch 1: val_loss improved from inf to 0.11575, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.4973 - loss: 0.1596 - val_accuracy: 0.9971 - val_loss: 0.1158\n",
      "\n",
      "Epoch 2/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.6094 - loss: 0.1192\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.6113 - loss: 0.1251 \n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.6072 - loss: 0.1276\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6073 - loss: 0.1270\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6074 - loss: 0.1278\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6064 - loss: 0.1276\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6060 - loss: 0.1275\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6039 - loss: 0.1280\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6019 - loss: 0.1283\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6005 - loss: 0.1288\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5989 - loss: 0.1291\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5978 - loss: 0.1294\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5971 - loss: 0.1296\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5964 - loss: 0.1299\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5960 - loss: 0.1303\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5957 - loss: 0.1306\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5953 - loss: 0.1309\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5946 - loss: 0.1309\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5937 - loss: 0.1308\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5929 - loss: 0.1307\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5920 - loss: 0.1305\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5913 - loss: 0.1303\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5905 - loss: 0.1300\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5897 - loss: 0.1299\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5890 - loss: 0.1298\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5882 - loss: 0.1296\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5874 - loss: 0.1295\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5866 - loss: 0.1293\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5858 - loss: 0.1292\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5851 - loss: 0.1290\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5843 - loss: 0.1287\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5836 - loss: 0.1285\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5830 - loss: 0.1282\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5824 - loss: 0.1280\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5818 - loss: 0.1277\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5813 - loss: 0.1274\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5807 - loss: 0.1271\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5801 - loss: 0.1268\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5795 - loss: 0.1265\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5790 - loss: 0.1262\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5785 - loss: 0.1259\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5780 - loss: 0.1256\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5775 - loss: 0.1253\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5770 - loss: 0.1250\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5765 - loss: 0.1247\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5760 - loss: 0.1244\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5754 - loss: 0.1241\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5749 - loss: 0.1238\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5744 - loss: 0.1236\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5738 - loss: 0.1233\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5733 - loss: 0.1230\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5728 - loss: 0.1227\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5723 - loss: 0.1224\n",
      "                                                                                  \n",
      "Epoch 2: val_loss improved from 0.11575 to 0.07148, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.5714 - loss: 0.1219 - val_accuracy: 0.9965 - val_loss: 0.0715\n",
      "\n",
      "Epoch 3/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.5625 - loss: 0.0766\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.5703 - loss: 0.0831\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.5625 - loss: 0.0864\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.5625 - loss: 0.0864\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.5647 - loss: 0.0865\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.5663 - loss: 0.0862\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.5669 - loss: 0.0857\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.5666 - loss: 0.0854\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5668 - loss: 0.0850\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.5663 - loss: 0.0847\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5658 - loss: 0.0842\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5653 - loss: 0.0836\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5647 - loss: 0.0831\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5639 - loss: 0.0825\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5631 - loss: 0.0819\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5622 - loss: 0.0813\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5613 - loss: 0.0807\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5604 - loss: 0.0801\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5593 - loss: 0.0796\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5584 - loss: 0.0790\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5574 - loss: 0.0785\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5565 - loss: 0.0780\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.5556 - loss: 0.0775\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.5549 - loss: 0.0771\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.5542 - loss: 0.0767\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5537 - loss: 0.0763\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5533 - loss: 0.0760\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5529 - loss: 0.0757\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5526 - loss: 0.0754\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5524 - loss: 0.0751\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5523 - loss: 0.0748\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5522 - loss: 0.0746\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5521 - loss: 0.0744\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5521 - loss: 0.0741\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5521 - loss: 0.0739\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5522 - loss: 0.0737\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5523 - loss: 0.0735\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5524 - loss: 0.0733\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5526 - loss: 0.0731\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5528 - loss: 0.0729\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5530 - loss: 0.0727\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5533 - loss: 0.0725\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5536 - loss: 0.0723\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5539 - loss: 0.0721\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5542 - loss: 0.0720\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5545 - loss: 0.0718\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5548 - loss: 0.0716\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5552 - loss: 0.0715\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5556 - loss: 0.0713\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5561 - loss: 0.0712\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5566 - loss: 0.0710\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5571 - loss: 0.0709\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5576 - loss: 0.0708\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5581 - loss: 0.0707\n",
      "                                                                                  \n",
      "Epoch 3: val_loss improved from 0.07148 to 0.06120, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.5586 - loss: 0.0706 - val_accuracy: 0.9900 - val_loss: 0.0612\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step                \n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step                \n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step       \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step       \n",
      "\n",
      "[    0     3     8 ... 12762 12764 12765]                                         \n",
      "Epoch 1/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.6562 - loss: 0.0476\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6680 - loss: 0.0537 \n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.6762 - loss: 0.0556\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.6829 - loss: 0.0556\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.6860 - loss: 0.0559\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6885 - loss: 0.0568\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6913 - loss: 0.0575\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6934 - loss: 0.0585\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6948 - loss: 0.0591\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6962 - loss: 0.0596\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6971 - loss: 0.0598\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6976 - loss: 0.0601\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6981 - loss: 0.0603\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6988 - loss: 0.0603\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6997 - loss: 0.0604\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7008 - loss: 0.0604\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7019 - loss: 0.0604\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7029 - loss: 0.0605\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7039 - loss: 0.0605\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7047 - loss: 0.0605\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7053 - loss: 0.0605\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7060 - loss: 0.0605\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7066 - loss: 0.0605\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7073 - loss: 0.0605\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7079 - loss: 0.0605\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7085 - loss: 0.0605\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7092 - loss: 0.0604\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7099 - loss: 0.0604\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7106 - loss: 0.0604\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7113 - loss: 0.0605\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7120 - loss: 0.0605\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7127 - loss: 0.0605\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7135 - loss: 0.0606\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7142 - loss: 0.0606\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7150 - loss: 0.0606\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7157 - loss: 0.0606\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7164 - loss: 0.0606\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7173 - loss: 0.0606\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7181 - loss: 0.0606\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7189 - loss: 0.0606\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7197 - loss: 0.0606\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7205 - loss: 0.0606\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7213 - loss: 0.0606\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7220 - loss: 0.0606\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7227 - loss: 0.0606\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7234 - loss: 0.0605\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7240 - loss: 0.0605\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7246 - loss: 0.0605\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7252 - loss: 0.0605\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7258 - loss: 0.0605\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7264 - loss: 0.0605\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7269 - loss: 0.0605\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7274 - loss: 0.0605\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7279 - loss: 0.0605\n",
      "                                                                                  \n",
      "Epoch 1: val_loss improved from inf to 0.06312, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.7284 - loss: 0.0604 - val_accuracy: 0.9947 - val_loss: 0.0631\n",
      "\n",
      "Epoch 2/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.7578 - loss: 0.0461\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.7441 - loss: 0.0478\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.7383 - loss: 0.0524\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.7388 - loss: 0.0543\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.7391 - loss: 0.0553\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7394 - loss: 0.0558\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7393 - loss: 0.0557\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7397 - loss: 0.0553\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7403 - loss: 0.0551\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.7409 - loss: 0.0546\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.7420 - loss: 0.0541\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7428 - loss: 0.0536\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7434 - loss: 0.0533\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7438 - loss: 0.0531\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7441 - loss: 0.0529\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7443 - loss: 0.0527\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7445 - loss: 0.0526\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7446 - loss: 0.0524\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7445 - loss: 0.0523\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7443 - loss: 0.0522\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7441 - loss: 0.0520\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7440 - loss: 0.0519\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7440 - loss: 0.0518\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7441 - loss: 0.0517\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7443 - loss: 0.0516\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7446 - loss: 0.0515\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7449 - loss: 0.0515\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7451 - loss: 0.0514\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7453 - loss: 0.0513\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7455 - loss: 0.0512\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7457 - loss: 0.0511\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7458 - loss: 0.0510\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7460 - loss: 0.0508\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7461 - loss: 0.0507\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7462 - loss: 0.0506\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7463 - loss: 0.0505\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7465 - loss: 0.0504\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7467 - loss: 0.0503\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7469 - loss: 0.0502\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7471 - loss: 0.0502\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7473 - loss: 0.0501\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7476 - loss: 0.0500\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7478 - loss: 0.0500\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7481 - loss: 0.0500\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7484 - loss: 0.0499\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7488 - loss: 0.0499\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7491 - loss: 0.0499\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7494 - loss: 0.0499\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7498 - loss: 0.0499\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7501 - loss: 0.0499\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7505 - loss: 0.0498\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7509 - loss: 0.0498\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7513 - loss: 0.0498\n",
      "                                                                                  \n",
      "Epoch 2: val_loss did not improve from 0.06312\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7520 - loss: 0.0498 - val_accuracy: 0.9947 - val_loss: 0.0659\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 24ms/step                \n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step                \n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step       \n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step       \n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step       \n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step       \n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step       \n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step       \n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step       \n",
      "\n",
      "100%|██████████| 2/2 [02:56<00:00, 88.04s/trial, best loss: -0.24998173872662088] \n",
      "Best hyperparameters: {'batch_size': 1, 'dense_units': 0, 'dropout_rate': 0.3021400220523167, 'embed_dim': 1, 'epochs': 0, 'lstm_units': 0, 'max_len': 1, 'recurrent_dropout': 0.28202504542899054}\n"
     ]
    }
   ],
   "source": [
    "# LSTM Parameter Optimization\n",
    "\n",
    "space = {\n",
    "    'max_len': hp.choice('max_len', [100, 200, 300]),\n",
    "    'embed_dim': hp.choice('embed_dim', [64, 128, 256]),\n",
    "    'lstm_units': hp.choice('lstm_units', [32, 64, 128]),\n",
    "    'recurrent_dropout': hp.uniform('recurrent_dropout', 0.1, 0.3),\n",
    "    'dense_units': hp.choice('dense_units', [32, 64, 128]),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.4),\n",
    "    'batch_size': hp.choice('batch_size', [64, 128, 256]),\n",
    "    'epochs': hp.choice('epochs', [3]),\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    # Cross-validation setup\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    val_scores_lstm = []\n",
    "    inputs = Input(shape=(params['max_len'],))\n",
    "    layer = Embedding(input_dim=max_words, output_dim=params['embed_dim'], input_length=params['max_len'])(inputs)\n",
    "    layer = Bidirectional(LSTM(params['lstm_units'], return_sequences=True, recurrent_dropout=params['recurrent_dropout']))(layer)\n",
    "    layer = GlobalMaxPool1D()(layer)\n",
    "    layer = Dropout(params['dropout_rate'])(layer)\n",
    "    layer = Dense(params['dense_units'], activation='relu')(layer)\n",
    "    layer = Dropout(params['dropout_rate'])(layer)\n",
    "    layer = Dense(6, activation='sigmoid')(layer)\n",
    "    model = Model(inputs=inputs, outputs=layer)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        print(train_index)\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        # Adjust the input data to match max_len\n",
    "        X_train_fold = pad_sequences_custom(X_train_fold, params['max_len'])\n",
    "        X_val_fold = pad_sequences_custom(X_val_fold, params['max_len'])\n",
    "    \n",
    "        checkpoint = ModelCheckpoint('save_best_model_lstm.keras', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=1)\n",
    "\n",
    "        history_lstm = model.fit(X_train_fold, y_train_fold, batch_size=params['batch_size'], epochs=params['epochs'], validation_split=0.2, callbacks=[checkpoint, early_stop])\n",
    "\n",
    "        # Evaluate the model\n",
    "        val_preds = model.predict(X_val_fold)\n",
    "        val_preds_binary = (val_preds > 0.5).astype(int)\n",
    "        f1 = f1_score(y_val_fold, val_preds_binary, average='macro')\n",
    "        val_scores_lstm.append(f1)\n",
    "\n",
    "    # Calculate the average F1 score over all folds\n",
    "    avg_f1 = np.mean(val_scores_lstm)\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_lstm = fmin(objective, space, algo=tpe.rand.suggest, max_evals=2, trials=trials)\n",
    "\n",
    "print('Best hyperparameters:', best_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters CNN: {'batch_size': 128, 'dense_units': 64, 'dropout_rate': 0.20693163905050424, 'embed_dim': 256, 'epochs': 3, 'filters': 256, 'kernel_size': 3, 'max_len': 200}\n",
      "Best hyperparameters CNN: {'batch_size': 128, 'dense_units': 32, 'dropout_rate': 0.3021400220523167, 'embed_dim': 128, 'epochs': 3, 'lstm_units': 32, 'max_len': 200, 'recurrent_dropout': 0.28202504542899054}\n"
     ]
    }
   ],
   "source": [
    "# Map best indices to actual values\n",
    "best_cnn['max_len'] = [100, 200, 300][best_cnn['max_len']]\n",
    "best_cnn['embed_dim'] = [64, 128, 256][best_cnn['embed_dim']]\n",
    "best_cnn['kernel_size'] = [3, 5, 7][best_cnn['kernel_size']]\n",
    "best_cnn['filters'] = [64, 128, 256][best_cnn['filters']]\n",
    "best_cnn['dense_units'] = [32, 64, 128][best_cnn['dense_units']]\n",
    "best_cnn['batch_size'] = [64, 128, 256][best_cnn['batch_size']]\n",
    "best_cnn['epochs'] = [3][best_cnn['epochs']]  # Only one choice, but maintaining structure\n",
    "\n",
    "print('Best hyperparameters CNN:', best_cnn)\n",
    "\n",
    "# Map best indices to actual values\n",
    "best_lstm['max_len'] = [100, 200, 300][best_lstm['max_len']]\n",
    "best_lstm['embed_dim'] = [64, 128, 256][best_lstm['embed_dim']]\n",
    "best_lstm['lstm_units'] = [32, 64, 128][best_lstm['lstm_units']]\n",
    "best_lstm['dense_units'] = [32, 64, 128][best_lstm['dense_units']]\n",
    "best_lstm['batch_size'] = [64, 128, 256][best_lstm['batch_size']]\n",
    "best_lstm['epochs'] = [3][best_lstm['epochs']]  # Only one choice, but maintaining structure\n",
    "\n",
    "print('Best hyperparameters LSTM:', best_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_scores_lstm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mval_scores_lstm\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_scores_lstm' is not defined"
     ]
    }
   ],
   "source": [
    "print(val_scores_lstm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
