{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T23:56:26.695066Z",
     "start_time": "2024-06-19T23:55:43.247199Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Radosz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Radosz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Radosz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'prepare_data' from 'd:\\\\Projects\\\\toxic-comment-classification\\\\prepare_data.py'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Bidirectional, GlobalMaxPool1D, LSTM\n",
    "\n",
    "import prepare_data as prep\n",
    "from prepare_data import DataPreprocessor\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reload(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T23:57:01.304114Z",
     "start_time": "2024-06-19T23:56:32.377396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id                                       comment_text  \\\n",
      "0       0000997932d777bf  explanation\\nwhy the edits made under my usern...   \n",
      "1       000103f0d9cfb60f  d'aww! he matches this background colour i'm s...   \n",
      "2       000113f07ec002fd  hey man, i'm really not trying to edit war. it...   \n",
      "3       0001b41b1c6bb37e  \"\\nmore\\ni can't make any real suggestions on ...   \n",
      "4       0001d958c54c6e35  you, sir, are my hero. any chance you remember...   \n",
      "...                  ...                                                ...   \n",
      "159566  ffe987279560d7ff  \":::::and for the second time of asking, when ...   \n",
      "159567  ffea4adeee384e90  you should be ashamed of yourself \\n\\nthat is ...   \n",
      "159568  ffee36eab5c267c9  spitzer \\n\\numm, theres no actual article for ...   \n",
      "159569  fff125370e4aaaf3  and it looks like it was actually you who put ...   \n",
      "159570  fff46fc426af1f9a  \"\\nand ... i really don't think you understand...   \n",
      "\n",
      "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0           0             0        0       0       0              0  \n",
      "1           0             0        0       0       0              0  \n",
      "2           0             0        0       0       0              0  \n",
      "3           0             0        0       0       0              0  \n",
      "4           0             0        0       0       0              0  \n",
      "...       ...           ...      ...     ...     ...            ...  \n",
      "159566      0             0        0       0       0              0  \n",
      "159567      0             0        0       0       0              0  \n",
      "159568      0             0        0       0       0              0  \n",
      "159569      0             0        0       0       0              0  \n",
      "159570      0             0        0       0       0              0  \n",
      "\n",
      "[159571 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "prepData = DataPreprocessor(\"jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "\n",
    "prepData.load_data()\n",
    "prepData.preprocess_data()\n",
    "X, y = prepData.get_XY()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T23:57:10.932793Z",
     "start_time": "2024-06-19T23:57:07.958084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (127656, 150)\n",
      "X_test (31915, 150)\n",
      "y_train (127656, 6)\n",
      "y_test (31915, 6)\n"
     ]
    }
   ],
   "source": [
    "# Zmniana wartości klas w binarne\n",
    "\n",
    "mlb = LabelBinarizer()\n",
    "y_binary = mlb.fit_transform(y)\n",
    "\n",
    "X_notoken = X\n",
    "\n",
    "# Tokenizacja danych tekstowych\n",
    "max_words = 20000\n",
    "max_len = 150\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_seq, maxlen=max_len)\n",
    "\n",
    "# Podział metodą train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"y_test\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (12766, 150)\n",
      "X_test (3192, 150)\n",
      "y_train (12766, 6)\n",
      "y_test (3192, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train2=X_train[::10]\n",
    "y_train2=y_train[::10]\n",
    "X_test2=X_test[::10]\n",
    "y_test2=y_test[::10]\n",
    "\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T22:03:14.764839Z",
     "start_time": "2024-06-19T22:03:14.676098Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LR preparation\n",
    "\n",
    "# Dodać walidację krzyżową do każdego modelu oraz testy statystyczne\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions = {\n",
    "    'C': uniform(loc=0.01, scale=10),\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "random_search_LR = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(solver='lbfgs', max_iter=1000, verbose=True),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=4,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "def LR_Training_CV(y_label, X_padded, tokenizer, k=5):\n",
    "    # Perform parameter search on the entire dataset\n",
    "    X_text = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_padded]\n",
    "    \n",
    "    tfidf_vec = TfidfVectorizer(max_df=0.7)\n",
    "    X_vec = tfidf_vec.fit_transform(X_text)\n",
    "    \n",
    "    random_search_LR.fit(X_vec, y_label.values.ravel())\n",
    "    best_params = random_search_LR.best_params_\n",
    "    print('Best parameters from RandomizedSearchCV:', best_params)\n",
    "    \n",
    "    # Use the best parameters for cross-validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_y_tests = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_padded):\n",
    "        X_train_LR, X_test_LR = X_padded[train_index], X_padded[test_index]\n",
    "        y_train_LR, y_test_LR = y_label.iloc[train_index], y_label.iloc[test_index]\n",
    "        \n",
    "        X_train_LR = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_train_LR]\n",
    "        X_test_LR = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_test_LR]\n",
    "        \n",
    "        tfidf_vec = TfidfVectorizer(max_df=0.7)\n",
    "        X_train_LR_vec = tfidf_vec.fit_transform(X_train_LR)\n",
    "        X_test_LR_vec = tfidf_vec.transform(X_test_LR)\n",
    "        \n",
    "        model = LogisticRegression(solver='lbfgs', max_iter=1000, verbose=True, **best_params)\n",
    "        model.fit(X_train_LR_vec, y_train_LR.values.ravel())\n",
    "        \n",
    "        predictions = model.predict(X_test_LR_vec)\n",
    "        \n",
    "        all_predictions.extend(predictions)\n",
    "        all_y_tests.extend(y_test_LR.values)\n",
    "    \n",
    "    print(confusion_matrix(all_y_tests, all_predictions))\n",
    "    print(classification_report(all_y_tests, all_predictions))\n",
    "    accuracy = accuracy_score(all_y_tests, all_predictions)\n",
    "    report = classification_report(all_y_tests, all_predictions, output_dict=True)\n",
    "\n",
    "    return accuracy, report['weighted avg']['precision'], report['weighted avg']['recall'], report['weighted avg']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T22:07:57.527035Z",
     "start_time": "2024-06-19T22:07:57.493046Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NB Preparation\n",
    "\n",
    "param_distributions = {\n",
    "    'alpha': uniform(loc=0, scale=1),\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "random_search_NB = RandomizedSearchCV(\n",
    "    estimator=MultinomialNB(),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=4,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "\n",
    "def NB_Training_CV(y_label, X_padded, tokenizer, k=5):\n",
    "    # Perform parameter search on the entire dataset\n",
    "    X_text = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_padded]\n",
    "\n",
    "    tfidf_vec = TfidfVectorizer(max_df=0.7)\n",
    "    X_vec = tfidf_vec.fit_transform(X_text)\n",
    "\n",
    "    random_search_NB.fit(X_vec, y_label.values.ravel())\n",
    "    best_params = random_search_NB.best_params_\n",
    "    print('Best parameters from RandomizedSearchCV:', best_params)\n",
    "\n",
    "    # Use the best parameters for cross-validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    all_predictions = []\n",
    "    all_y_tests = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_padded):\n",
    "        X_train_NB, X_test_NB = X_padded[train_index], X_padded[test_index]\n",
    "        y_train_NB, y_test_NB = y_label.iloc[train_index], y_label.iloc[test_index]\n",
    "\n",
    "        X_train_NB = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_train_NB]\n",
    "        X_test_NB = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_test_NB]\n",
    "\n",
    "        tfidf_vec = TfidfVectorizer(max_df=0.7)\n",
    "        X_train_NB_vec = tfidf_vec.fit_transform(X_train_NB)\n",
    "        X_test_NB_vec = tfidf_vec.transform(X_test_NB)\n",
    "\n",
    "        model = MultinomialNB(**best_params)\n",
    "        model.fit(X_train_NB_vec, y_train_NB.values.ravel())\n",
    "\n",
    "        predictions = model.predict(X_test_NB_vec)\n",
    "\n",
    "        all_predictions.extend(predictions)\n",
    "        all_y_tests.extend(y_test_NB.values)\n",
    "\n",
    "    print(confusion_matrix(all_y_tests, all_predictions))\n",
    "    print(classification_report(all_y_tests, all_predictions))\n",
    "\n",
    "     # Calculate and return metrics\n",
    "    report = classification_report(all_y_tests, all_predictions, output_dict=True)\n",
    "    accuracy = accuracy_score(all_y_tests, all_predictions)\n",
    "    print('Accuracy:', accuracy)\n",
    "    return accuracy, report['weighted avg']['precision'], report['weighted avg']['recall'], report['weighted avg']['f1-score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic comments NB:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.3745401188473625, 'fit_prior': True}\n",
      "[[143447    830]\n",
      " [  7270   8024]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    144277\n",
      "           1       0.91      0.52      0.66     15294\n",
      "\n",
      "    accuracy                           0.95    159571\n",
      "   macro avg       0.93      0.76      0.82    159571\n",
      "weighted avg       0.95      0.95      0.94    159571\n",
      "\n",
      "Accuracy: 0.9492388967920237\n",
      "toxic comments LR:\n",
      "Best parameters from RandomizedSearchCV: {'C': 7.3299394181140505, 'penalty': 'l2'}\n",
      "[[142621   1656]\n",
      " [  4909  10385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    144277\n",
      "           1       0.86      0.68      0.76     15294\n",
      "\n",
      "    accuracy                           0.96    159571\n",
      "   macro avg       0.91      0.83      0.87    159571\n",
      "weighted avg       0.96      0.96      0.96    159571\n",
      "\n",
      "severe_toxic comments NB:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.1834347898661638, 'fit_prior': False}\n",
      "[[146137  11839]\n",
      " [   122   1473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    157976\n",
      "           1       0.11      0.92      0.20      1595\n",
      "\n",
      "    accuracy                           0.93    159571\n",
      "   macro avg       0.55      0.92      0.58    159571\n",
      "weighted avg       0.99      0.93      0.95    159571\n",
      "\n",
      "Accuracy: 0.9250427709295549\n",
      "severe_toxic comments LR:\n",
      "Best parameters from RandomizedSearchCV: {'C': 9.51714306409916, 'penalty': 'l2'}\n",
      "[[157524    452]\n",
      " [  1114    481]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    157976\n",
      "           1       0.52      0.30      0.38      1595\n",
      "\n",
      "    accuracy                           0.99    159571\n",
      "   macro avg       0.75      0.65      0.69    159571\n",
      "weighted avg       0.99      0.99      0.99    159571\n",
      "\n",
      "obscene comments NB:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.3745401188473625, 'fit_prior': True}\n",
      "[[150524    598]\n",
      " [  3999   4450]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98    151122\n",
      "           1       0.88      0.53      0.66      8449\n",
      "\n",
      "    accuracy                           0.97    159571\n",
      "   macro avg       0.93      0.76      0.82    159571\n",
      "weighted avg       0.97      0.97      0.97    159571\n",
      "\n",
      "Accuracy: 0.9711915072287571\n",
      "obscene comments LR:\n",
      "Best parameters from RandomizedSearchCV: {'C': 9.51714306409916, 'penalty': 'l2'}\n",
      "[[150240    882]\n",
      " [  2567   5882]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    151122\n",
      "           1       0.87      0.70      0.77      8449\n",
      "\n",
      "    accuracy                           0.98    159571\n",
      "   macro avg       0.93      0.85      0.88    159571\n",
      "weighted avg       0.98      0.98      0.98    159571\n",
      "\n",
      "threat comments NB:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.1834347898661638, 'fit_prior': False}\n",
      "[[148506  10587]\n",
      " [   111    367]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97    159093\n",
      "           1       0.03      0.77      0.06       478\n",
      "\n",
      "    accuracy                           0.93    159571\n",
      "   macro avg       0.52      0.85      0.51    159571\n",
      "weighted avg       1.00      0.93      0.96    159571\n",
      "\n",
      "Accuracy: 0.93295774294828\n",
      "threat comments LR:\n",
      "Best parameters from RandomizedSearchCV: {'C': 9.51714306409916, 'penalty': 'l2'}\n",
      "[[159027     66]\n",
      " [   382     96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    159093\n",
      "           1       0.59      0.20      0.30       478\n",
      "\n",
      "    accuracy                           1.00    159571\n",
      "   macro avg       0.80      0.60      0.65    159571\n",
      "weighted avg       1.00      1.00      1.00    159571\n",
      "\n",
      "insult comments NB:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.3745401188473625, 'fit_prior': True}\n",
      "[[150866    828]\n",
      " [  4359   3518]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    151694\n",
      "           1       0.81      0.45      0.58      7877\n",
      "\n",
      "    accuracy                           0.97    159571\n",
      "   macro avg       0.89      0.72      0.78    159571\n",
      "weighted avg       0.96      0.97      0.96    159571\n",
      "\n",
      "Accuracy: 0.9674940935382995\n",
      "insult comments LR:\n",
      "Best parameters from RandomizedSearchCV: {'C': 7.3299394181140505, 'penalty': 'l2'}\n",
      "[[150438   1256]\n",
      " [  3356   4521]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    151694\n",
      "           1       0.78      0.57      0.66      7877\n",
      "\n",
      "    accuracy                           0.97    159571\n",
      "   macro avg       0.88      0.78      0.82    159571\n",
      "weighted avg       0.97      0.97      0.97    159571\n",
      "\n",
      "identity_hate comments NB:\n",
      "Best parameters from RandomizedSearchCV: {'alpha': 0.1834347898661638, 'fit_prior': False}\n",
      "[[143381  14785]\n",
      " [   188   1217]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95    158166\n",
      "           1       0.08      0.87      0.14      1405\n",
      "\n",
      "    accuracy                           0.91    159571\n",
      "   macro avg       0.54      0.89      0.55    159571\n",
      "weighted avg       0.99      0.91      0.94    159571\n",
      "\n",
      "Accuracy: 0.9061671606996259\n",
      "identity_hate comments LR:\n",
      "Best parameters from RandomizedSearchCV: {'C': 7.3299394181140505, 'penalty': 'l2'}\n",
      "[[157941    225]\n",
      " [  1016    389]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    158166\n",
      "           1       0.63      0.28      0.39      1405\n",
      "\n",
      "    accuracy                           0.99    159571\n",
      "   macro avg       0.81      0.64      0.69    159571\n",
      "weighted avg       0.99      0.99      0.99    159571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    'Regresja_Liniowa': {'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0},\n",
    "    'Naive_Bayes': {'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0},\n",
    "    'CNN': {'accuracy': 0.90, 'precision': 0.87, 'recall': 0.85, 'f1_score': 0.86},\n",
    "    'LSTM': {'accuracy': 0.89, 'precision': 0.85, 'recall': 0.84, 'f1_score': 0.84}\n",
    "}\n",
    "\n",
    "\n",
    "categories = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "for category in categories:\n",
    "    print(f\"{category} comments NB:\")\n",
    "    accuracy, precision, recall, f1_score = NB_Training_CV(y[[category]], X_padded, tokenizer)\n",
    "    results['Naive_Bayes']['accuracy'] += accuracy\n",
    "    results['Naive_Bayes']['precision'] += precision\n",
    "    results['Naive_Bayes']['recall'] += recall\n",
    "    results['Naive_Bayes']['f1_score'] += f1_score\n",
    "\n",
    "    print(f\"{category} comments LR:\")\n",
    "    accuracy, precision, recall, f1_score = LR_Training_CV(y[[category]], X_padded, tokenizer)\n",
    "    results['Regresja_Liniowa']['accuracy'] += accuracy\n",
    "    results['Regresja_Liniowa']['precision'] += precision\n",
    "    results['Regresja_Liniowa']['recall'] += recall\n",
    "    results['Regresja_Liniowa']['f1_score'] += f1_score\n",
    "\n",
    "# Średnie wyniki dla wszystkich kategorii\n",
    "results['Naive_Bayes']['accuracy'] /= len(categories)\n",
    "results['Naive_Bayes']['precision'] /= len(categories)\n",
    "results['Naive_Bayes']['recall'] /= len(categories)\n",
    "results['Naive_Bayes']['f1_score'] /= len(categories)\n",
    "results['Regresja_Liniowa']['accuracy'] /= len(categories)\n",
    "results['Regresja_Liniowa']['precision'] /= len(categories)\n",
    "results['Regresja_Liniowa']['recall'] /= len(categories)\n",
    "results['Regresja_Liniowa']['f1_score'] /= len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Naive Bayes:\n",
      "{'accuracy': 0.9420153620227568, 'precision': 0.9762886514003092, 'recall': 0.9420153620227568, 'f1_score': 0.9554274681219587}\n",
      "Results for Logistic Regression:\n",
      "{'accuracy': 0.9813238829946127, 'precision': 0.9795794651889684, 'recall': 0.9813238829946127, 'f1_score': 0.9798306779190793}\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for Naive Bayes:\")\n",
    "print(results['Naive_Bayes'])\n",
    "print(\"Results for Logistic Regression:\")\n",
    "print(results['Regresja_Liniowa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T21:06:03.838974Z",
     "start_time": "2024-06-19T21:06:03.817972Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_pred = tf.round(tf.clip_by_value(y_pred, 0, 1))\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred)\n",
    "    false_positives = tf.reduce_sum((1 - y_true) * y_pred)\n",
    "    false_negatives = tf.reduce_sum(y_true * (1 - y_pred))\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives + tf.keras.backend.epsilon())\n",
    "    recall = true_positives / (true_positives + false_negatives + tf.keras.backend.epsilon())\n",
    "    \n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:13:01.622785Z",
     "start_time": "2024-06-20T00:06:19.165310Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     2     4 ... 12758 12763 12765]            \n",
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:16\u001b[0m 2s/step - accuracy: 0.7188 - loss: 0.6837\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 77ms/step - accuracy: 0.6953 - loss: 0.6718\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 77ms/step - accuracy: 0.6753 - loss: 0.6595\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - accuracy: 0.6598 - loss: 0.6457\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.6472 - loss: 0.6283\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.6409 - loss: 0.6084\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.6387 - loss: 0.5866 \n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.6384 - loss: 0.5687\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.6385 - loss: 0.5515\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.6396 - loss: 0.5360\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.6423 - loss: 0.5211\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.6453 - loss: 0.5073\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.6485 - loss: 0.4941\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.6518 - loss: 0.4814\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.6544 - loss: 0.4700\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.6564 - loss: 0.4595\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.6583 - loss: 0.4497\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.6601 - loss: 0.4405\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6610 - loss: 0.4319\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6615 - loss: 0.4238\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6612 - loss: 0.4161\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6604 - loss: 0.4089\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6589 - loss: 0.4020\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6569 - loss: 0.3956\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6547 - loss: 0.3896\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6524 - loss: 0.3837\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6503 - loss: 0.3782\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6481 - loss: 0.3729\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6460 - loss: 0.3680\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6442 - loss: 0.3632\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6425 - loss: 0.3586\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.6413 - loss: 0.3542\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6403 - loss: 0.3501\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6396 - loss: 0.3461\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6391 - loss: 0.3422\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6388 - loss: 0.3385\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6387 - loss: 0.3350\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6387 - loss: 0.3316\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6389 - loss: 0.3283\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6392 - loss: 0.3252\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.6395 - loss: 0.3223\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6399 - loss: 0.3194\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6403 - loss: 0.3168\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6408 - loss: 0.3143\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6412 - loss: 0.3119\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6416 - loss: 0.3096\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6420 - loss: 0.3074\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6424 - loss: 0.3053\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6428 - loss: 0.3033\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6431 - loss: 0.3014\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6435 - loss: 0.2995\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6439 - loss: 0.2977\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6443 - loss: 0.2959\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6446 - loss: 0.2941\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6450 - loss: 0.2923\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6453 - loss: 0.2906\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.6457 - loss: 0.2889\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6461 - loss: 0.2872\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6465 - loss: 0.2856\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6470 - loss: 0.2840\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6475 - loss: 0.2825\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6480 - loss: 0.2810\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6486 - loss: 0.2795\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6492 - loss: 0.2781\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6499 - loss: 0.2767\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6506 - loss: 0.2753\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6513 - loss: 0.2739\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6521 - loss: 0.2726\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6529 - loss: 0.2713\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6537 - loss: 0.2701\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6545 - loss: 0.2688\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6553 - loss: 0.2676\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6561 - loss: 0.2664\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6569 - loss: 0.2653\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6577 - loss: 0.2641\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6584 - loss: 0.2630\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6591 - loss: 0.2619\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6598 - loss: 0.2609\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6605 - loss: 0.2598\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6611 - loss: 0.2588\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6617 - loss: 0.2577\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6623 - loss: 0.2567\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6628 - loss: 0.2558\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6633 - loss: 0.2548\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6638 - loss: 0.2539\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6642 - loss: 0.2529\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6647 - loss: 0.2520\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6651 - loss: 0.2511\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6656 - loss: 0.2502\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6661 - loss: 0.2494\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6665 - loss: 0.2485\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6670 - loss: 0.2477\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6675 - loss: 0.2469\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6680 - loss: 0.2461\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6684 - loss: 0.2453\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6689 - loss: 0.2445\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6694 - loss: 0.2437\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6699 - loss: 0.2430\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6704 - loss: 0.2422\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6709 - loss: 0.2415\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6714 - loss: 0.2408\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6719 - loss: 0.2401\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6724 - loss: 0.2394\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6728 - loss: 0.2387\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6733 - loss: 0.2380\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6737 - loss: 0.2373\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6742 - loss: 0.2366\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6747 - loss: 0.2360\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6751 - loss: 0.2353\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6756 - loss: 0.2347\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6761 - loss: 0.2341\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6765 - loss: 0.2335\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6770 - loss: 0.2328\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6774 - loss: 0.2322\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6779 - loss: 0.2316\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6783 - loss: 0.2310\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6787 - loss: 0.2304\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6791 - loss: 0.2298\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6794 - loss: 0.2293\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.6798 - loss: 0.2287\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6801 - loss: 0.2281\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6805 - loss: 0.2276\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6808 - loss: 0.2270\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6811 - loss: 0.2264\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6815 - loss: 0.2259\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6818 - loss: 0.2253\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6822 - loss: 0.2248\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6825 - loss: 0.2243\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6829 - loss: 0.2237\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6833 - loss: 0.2232\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6836 - loss: 0.2227\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6840 - loss: 0.2222\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6844 - loss: 0.2217\n",
      "                                                     \n",
      "Epoch 1: val_loss improved from inf to 0.09657, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 92ms/step - accuracy: 0.6848 - loss: 0.2212 - val_accuracy: 0.9948 - val_loss: 0.0966\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 107ms/step - accuracy: 0.8594 - loss: 0.1210\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 127ms/step - accuracy: 0.8398 - loss: 0.1091\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 115ms/step - accuracy: 0.8203 - loss: 0.0999\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 105ms/step - accuracy: 0.7979 - loss: 0.0981\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.7752 - loss: 0.0957\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.7558 - loss: 0.0944 \n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - accuracy: 0.7390 - loss: 0.0924\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.7240 - loss: 0.0908\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - accuracy: 0.7103 - loss: 0.0897\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.6991 - loss: 0.0898\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.6901 - loss: 0.0900\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.6830 - loss: 0.0907\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.6773 - loss: 0.0910\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.6734 - loss: 0.0914\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.6711 - loss: 0.0916\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.6700 - loss: 0.0919\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.6696 - loss: 0.0922\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.6696 - loss: 0.0924\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.6700 - loss: 0.0926\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.6708 - loss: 0.0927\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.6715 - loss: 0.0928\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.6720 - loss: 0.0928\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.6725 - loss: 0.0927\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6730 - loss: 0.0926 \n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6735 - loss: 0.0924\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6740 - loss: 0.0922\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6746 - loss: 0.0921\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6753 - loss: 0.0920\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6761 - loss: 0.0920\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6769 - loss: 0.0919\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6780 - loss: 0.0918\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6791 - loss: 0.0917\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.6803 - loss: 0.0915\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.6817 - loss: 0.0914\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.6832 - loss: 0.0912\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.6847 - loss: 0.0910\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.6863 - loss: 0.0908\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.6880 - loss: 0.0906\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.6896 - loss: 0.0904\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.6913 - loss: 0.0901\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.6930 - loss: 0.0899\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6947 - loss: 0.0897\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6963 - loss: 0.0894\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6979 - loss: 0.0892\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6995 - loss: 0.0890\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7010 - loss: 0.0888\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7025 - loss: 0.0885\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7041 - loss: 0.0883\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7056 - loss: 0.0881\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.7071 - loss: 0.0879\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.7086 - loss: 0.0876\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7101 - loss: 0.0874\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7116 - loss: 0.0872\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7131 - loss: 0.0870\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7144 - loss: 0.0868\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7157 - loss: 0.0865\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7170 - loss: 0.0863\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7182 - loss: 0.0861\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7193 - loss: 0.0859\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.7204 - loss: 0.0857\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.7215 - loss: 0.0855\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.7226 - loss: 0.0852\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.7237 - loss: 0.0850\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.7247 - loss: 0.0848\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.7258 - loss: 0.0846\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.7268 - loss: 0.0844\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7279 - loss: 0.0842\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7289 - loss: 0.0840\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7300 - loss: 0.0838\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7311 - loss: 0.0837\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7321 - loss: 0.0835\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7332 - loss: 0.0833\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.7342 - loss: 0.0831\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.7353 - loss: 0.0829\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.7363 - loss: 0.0828\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.7374 - loss: 0.0826\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.7384 - loss: 0.0824\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7395 - loss: 0.0823\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7405 - loss: 0.0821\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7416 - loss: 0.0820\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7426 - loss: 0.0818\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7437 - loss: 0.0817\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7447 - loss: 0.0816\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7458 - loss: 0.0814\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7468 - loss: 0.0813\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7478 - loss: 0.0812\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7489 - loss: 0.0810\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7499 - loss: 0.0809\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7509 - loss: 0.0808\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7519 - loss: 0.0806\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7529 - loss: 0.0805\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7539 - loss: 0.0804\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7549 - loss: 0.0803\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7559 - loss: 0.0802\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7569 - loss: 0.0801\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7578 - loss: 0.0800\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7588 - loss: 0.0799\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7597 - loss: 0.0798\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7606 - loss: 0.0797\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7615 - loss: 0.0796\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7624 - loss: 0.0795\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7633 - loss: 0.0794\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7641 - loss: 0.0793\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7649 - loss: 0.0792\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7657 - loss: 0.0791\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7665 - loss: 0.0790\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7673 - loss: 0.0789\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7681 - loss: 0.0788\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7688 - loss: 0.0787\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7696 - loss: 0.0786\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7703 - loss: 0.0785\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7711 - loss: 0.0785\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7718 - loss: 0.0784\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7725 - loss: 0.0783\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7733 - loss: 0.0782\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7740 - loss: 0.0781\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7747 - loss: 0.0780\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7754 - loss: 0.0779\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7762 - loss: 0.0778\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7769 - loss: 0.0777\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7776 - loss: 0.0777\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7783 - loss: 0.0776\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7790 - loss: 0.0775\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7797 - loss: 0.0774\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7804 - loss: 0.0773\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7811 - loss: 0.0773\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7818 - loss: 0.0772\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7825 - loss: 0.0771\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7832 - loss: 0.0770\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7839 - loss: 0.0770\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7846 - loss: 0.0769\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7852 - loss: 0.0768\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7859 - loss: 0.0768\n",
      "                                                     \n",
      "Epoch 2: val_loss improved from 0.09657 to 0.05931, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.7866 - loss: 0.0767 - val_accuracy: 0.9948 - val_loss: 0.0593\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - accuracy: 0.9062 - loss: 0.0423\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9180 - loss: 0.0409 \n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.9175 - loss: 0.0413\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.9186 - loss: 0.0442\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.9136 - loss: 0.0449\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.9029 - loss: 0.0447 \n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.8935 - loss: 0.0449\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.8853 - loss: 0.0451\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.8770 - loss: 0.0452\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.8698 - loss: 0.0455\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.8641 - loss: 0.0456\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.8590 - loss: 0.0456\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.8553 - loss: 0.0457\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.8524 - loss: 0.0457\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.8503 - loss: 0.0457\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.8489 - loss: 0.0458\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.8479 - loss: 0.0459\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.8473 - loss: 0.0460\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.8470 - loss: 0.0460\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.8471 - loss: 0.0461\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.8474 - loss: 0.0460\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.8478 - loss: 0.0460\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8482 - loss: 0.0459\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8487 - loss: 0.0458\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8492 - loss: 0.0457\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8497 - loss: 0.0456\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.8501 - loss: 0.0455\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.8506 - loss: 0.0454\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.8512 - loss: 0.0453\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.8518 - loss: 0.0453\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.8524 - loss: 0.0453\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.8531 - loss: 0.0452\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8538 - loss: 0.0451\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8545 - loss: 0.0451\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8552 - loss: 0.0450\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8559 - loss: 0.0449\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8566 - loss: 0.0448\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8573 - loss: 0.0448\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8580 - loss: 0.0448\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8586 - loss: 0.0447\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8593 - loss: 0.0447\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8599 - loss: 0.0447\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8606 - loss: 0.0447\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.8612 - loss: 0.0447\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.8617 - loss: 0.0447\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8623 - loss: 0.0447\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8629 - loss: 0.0446\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8635 - loss: 0.0446\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8641 - loss: 0.0446\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8647 - loss: 0.0446\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8653 - loss: 0.0447\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8659 - loss: 0.0447\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8665 - loss: 0.0447\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8671 - loss: 0.0447\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8676 - loss: 0.0447\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8681 - loss: 0.0447\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.8687 - loss: 0.0447\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8691 - loss: 0.0447\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8696 - loss: 0.0447\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8700 - loss: 0.0446\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8704 - loss: 0.0446\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.8708 - loss: 0.0446\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.8712 - loss: 0.0446\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.8715 - loss: 0.0446\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8719 - loss: 0.0446\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8723 - loss: 0.0446\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8726 - loss: 0.0446\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8730 - loss: 0.0446\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8734 - loss: 0.0446\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8737 - loss: 0.0446\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8741 - loss: 0.0445\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8745 - loss: 0.0445\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8748 - loss: 0.0445\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8752 - loss: 0.0445\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8755 - loss: 0.0445\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8759 - loss: 0.0445\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8762 - loss: 0.0445\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8766 - loss: 0.0445\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8769 - loss: 0.0445\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8772 - loss: 0.0445\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8775 - loss: 0.0445\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8778 - loss: 0.0445\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8780 - loss: 0.0445\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8782 - loss: 0.0444\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8784 - loss: 0.0444\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8785 - loss: 0.0444\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8786 - loss: 0.0444\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8787 - loss: 0.0444\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8787 - loss: 0.0444\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8788 - loss: 0.0444\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8788 - loss: 0.0444\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8789 - loss: 0.0443\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8790 - loss: 0.0443\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8790 - loss: 0.0443\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8791 - loss: 0.0443\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8792 - loss: 0.0443\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8793 - loss: 0.0443\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8794 - loss: 0.0443\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8795 - loss: 0.0442\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8796 - loss: 0.0442\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8798 - loss: 0.0442\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8799 - loss: 0.0442\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8800 - loss: 0.0442\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8802 - loss: 0.0442\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8804 - loss: 0.0441\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8805 - loss: 0.0441\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.8807 - loss: 0.0441\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8809 - loss: 0.0441\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8810 - loss: 0.0441\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8812 - loss: 0.0441\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8814 - loss: 0.0441\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8816 - loss: 0.0441\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8818 - loss: 0.0440\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8820 - loss: 0.0440\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8822 - loss: 0.0440\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8823 - loss: 0.0440\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8825 - loss: 0.0440\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8827 - loss: 0.0440\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8829 - loss: 0.0440\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8831 - loss: 0.0440\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8833 - loss: 0.0440\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8835 - loss: 0.0440\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8837 - loss: 0.0440\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8839 - loss: 0.0439\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8841 - loss: 0.0439\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8843 - loss: 0.0439\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8844 - loss: 0.0439\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8846 - loss: 0.0439\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8848 - loss: 0.0439\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8850 - loss: 0.0439\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8852 - loss: 0.0439\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8854 - loss: 0.0438\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8855 - loss: 0.0438\n",
      "                                                     \n",
      "Epoch 3: val_loss did not improve from 0.05931\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 88ms/step - accuracy: 0.8857 - loss: 0.0438 - val_accuracy: 0.9948 - val_loss: 0.0671\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 142ms/step\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "[    0     1     2 ... 12762 12763 12764]            \n",
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0450\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0415\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.9983 - loss: 0.0421\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9977 - loss: 0.0423\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9969 - loss: 0.0424\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.9961 - loss: 0.0423\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.9951 - loss: 0.0426\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9942 - loss: 0.0428\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9930 - loss: 0.0428\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9904 - loss: 0.0426\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.9878 - loss: 0.0428\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.9842 - loss: 0.0428\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9804 - loss: 0.0428 \n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9763 - loss: 0.0429\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9719 - loss: 0.0431\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.9677 - loss: 0.0433\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9634 - loss: 0.0434\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.9593 - loss: 0.0435\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9552 - loss: 0.0436\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9512 - loss: 0.0437\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.9474 - loss: 0.0437\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.9438 - loss: 0.0437\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.9403 - loss: 0.0437\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.9368 - loss: 0.0437\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9333 - loss: 0.0438\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9302 - loss: 0.0439\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9272 - loss: 0.0439\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9244 - loss: 0.0440\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9219 - loss: 0.0441\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9196 - loss: 0.0442\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9175 - loss: 0.0443\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9158 - loss: 0.0444\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9142 - loss: 0.0445\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9128 - loss: 0.0446\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.9116 - loss: 0.0448\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9105 - loss: 0.0449\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9096 - loss: 0.0450\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.9087 - loss: 0.0451\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9080 - loss: 0.0452\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9074 - loss: 0.0453\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9068 - loss: 0.0453\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9063 - loss: 0.0454\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9059 - loss: 0.0455\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9055 - loss: 0.0456\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9052 - loss: 0.0457\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9049 - loss: 0.0457\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9045 - loss: 0.0458\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.9042 - loss: 0.0458\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9039 - loss: 0.0459\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9036 - loss: 0.0460\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9033 - loss: 0.0460\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9029 - loss: 0.0461\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9025 - loss: 0.0461\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9020 - loss: 0.0462\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9015 - loss: 0.0463\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9009 - loss: 0.0463\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9003 - loss: 0.0464\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.8996 - loss: 0.0464\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.8989 - loss: 0.0465\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.8982 - loss: 0.0466\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8974 - loss: 0.0466\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8967 - loss: 0.0467\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8960 - loss: 0.0467\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8954 - loss: 0.0468\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8947 - loss: 0.0468\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8941 - loss: 0.0469\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8935 - loss: 0.0469\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8929 - loss: 0.0470\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8924 - loss: 0.0470\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8918 - loss: 0.0471\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8913 - loss: 0.0471\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8909 - loss: 0.0471\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8904 - loss: 0.0472\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.8900 - loss: 0.0472\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8896 - loss: 0.0472\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8892 - loss: 0.0473\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8889 - loss: 0.0473\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8886 - loss: 0.0473\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8883 - loss: 0.0473\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8880 - loss: 0.0473\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8878 - loss: 0.0473\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8875 - loss: 0.0474\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8873 - loss: 0.0474\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8870 - loss: 0.0474\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.8868 - loss: 0.0474\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8865 - loss: 0.0474\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8862 - loss: 0.0474\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8860 - loss: 0.0475\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8857 - loss: 0.0475\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8853 - loss: 0.0475\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8850 - loss: 0.0475\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8846 - loss: 0.0475\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8842 - loss: 0.0475\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8839 - loss: 0.0475\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8835 - loss: 0.0475\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8831 - loss: 0.0475\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8827 - loss: 0.0475\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8823 - loss: 0.0475\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8818 - loss: 0.0475\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8814 - loss: 0.0475\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8810 - loss: 0.0475\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8806 - loss: 0.0475\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8802 - loss: 0.0475\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8799 - loss: 0.0475\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8795 - loss: 0.0475\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8792 - loss: 0.0475\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8789 - loss: 0.0475\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8785 - loss: 0.0475\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.8782 - loss: 0.0475\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8780 - loss: 0.0476\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8777 - loss: 0.0476\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8774 - loss: 0.0476\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8772 - loss: 0.0476\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8769 - loss: 0.0476\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8767 - loss: 0.0476\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8765 - loss: 0.0477\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8763 - loss: 0.0477\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8761 - loss: 0.0477\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8758 - loss: 0.0477\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8756 - loss: 0.0477\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.8754 - loss: 0.0477\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8751 - loss: 0.0477\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8748 - loss: 0.0478\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8745 - loss: 0.0478\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8742 - loss: 0.0478\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8739 - loss: 0.0478\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8736 - loss: 0.0478\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8732 - loss: 0.0478\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8729 - loss: 0.0478\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8726 - loss: 0.0478\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8722 - loss: 0.0478\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8719 - loss: 0.0478\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8716 - loss: 0.0478\n",
      "                                                     \n",
      "Epoch 1: val_loss improved from inf to 0.04053, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 95ms/step - accuracy: 0.8713 - loss: 0.0478 - val_accuracy: 0.9944 - val_loss: 0.0405\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 96ms/step - accuracy: 0.8906 - loss: 0.0137\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.8984 - loss: 0.0224\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.9097 - loss: 0.0258\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.9186 - loss: 0.0262\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.9243 - loss: 0.0268\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9282 - loss: 0.0271\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9315 - loss: 0.0276\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9339 - loss: 0.0285\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9364 - loss: 0.0291\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9387 - loss: 0.0296\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9408 - loss: 0.0299\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9428 - loss: 0.0301\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9446 - loss: 0.0302\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9463 - loss: 0.0302 \n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9478 - loss: 0.0301\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9490 - loss: 0.0300\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9502 - loss: 0.0299\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9512 - loss: 0.0298\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9522 - loss: 0.0298\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9530 - loss: 0.0297\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9538 - loss: 0.0296\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9545 - loss: 0.0295\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9551 - loss: 0.0295\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9557 - loss: 0.0295\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9562 - loss: 0.0294\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9567 - loss: 0.0294\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9571 - loss: 0.0293\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.9576 - loss: 0.0293\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.9580 - loss: 0.0293\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9584 - loss: 0.0293\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9588 - loss: 0.0293\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9592 - loss: 0.0293\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9596 - loss: 0.0293\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.9599 - loss: 0.0293\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9603 - loss: 0.0293\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9606 - loss: 0.0294\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.9609 - loss: 0.0294\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9612 - loss: 0.0294\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9615 - loss: 0.0295\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9619 - loss: 0.0295\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9622 - loss: 0.0295\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9624 - loss: 0.0295\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9627 - loss: 0.0296\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9629 - loss: 0.0296\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9630 - loss: 0.0296\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9631 - loss: 0.0296\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9632 - loss: 0.0296\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9632 - loss: 0.0297\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.9632 - loss: 0.0297\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9631 - loss: 0.0297\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9631 - loss: 0.0297\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9630 - loss: 0.0297\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9629 - loss: 0.0297\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9627 - loss: 0.0297\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9625 - loss: 0.0297\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9622 - loss: 0.0296\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9619 - loss: 0.0296\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9616 - loss: 0.0296\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9612 - loss: 0.0296\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9608 - loss: 0.0296\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.9604 - loss: 0.0296\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9600 - loss: 0.0296\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9595 - loss: 0.0296\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9590 - loss: 0.0296\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9585 - loss: 0.0296\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9580 - loss: 0.0296\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9573 - loss: 0.0296\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9567 - loss: 0.0296\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9560 - loss: 0.0296\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9552 - loss: 0.0296\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9544 - loss: 0.0296\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9536 - loss: 0.0296\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9528 - loss: 0.0296\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9519 - loss: 0.0296\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9510 - loss: 0.0296\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9501 - loss: 0.0296\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9492 - loss: 0.0296\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9482 - loss: 0.0296\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9473 - loss: 0.0296\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9464 - loss: 0.0297\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9455 - loss: 0.0297\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9446 - loss: 0.0297\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9438 - loss: 0.0297\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9430 - loss: 0.0297\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.9422 - loss: 0.0297\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9414 - loss: 0.0297\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9407 - loss: 0.0297\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9399 - loss: 0.0297\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9393 - loss: 0.0297\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9386 - loss: 0.0297\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9379 - loss: 0.0297\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9373 - loss: 0.0297\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9367 - loss: 0.0297\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9361 - loss: 0.0297\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9355 - loss: 0.0297\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9349 - loss: 0.0298\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9344 - loss: 0.0298\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9339 - loss: 0.0298\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9334 - loss: 0.0298\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9329 - loss: 0.0298\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9324 - loss: 0.0298\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9319 - loss: 0.0298\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9314 - loss: 0.0298\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9309 - loss: 0.0298\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9304 - loss: 0.0298\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9299 - loss: 0.0298\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9294 - loss: 0.0298\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9289 - loss: 0.0298\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9283 - loss: 0.0298\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9278 - loss: 0.0298\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9272 - loss: 0.0299\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9266 - loss: 0.0299\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9260 - loss: 0.0299\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9254 - loss: 0.0299\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9248 - loss: 0.0299\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9242 - loss: 0.0299\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9236 - loss: 0.0299\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9231 - loss: 0.0299\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9225 - loss: 0.0299\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9219 - loss: 0.0299\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9214 - loss: 0.0299\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9209 - loss: 0.0300\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9203 - loss: 0.0300\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9198 - loss: 0.0300\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9193 - loss: 0.0300\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9188 - loss: 0.0300\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9184 - loss: 0.0300\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9179 - loss: 0.0300\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9174 - loss: 0.0300\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9170 - loss: 0.0300\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9165 - loss: 0.0300\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9161 - loss: 0.0300\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9157 - loss: 0.0301\n",
      "                                                     \n",
      "Epoch 2: val_loss improved from 0.04053 to 0.03576, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.9153 - loss: 0.0301 - val_accuracy: 0.9944 - val_loss: 0.0358\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 129ms/step - accuracy: 0.8906 - loss: 0.0200\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9023 - loss: 0.0226 \n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 87ms/step - accuracy: 0.9054 - loss: 0.0222\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9115 - loss: 0.0219\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.9167 - loss: 0.0221\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9214 - loss: 0.0220\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.9241 - loss: 0.0223\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9265 - loss: 0.0229\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9273 - loss: 0.0233\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9279 - loss: 0.0235\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.9282 - loss: 0.0237\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9284 - loss: 0.0240 \n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9290 - loss: 0.0241\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9296 - loss: 0.0243\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9304 - loss: 0.0244\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9312 - loss: 0.0246\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9319 - loss: 0.0247\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9327 - loss: 0.0247 \n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9334 - loss: 0.0248\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9340 - loss: 0.0248\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9346 - loss: 0.0248\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9351 - loss: 0.0248\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9355 - loss: 0.0248\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9359 - loss: 0.0248\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9360 - loss: 0.0249\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9362 - loss: 0.0249\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9363 - loss: 0.0250\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.9362 - loss: 0.0250\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.9361 - loss: 0.0251\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9358 - loss: 0.0252\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9355 - loss: 0.0253\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9351 - loss: 0.0253\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9346 - loss: 0.0254\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9340 - loss: 0.0254\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9334 - loss: 0.0254\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9327 - loss: 0.0255\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9320 - loss: 0.0255\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9314 - loss: 0.0256\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9308 - loss: 0.0256\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.9302 - loss: 0.0256\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9297 - loss: 0.0257\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9293 - loss: 0.0258\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9288 - loss: 0.0258\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9284 - loss: 0.0259\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9281 - loss: 0.0259\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9278 - loss: 0.0259\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9276 - loss: 0.0260\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9274 - loss: 0.0260\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.9272 - loss: 0.0260\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9271 - loss: 0.0261\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.9269 - loss: 0.0261\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9269 - loss: 0.0261\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9268 - loss: 0.0262\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9268 - loss: 0.0262\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9267 - loss: 0.0262\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9267 - loss: 0.0262\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9266 - loss: 0.0263\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9266 - loss: 0.0263\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9265 - loss: 0.0263\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9265 - loss: 0.0263\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9264 - loss: 0.0263\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9264 - loss: 0.0264\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9264 - loss: 0.0264\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9263 - loss: 0.0264\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9263 - loss: 0.0264\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9262 - loss: 0.0265\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9262 - loss: 0.0265\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9261 - loss: 0.0265\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9261 - loss: 0.0265\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.9260 - loss: 0.0265\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9260 - loss: 0.0265\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9259 - loss: 0.0265\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9259 - loss: 0.0265\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9258 - loss: 0.0265\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.9258 - loss: 0.0265\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9257 - loss: 0.0266\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9257 - loss: 0.0266\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9256 - loss: 0.0266\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9256 - loss: 0.0266\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9255 - loss: 0.0266\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9255 - loss: 0.0266\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0266\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9254 - loss: 0.0265\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9253 - loss: 0.0265\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9252 - loss: 0.0265\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9252 - loss: 0.0265\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9251 - loss: 0.0265\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9250 - loss: 0.0265\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9249 - loss: 0.0265\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9249 - loss: 0.0265\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9248 - loss: 0.0265\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9247 - loss: 0.0265\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9247 - loss: 0.0265\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.9246 - loss: 0.0265\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9246 - loss: 0.0265\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9246 - loss: 0.0265\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9245 - loss: 0.0265\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9245 - loss: 0.0265\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9245 - loss: 0.0265\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9244 - loss: 0.0265\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9244 - loss: 0.0265\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9243 - loss: 0.0265\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9243 - loss: 0.0265\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9242 - loss: 0.0265\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9241 - loss: 0.0264\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9240 - loss: 0.0264\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9240 - loss: 0.0264\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9239 - loss: 0.0264\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9238 - loss: 0.0264\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9237 - loss: 0.0264\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9236 - loss: 0.0264\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9236 - loss: 0.0264\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9235 - loss: 0.0264\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9234 - loss: 0.0264\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9233 - loss: 0.0264\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9233 - loss: 0.0264\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9232 - loss: 0.0264\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9232 - loss: 0.0264\n",
      "                                                     \n",
      "Epoch 3: val_loss did not improve from 0.03576\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.9231 - loss: 0.0264 - val_accuracy: 0.9944 - val_loss: 0.0383\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step \n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\n",
      "[    0     3     8 ... 12762 12764 12765]            \n",
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.9062 - loss: 0.0305\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.9219 - loss: 0.0260\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.9253 - loss: 0.0276\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - accuracy: 0.9255 - loss: 0.0282\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.9254 - loss: 0.0289\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9235 - loss: 0.0293\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.9210 - loss: 0.0300\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9194 - loss: 0.0306\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9176 - loss: 0.0310\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.9158 - loss: 0.0312\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9140 - loss: 0.0314\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9125 - loss: 0.0319\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.9108 - loss: 0.0324\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.9085 - loss: 0.0328 \n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.9052 - loss: 0.0331\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9018 - loss: 0.0333 \n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8985 - loss: 0.0335\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8949 - loss: 0.0336\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8911 - loss: 0.0338\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8873 - loss: 0.0339\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8838 - loss: 0.0340\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8804 - loss: 0.0341\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8774 - loss: 0.0342\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.8746 - loss: 0.0343\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.8721 - loss: 0.0343\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.8699 - loss: 0.0344\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.8680 - loss: 0.0344\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8661 - loss: 0.0344\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8644 - loss: 0.0344\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8628 - loss: 0.0344\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8614 - loss: 0.0344\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.8601 - loss: 0.0344\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8588 - loss: 0.0344\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8575 - loss: 0.0344\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8563 - loss: 0.0344\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8550 - loss: 0.0344\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.8536 - loss: 0.0344\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.8522 - loss: 0.0343\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 87ms/step - accuracy: 0.8507 - loss: 0.0343\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 87ms/step - accuracy: 0.8491 - loss: 0.0343\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8476 - loss: 0.0343\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8460 - loss: 0.0343\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8444 - loss: 0.0343\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8428 - loss: 0.0342\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8413 - loss: 0.0342\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8398 - loss: 0.0342\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8384 - loss: 0.0342\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8369 - loss: 0.0342\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8355 - loss: 0.0342\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8341 - loss: 0.0342\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.8327 - loss: 0.0342\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.8313 - loss: 0.0342\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8298 - loss: 0.0341\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8283 - loss: 0.0341\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8268 - loss: 0.0341\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8252 - loss: 0.0341\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8236 - loss: 0.0340\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8220 - loss: 0.0340\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8203 - loss: 0.0340\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8186 - loss: 0.0340\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8169 - loss: 0.0339\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8152 - loss: 0.0339\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8135 - loss: 0.0339\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.8118 - loss: 0.0338\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8101 - loss: 0.0338\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8084 - loss: 0.0338\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8068 - loss: 0.0338\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8052 - loss: 0.0338\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8037 - loss: 0.0338\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8022 - loss: 0.0338\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.8008 - loss: 0.0338\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7994 - loss: 0.0338\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.7981 - loss: 0.0338\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.7968 - loss: 0.0338\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.7955 - loss: 0.0338\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.7942 - loss: 0.0338\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7930 - loss: 0.0338\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7917 - loss: 0.0337\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7904 - loss: 0.0337\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7892 - loss: 0.0337\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7879 - loss: 0.0337\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7867 - loss: 0.0337\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7855 - loss: 0.0337\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7844 - loss: 0.0337\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7833 - loss: 0.0337\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7823 - loss: 0.0337\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7813 - loss: 0.0337\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7803 - loss: 0.0337\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.7794 - loss: 0.0337\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7785 - loss: 0.0337\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7776 - loss: 0.0337\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7767 - loss: 0.0337\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7759 - loss: 0.0337\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7750 - loss: 0.0336\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7742 - loss: 0.0336\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7735 - loss: 0.0336\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7727 - loss: 0.0336\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7720 - loss: 0.0336\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.7713 - loss: 0.0336\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7706 - loss: 0.0336\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7700 - loss: 0.0336\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7693 - loss: 0.0336\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7687 - loss: 0.0336\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7681 - loss: 0.0336\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7675 - loss: 0.0336\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7669 - loss: 0.0336\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7663 - loss: 0.0336\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7657 - loss: 0.0336\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7652 - loss: 0.0336\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7646 - loss: 0.0336\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.7641 - loss: 0.0336\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.7636 - loss: 0.0336\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.7631 - loss: 0.0335\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7627 - loss: 0.0335\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7622 - loss: 0.0335\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7617 - loss: 0.0335\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7613 - loss: 0.0335\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7608 - loss: 0.0335\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7604 - loss: 0.0335\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7600 - loss: 0.0335\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7596 - loss: 0.0335\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7592 - loss: 0.0334\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7588 - loss: 0.0334\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7584 - loss: 0.0334\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7580 - loss: 0.0334\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7576 - loss: 0.0334\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7573 - loss: 0.0334\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7569 - loss: 0.0334\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7566 - loss: 0.0334\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7563 - loss: 0.0334\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7559 - loss: 0.0333\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7556 - loss: 0.0333\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7553 - loss: 0.0333\n",
      "                                                     \n",
      "Epoch 1: val_loss improved from inf to 0.02188, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 98ms/step - accuracy: 0.7550 - loss: 0.0333 - val_accuracy: 0.7596 - val_loss: 0.0219\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 101ms/step - accuracy: 0.7969 - loss: 0.0173\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.7695 - loss: 0.0206 \n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.7457 - loss: 0.0221\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.7253 - loss: 0.0217\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.7083 - loss: 0.0222\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.6953 - loss: 0.0224\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.6827 - loss: 0.0223\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.6726 - loss: 0.0225\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.6644 - loss: 0.0228\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.6583 - loss: 0.0231\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.6528 - loss: 0.0233\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.6479 - loss: 0.0234\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.6444 - loss: 0.0235\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.6412 - loss: 0.0236\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.6390 - loss: 0.0237\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.6375 - loss: 0.0238\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.6363 - loss: 0.0238 \n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.6355 - loss: 0.0239\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.6354 - loss: 0.0240\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.6358 - loss: 0.0240\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.6367 - loss: 0.0240\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.6379 - loss: 0.0240\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.6391 - loss: 0.0240\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.6404 - loss: 0.0240\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.6417 - loss: 0.0241\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.6430 - loss: 0.0241\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.6443 - loss: 0.0241\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6456 - loss: 0.0241\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6469 - loss: 0.0241\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6484 - loss: 0.0241\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6499 - loss: 0.0241\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6514 - loss: 0.0241\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6529 - loss: 0.0241\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6545 - loss: 0.0241\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.6562 - loss: 0.0241\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6578 - loss: 0.0241\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.6594 - loss: 0.0241\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.6611 - loss: 0.0241\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.6627 - loss: 0.0241\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.6643 - loss: 0.0241\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6660 - loss: 0.0241\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6676 - loss: 0.0241\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6692 - loss: 0.0240\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.6707 - loss: 0.0240\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6722 - loss: 0.0240\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6736 - loss: 0.0240\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6750 - loss: 0.0240\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6764 - loss: 0.0240\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6778 - loss: 0.0240\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6792 - loss: 0.0240\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6806 - loss: 0.0240\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.6820 - loss: 0.0240\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.6833 - loss: 0.0240\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.6847 - loss: 0.0240\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6860 - loss: 0.0240\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6873 - loss: 0.0240\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6886 - loss: 0.0240\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6898 - loss: 0.0239\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6910 - loss: 0.0239\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6921 - loss: 0.0239\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6931 - loss: 0.0239\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6941 - loss: 0.0239\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6950 - loss: 0.0239\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.6959 - loss: 0.0238\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.6966 - loss: 0.0238\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.6974 - loss: 0.0238\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.6982 - loss: 0.0238\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.6989 - loss: 0.0238\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.6996 - loss: 0.0237\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7003 - loss: 0.0237\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7010 - loss: 0.0237\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7017 - loss: 0.0237\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7023 - loss: 0.0237\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7029 - loss: 0.0237\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.7034 - loss: 0.0237\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7038 - loss: 0.0236\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7042 - loss: 0.0236\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7045 - loss: 0.0236\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7047 - loss: 0.0236\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7049 - loss: 0.0236\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7050 - loss: 0.0236\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7051 - loss: 0.0235\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7051 - loss: 0.0235\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7051 - loss: 0.0235\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7050 - loss: 0.0235\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7050 - loss: 0.0235\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7048 - loss: 0.0234\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7047 - loss: 0.0234\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7045 - loss: 0.0234\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7043 - loss: 0.0234\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7041 - loss: 0.0234\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7039 - loss: 0.0233\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7037 - loss: 0.0233\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7035 - loss: 0.0233\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7033 - loss: 0.0233\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7032 - loss: 0.0233\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7030 - loss: 0.0233\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.7029 - loss: 0.0232\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7027 - loss: 0.0232\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7026 - loss: 0.0232\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7025 - loss: 0.0232\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7024 - loss: 0.0232\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7023 - loss: 0.0232\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7022 - loss: 0.0232\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7021 - loss: 0.0232\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7020 - loss: 0.0232\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.7019 - loss: 0.0232\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.7018 - loss: 0.0232\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.7017 - loss: 0.0232\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.7016 - loss: 0.0232\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.7015 - loss: 0.0232\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7014 - loss: 0.0232\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7012 - loss: 0.0232\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7011 - loss: 0.0232\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7010 - loss: 0.0231\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7008 - loss: 0.0231\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7007 - loss: 0.0231\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7005 - loss: 0.0231\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7003 - loss: 0.0231\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7000 - loss: 0.0231\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.6998 - loss: 0.0231\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6995 - loss: 0.0231\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6993 - loss: 0.0231\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6990 - loss: 0.0231\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6987 - loss: 0.0231\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6984 - loss: 0.0231\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6981 - loss: 0.0231\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6978 - loss: 0.0231\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6975 - loss: 0.0231\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6972 - loss: 0.0231\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6969 - loss: 0.0231\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6966 - loss: 0.0231\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6963 - loss: 0.0231\n",
      "                                                     \n",
      "Epoch 2: val_loss did not improve from 0.02188\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.6960 - loss: 0.0231 - val_accuracy: 0.6418 - val_loss: 0.0222\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 98ms/step - accuracy: 0.6094 - loss: 0.0163\n",
      "\u001b[1m  2/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.6094 - loss: 0.0222\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 87ms/step - accuracy: 0.6076 - loss: 0.0222\n",
      "\u001b[1m  4/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.6003 - loss: 0.0215\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.5921 - loss: 0.0208\n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - accuracy: 0.5854 - loss: 0.0209\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.5818 - loss: 0.0211\n",
      "\u001b[1m  8/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.5794 - loss: 0.0215\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.5754 - loss: 0.0217\n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.5716 - loss: 0.0218\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.5681 - loss: 0.0218\n",
      "\u001b[1m 12/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.5631 - loss: 0.0219\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.5581 - loss: 0.0220\n",
      "\u001b[1m 14/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.5535 - loss: 0.0219\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.5492 - loss: 0.0219\n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.5452 - loss: 0.0219\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.5415 - loss: 0.0219\n",
      "\u001b[1m 18/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.5381 - loss: 0.0218 \n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.5350 - loss: 0.0218\n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.5323 - loss: 0.0219\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5302 - loss: 0.0219\n",
      "\u001b[1m 22/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5283 - loss: 0.0220\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5268 - loss: 0.0220\n",
      "\u001b[1m 24/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5257 - loss: 0.0220\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5250 - loss: 0.0220\n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5246 - loss: 0.0220\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5244 - loss: 0.0220\n",
      "\u001b[1m 28/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.5245 - loss: 0.0220\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.5248 - loss: 0.0220\n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.5252 - loss: 0.0219\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.5257 - loss: 0.0219\n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.5262 - loss: 0.0219\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.5268 - loss: 0.0219\n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.5273 - loss: 0.0219\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.5279 - loss: 0.0219\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.5285 - loss: 0.0219\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.5290 - loss: 0.0219\n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.5295 - loss: 0.0219\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5297 - loss: 0.0219\n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5297 - loss: 0.0219\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5296 - loss: 0.0219\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5292 - loss: 0.0220\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5288 - loss: 0.0220\n",
      "\u001b[1m 44/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5282 - loss: 0.0220\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5275 - loss: 0.0220\n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5267 - loss: 0.0220\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5258 - loss: 0.0220\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5249 - loss: 0.0220\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.5240 - loss: 0.0220\n",
      "\u001b[1m 50/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.5231 - loss: 0.0220\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5222 - loss: 0.0220\n",
      "\u001b[1m 52/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5215 - loss: 0.0220\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5207 - loss: 0.0220\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5200 - loss: 0.0220\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5195 - loss: 0.0220\n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5190 - loss: 0.0220\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5188 - loss: 0.0219\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5186 - loss: 0.0219\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5186 - loss: 0.0219\n",
      "\u001b[1m 60/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5187 - loss: 0.0219\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5188 - loss: 0.0219\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.5190 - loss: 0.0218\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5193 - loss: 0.0218\n",
      "\u001b[1m 64/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5197 - loss: 0.0218\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5201 - loss: 0.0218\n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5206 - loss: 0.0217\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5210 - loss: 0.0217\n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5214 - loss: 0.0217\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5218 - loss: 0.0217\n",
      "\u001b[1m 70/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.5221 - loss: 0.0217\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.5224 - loss: 0.0217\n",
      "\u001b[1m 72/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.5226 - loss: 0.0216\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.5227 - loss: 0.0216\n",
      "\u001b[1m 74/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5229 - loss: 0.0216\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5229 - loss: 0.0216\n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5230 - loss: 0.0216\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5230 - loss: 0.0216\n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5230 - loss: 0.0215\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5230 - loss: 0.0215\n",
      "\u001b[1m 80/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5230 - loss: 0.0215\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5231 - loss: 0.0215\n",
      "\u001b[1m 82/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5231 - loss: 0.0215\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5232 - loss: 0.0215\n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5233 - loss: 0.0214\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5233 - loss: 0.0214\n",
      "\u001b[1m 86/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5234 - loss: 0.0214\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5235 - loss: 0.0214\n",
      "\u001b[1m 88/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5236 - loss: 0.0214\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5238 - loss: 0.0213\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5239 - loss: 0.0213\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5240 - loss: 0.0213\n",
      "\u001b[1m 92/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5242 - loss: 0.0213\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5243 - loss: 0.0213\n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5244 - loss: 0.0213\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5245 - loss: 0.0212\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5246 - loss: 0.0212\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5247 - loss: 0.0212\n",
      "\u001b[1m 98/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5247 - loss: 0.0212\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5247 - loss: 0.0212\n",
      "\u001b[1m100/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5248 - loss: 0.0211\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5248 - loss: 0.0211\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5247 - loss: 0.0211\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5247 - loss: 0.0211\n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5246 - loss: 0.0211\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5245 - loss: 0.0211\n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5244 - loss: 0.0210\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5243 - loss: 0.0210\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5242 - loss: 0.0210\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5240 - loss: 0.0210\n",
      "\u001b[1m110/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5238 - loss: 0.0210\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5237 - loss: 0.0209\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5235 - loss: 0.0209\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5233 - loss: 0.0209\n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5231 - loss: 0.0209\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5228 - loss: 0.0209\n",
      "\u001b[1m116/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5226 - loss: 0.0209\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5223 - loss: 0.0209\n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5221 - loss: 0.0208\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5218 - loss: 0.0208\n",
      "\u001b[1m120/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5215 - loss: 0.0208\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5212 - loss: 0.0208\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5209 - loss: 0.0208\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5205 - loss: 0.0208\n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5202 - loss: 0.0208\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5199 - loss: 0.0207\n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5195 - loss: 0.0207\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5192 - loss: 0.0207\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5188 - loss: 0.0207\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5185 - loss: 0.0207\n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5182 - loss: 0.0207\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5178 - loss: 0.0207\n",
      "\u001b[1m132/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5175 - loss: 0.0206\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5172 - loss: 0.0206\n",
      "                                                     \n",
      "Epoch 3: val_loss did not improve from 0.02188\n",
      "\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.5169 - loss: 0.0206 - val_accuracy: 0.5309 - val_loss: 0.0226\n",
      "\n",
      "Epoch 3: early stopping                              \n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step \n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 42/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 54/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 62/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 90/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m 96/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m102/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "[    1     2     4 ... 12758 12763 12765]                                        \n",
      " 50%|█████     | 1/2 [02:00<02:00, 120.64s/trial, best loss: -0.4752855495018105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:33\u001b[0m 2s/step - accuracy: 0.2188 - loss: 0.6966\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.1084 - loss: 0.6813 \n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.0812 - loss: 0.6532\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.0705 - loss: 0.6044\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.0860 - loss: 0.5632\n",
      "\u001b[1m 26/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.1252 - loss: 0.5277\n",
      "\u001b[1m 30/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.1597 - loss: 0.5026\n",
      "\u001b[1m 35/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.1966 - loss: 0.4755\n",
      "\u001b[1m 40/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.2254 - loss: 0.4522\n",
      "\u001b[1m 45/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.2504 - loss: 0.4324\n",
      "\u001b[1m 50/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.2729 - loss: 0.4150\n",
      "\u001b[1m 55/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.2925 - loss: 0.4000\n",
      "\u001b[1m 60/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3102 - loss: 0.3869\n",
      "\u001b[1m 64/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3230 - loss: 0.3776\n",
      "\u001b[1m 69/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3380 - loss: 0.3670\n",
      "\u001b[1m 74/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3524 - loss: 0.3577\n",
      "\u001b[1m 79/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3662 - loss: 0.3493\n",
      "\u001b[1m 84/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3794 - loss: 0.3417\n",
      "\u001b[1m 89/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3917 - loss: 0.3347\n",
      "\u001b[1m 94/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4032 - loss: 0.3283\n",
      "\u001b[1m 99/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4143 - loss: 0.3224\n",
      "\u001b[1m104/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4249 - loss: 0.3169\n",
      "\u001b[1m109/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4350 - loss: 0.3118\n",
      "\u001b[1m112/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4409 - loss: 0.3089\n",
      "\u001b[1m116/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4484 - loss: 0.3052\n",
      "\u001b[1m120/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4557 - loss: 0.3017\n",
      "\u001b[1m125/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4644 - loss: 0.2976\n",
      "\u001b[1m130/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4725 - loss: 0.2938\n",
      "\u001b[1m135/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4800 - loss: 0.2902\n",
      "\u001b[1m140/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4868 - loss: 0.2867\n",
      "\u001b[1m145/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4934 - loss: 0.2834\n",
      "\u001b[1m149/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4985 - loss: 0.2809\n",
      "\u001b[1m153/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5034 - loss: 0.2785\n",
      "\u001b[1m158/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5094 - loss: 0.2755\n",
      "\u001b[1m162/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5139 - loss: 0.2733\n",
      "\u001b[1m167/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5192 - loss: 0.2705\n",
      "\u001b[1m172/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.2679\n",
      "\u001b[1m176/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5281 - loss: 0.2659\n",
      "\u001b[1m181/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5329 - loss: 0.2634\n",
      "\u001b[1m186/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5375 - loss: 0.2611\n",
      "\u001b[1m191/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5418 - loss: 0.2588\n",
      "\u001b[1m196/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5459 - loss: 0.2567\n",
      "\u001b[1m201/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5498 - loss: 0.2546\n",
      "\u001b[1m206/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5536 - loss: 0.2525\n",
      "\u001b[1m211/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5573 - loss: 0.2506\n",
      "\u001b[1m216/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5611 - loss: 0.2487\n",
      "\u001b[1m221/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5647 - loss: 0.2468\n",
      "\u001b[1m226/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5682 - loss: 0.2450\n",
      "\u001b[1m231/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5715 - loss: 0.2432\n",
      "\u001b[1m235/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5740 - loss: 0.2418\n",
      "\u001b[1m240/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5770 - loss: 0.2402\n",
      "\u001b[1m245/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5799 - loss: 0.2386\n",
      "\u001b[1m250/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5827 - loss: 0.2370\n",
      "\u001b[1m255/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5855 - loss: 0.2355\n",
      "\u001b[1m260/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5882 - loss: 0.2340\n",
      "\u001b[1m265/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5909 - loss: 0.2325\n",
      "                                                                                 \n",
      "Epoch 1: val_loss improved from inf to 0.09667, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.5920 - loss: 0.2319 - val_accuracy: 0.9948 - val_loss: 0.0967\n",
      "\n",
      "Epoch 2/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.9062 - loss: 0.1011\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7820 - loss: 0.0849\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6944 - loss: 0.0803\n",
      "\u001b[1m 15/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6505 - loss: 0.0786\n",
      "\u001b[1m 19/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6241 - loss: 0.0783\n",
      "\u001b[1m 24/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6093 - loss: 0.0789\n",
      "\u001b[1m 29/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6118 - loss: 0.0795\n",
      "\u001b[1m 34/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6220 - loss: 0.0798\n",
      "\u001b[1m 39/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6342 - loss: 0.0804\n",
      "\u001b[1m 44/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6441 - loss: 0.0810\n",
      "\u001b[1m 48/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6495 - loss: 0.0813\n",
      "\u001b[1m 53/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6540 - loss: 0.0818\n",
      "\u001b[1m 57/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6567 - loss: 0.0820\n",
      "\u001b[1m 62/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6595 - loss: 0.0823\n",
      "\u001b[1m 67/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6624 - loss: 0.0826\n",
      "\u001b[1m 72/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6652 - loss: 0.0828\n",
      "\u001b[1m 77/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6686 - loss: 0.0829\n",
      "\u001b[1m 82/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6723 - loss: 0.0829\n",
      "\u001b[1m 87/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6763 - loss: 0.0830\n",
      "\u001b[1m 92/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6806 - loss: 0.0830\n",
      "\u001b[1m 96/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6841 - loss: 0.0831\n",
      "\u001b[1m101/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6884 - loss: 0.0832\n",
      "\u001b[1m106/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6924 - loss: 0.0832\n",
      "\u001b[1m110/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6953 - loss: 0.0832\n",
      "\u001b[1m114/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6982 - loss: 0.0832\n",
      "\u001b[1m118/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7009 - loss: 0.0832\n",
      "\u001b[1m123/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7043 - loss: 0.0833\n",
      "\u001b[1m128/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7075 - loss: 0.0833\n",
      "\u001b[1m133/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7105 - loss: 0.0833\n",
      "\u001b[1m137/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7130 - loss: 0.0833\n",
      "\u001b[1m142/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7160 - loss: 0.0832\n",
      "\u001b[1m147/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7190 - loss: 0.0832\n",
      "\u001b[1m152/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7220 - loss: 0.0831\n",
      "\u001b[1m157/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7250 - loss: 0.0830\n",
      "\u001b[1m161/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7274 - loss: 0.0829\n",
      "\u001b[1m165/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7297 - loss: 0.0828\n",
      "\u001b[1m169/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7320 - loss: 0.0827\n",
      "\u001b[1m174/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7348 - loss: 0.0826\n",
      "\u001b[1m177/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7365 - loss: 0.0825\n",
      "\u001b[1m181/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7387 - loss: 0.0824\n",
      "\u001b[1m186/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7414 - loss: 0.0823\n",
      "\u001b[1m191/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7441 - loss: 0.0821\n",
      "\u001b[1m196/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7466 - loss: 0.0819\n",
      "\u001b[1m200/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7486 - loss: 0.0818\n",
      "\u001b[1m205/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7511 - loss: 0.0816\n",
      "\u001b[1m210/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7535 - loss: 0.0814\n",
      "\u001b[1m214/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7554 - loss: 0.0813\n",
      "\u001b[1m219/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7578 - loss: 0.0811\n",
      "\u001b[1m224/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7601 - loss: 0.0809\n",
      "\u001b[1m229/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7623 - loss: 0.0807\n",
      "\u001b[1m234/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7645 - loss: 0.0806\n",
      "\u001b[1m239/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7665 - loss: 0.0804\n",
      "\u001b[1m244/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7684 - loss: 0.0802\n",
      "\u001b[1m249/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7703 - loss: 0.0800\n",
      "\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7720 - loss: 0.0799\n",
      "\u001b[1m258/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7734 - loss: 0.0797\n",
      "\u001b[1m263/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7752 - loss: 0.0796\n",
      "                                                                                 \n",
      "Epoch 2: val_loss improved from 0.09667 to 0.06179, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.7765 - loss: 0.0794 - val_accuracy: 0.9948 - val_loss: 0.0618\n",
      "\n",
      "Epoch 3/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0261\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9617 - loss: 0.0462\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9535 - loss: 0.0526\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9498 - loss: 0.0543\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9507 - loss: 0.0547\n",
      "\u001b[1m 26/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9530 - loss: 0.0542\n",
      "\u001b[1m 31/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9553 - loss: 0.0542\n",
      "\u001b[1m 36/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9576 - loss: 0.0541\n",
      "\u001b[1m 40/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9593 - loss: 0.0539\n",
      "\u001b[1m 44/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9609 - loss: 0.0537\n",
      "\u001b[1m 49/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9625 - loss: 0.0535\n",
      "\u001b[1m 54/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9638 - loss: 0.0531\n",
      "\u001b[1m 59/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: 0.0528\n",
      "\u001b[1m 63/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9659 - loss: 0.0525\n",
      "\u001b[1m 68/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9668 - loss: 0.0521\n",
      "\u001b[1m 73/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9677 - loss: 0.0517\n",
      "\u001b[1m 77/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9683 - loss: 0.0514\n",
      "\u001b[1m 81/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9687 - loss: 0.0510\n",
      "\u001b[1m 85/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9690 - loss: 0.0507\n",
      "\u001b[1m 90/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9693 - loss: 0.0503\n",
      "\u001b[1m 95/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9696 - loss: 0.0500\n",
      "\u001b[1m100/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0497\n",
      "\u001b[1m104/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0495\n",
      "\u001b[1m109/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0492\n",
      "\u001b[1m113/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0490\n",
      "\u001b[1m118/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0487\n",
      "\u001b[1m123/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0485\n",
      "\u001b[1m128/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0482\n",
      "\u001b[1m133/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0480\n",
      "\u001b[1m138/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9699 - loss: 0.0477\n",
      "\u001b[1m143/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9699 - loss: 0.0475\n",
      "\u001b[1m147/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0474\n",
      "\u001b[1m152/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9697 - loss: 0.0472\n",
      "\u001b[1m157/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9695 - loss: 0.0470\n",
      "\u001b[1m161/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9693 - loss: 0.0468\n",
      "\u001b[1m166/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9690 - loss: 0.0466\n",
      "\u001b[1m170/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9686 - loss: 0.0465\n",
      "\u001b[1m175/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9680 - loss: 0.0463\n",
      "\u001b[1m180/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9674 - loss: 0.0462\n",
      "\u001b[1m185/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9668 - loss: 0.0460\n",
      "\u001b[1m190/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9663 - loss: 0.0459\n",
      "\u001b[1m195/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9658 - loss: 0.0457\n",
      "\u001b[1m200/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9654 - loss: 0.0456\n",
      "\u001b[1m205/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: 0.0455\n",
      "\u001b[1m210/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9645 - loss: 0.0454\n",
      "\u001b[1m215/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9639 - loss: 0.0453\n",
      "\u001b[1m219/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9634 - loss: 0.0453\n",
      "\u001b[1m223/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9629 - loss: 0.0452\n",
      "\u001b[1m228/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9623 - loss: 0.0451\n",
      "\u001b[1m232/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9619 - loss: 0.0451\n",
      "\u001b[1m237/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9613 - loss: 0.0450\n",
      "\u001b[1m242/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9609 - loss: 0.0449\n",
      "\u001b[1m247/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9604 - loss: 0.0448\n",
      "\u001b[1m252/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9600 - loss: 0.0448\n",
      "\u001b[1m257/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9596 - loss: 0.0447\n",
      "\u001b[1m262/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9592 - loss: 0.0447\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9590 - loss: 0.0446\n",
      "                                                                                 \n",
      "Epoch 3: val_loss did not improve from 0.06179\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9589 - loss: 0.0446 - val_accuracy: 0.9948 - val_loss: 0.0649\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 104ms/step             \n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 40/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step      \n",
      "\n",
      "[    0     1     2 ... 12762 12763 12764]                                        \n",
      "Epoch 1/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0228\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0284\n",
      "\u001b[1m 10/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0328\n",
      "\u001b[1m 15/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9935 - loss: 0.0370\n",
      "\u001b[1m 20/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9881 - loss: 0.0397\n",
      "\u001b[1m 24/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9840 - loss: 0.0413\n",
      "\u001b[1m 29/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9774 - loss: 0.0426\n",
      "\u001b[1m 34/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9675 - loss: 0.0436\n",
      "\u001b[1m 39/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9541 - loss: 0.0442\n",
      "\u001b[1m 43/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9428 - loss: 0.0445\n",
      "\u001b[1m 48/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9302 - loss: 0.0447\n",
      "\u001b[1m 53/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9197 - loss: 0.0448\n",
      "\u001b[1m 58/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9110 - loss: 0.0448\n",
      "\u001b[1m 62/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9049 - loss: 0.0448\n",
      "\u001b[1m 67/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8977 - loss: 0.0448\n",
      "\u001b[1m 72/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8907 - loss: 0.0448\n",
      "\u001b[1m 76/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8853 - loss: 0.0448\n",
      "\u001b[1m 81/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8791 - loss: 0.0449\n",
      "\u001b[1m 86/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8739 - loss: 0.0450\n",
      "\u001b[1m 91/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8692 - loss: 0.0451\n",
      "\u001b[1m 95/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8656 - loss: 0.0452\n",
      "\u001b[1m100/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8611 - loss: 0.0453\n",
      "\u001b[1m105/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8571 - loss: 0.0454\n",
      "\u001b[1m108/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8549 - loss: 0.0454\n",
      "\u001b[1m112/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8525 - loss: 0.0455\n",
      "\u001b[1m117/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8499 - loss: 0.0456\n",
      "\u001b[1m122/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8478 - loss: 0.0456\n",
      "\u001b[1m127/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8460 - loss: 0.0457\n",
      "\u001b[1m131/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8445 - loss: 0.0457\n",
      "\u001b[1m136/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8428 - loss: 0.0458\n",
      "\u001b[1m141/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8412 - loss: 0.0458\n",
      "\u001b[1m146/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8398 - loss: 0.0458\n",
      "\u001b[1m151/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8385 - loss: 0.0458\n",
      "\u001b[1m156/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8374 - loss: 0.0458\n",
      "\u001b[1m161/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8367 - loss: 0.0458\n",
      "\u001b[1m165/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8362 - loss: 0.0458\n",
      "\u001b[1m170/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8358 - loss: 0.0458\n",
      "\u001b[1m174/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8355 - loss: 0.0458\n",
      "\u001b[1m179/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8352 - loss: 0.0459\n",
      "\u001b[1m184/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8349 - loss: 0.0459\n",
      "\u001b[1m188/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8348 - loss: 0.0459\n",
      "\u001b[1m192/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8347 - loss: 0.0459\n",
      "\u001b[1m196/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8347 - loss: 0.0459\n",
      "\u001b[1m201/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8348 - loss: 0.0459\n",
      "\u001b[1m206/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8349 - loss: 0.0459\n",
      "\u001b[1m211/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8352 - loss: 0.0459\n",
      "\u001b[1m216/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8355 - loss: 0.0459\n",
      "\u001b[1m221/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8358 - loss: 0.0459\n",
      "\u001b[1m226/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8360 - loss: 0.0459\n",
      "\u001b[1m231/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8362 - loss: 0.0459\n",
      "\u001b[1m236/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8365 - loss: 0.0460\n",
      "\u001b[1m241/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8367 - loss: 0.0460\n",
      "\u001b[1m246/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8371 - loss: 0.0460\n",
      "\u001b[1m251/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8374 - loss: 0.0460\n",
      "\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8376 - loss: 0.0460\n",
      "\u001b[1m258/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8379 - loss: 0.0461\n",
      "\u001b[1m263/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8383 - loss: 0.0461\n",
      "                                                                                 \n",
      "Epoch 1: val_loss improved from inf to 0.04076, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.8387 - loss: 0.0461 - val_accuracy: 0.9944 - val_loss: 0.0408\n",
      "\n",
      "Epoch 2/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.9688 - loss: 0.0328\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9590 - loss: 0.0432\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9393 - loss: 0.0427\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9145 - loss: 0.0427\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8956 - loss: 0.0427\n",
      "\u001b[1m 25/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8862 - loss: 0.0423\n",
      "\u001b[1m 30/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8795 - loss: 0.0416\n",
      "\u001b[1m 34/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8770 - loss: 0.0412\n",
      "\u001b[1m 39/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8763 - loss: 0.0409\n",
      "\u001b[1m 44/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8773 - loss: 0.0405\n",
      "\u001b[1m 49/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8790 - loss: 0.0402\n",
      "\u001b[1m 53/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8807 - loss: 0.0400\n",
      "\u001b[1m 58/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8829 - loss: 0.0397\n",
      "\u001b[1m 62/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8846 - loss: 0.0394\n",
      "\u001b[1m 67/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8868 - loss: 0.0391\n",
      "\u001b[1m 71/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8884 - loss: 0.0389\n",
      "\u001b[1m 75/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8900 - loss: 0.0386\n",
      "\u001b[1m 80/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8917 - loss: 0.0384\n",
      "\u001b[1m 85/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8931 - loss: 0.0382\n",
      "\u001b[1m 90/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8942 - loss: 0.0380\n",
      "\u001b[1m 94/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8945 - loss: 0.0379\n",
      "\u001b[1m 97/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8944 - loss: 0.0378\n",
      "\u001b[1m101/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8939 - loss: 0.0377\n",
      "\u001b[1m105/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8933 - loss: 0.0376\n",
      "\u001b[1m110/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8926 - loss: 0.0375\n",
      "\u001b[1m115/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8919 - loss: 0.0374\n",
      "\u001b[1m120/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8913 - loss: 0.0372\n",
      "\u001b[1m125/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8907 - loss: 0.0371\n",
      "\u001b[1m130/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8902 - loss: 0.0369\n",
      "\u001b[1m134/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8900 - loss: 0.0369\n",
      "\u001b[1m139/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8897 - loss: 0.0368\n",
      "\u001b[1m144/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8896 - loss: 0.0367\n",
      "\u001b[1m149/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8895 - loss: 0.0365\n",
      "\u001b[1m153/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8894 - loss: 0.0365\n",
      "\u001b[1m158/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8894 - loss: 0.0363\n",
      "\u001b[1m163/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8895 - loss: 0.0362\n",
      "\u001b[1m168/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8897 - loss: 0.0361\n",
      "\u001b[1m173/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8899 - loss: 0.0360\n",
      "\u001b[1m178/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8902 - loss: 0.0359\n",
      "\u001b[1m183/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8904 - loss: 0.0358\n",
      "\u001b[1m188/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8906 - loss: 0.0358\n",
      "\u001b[1m192/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8907 - loss: 0.0357\n",
      "\u001b[1m196/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8908 - loss: 0.0357\n",
      "\u001b[1m201/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8910 - loss: 0.0356\n",
      "\u001b[1m205/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8912 - loss: 0.0355\n",
      "\u001b[1m209/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8914 - loss: 0.0355\n",
      "\u001b[1m213/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8917 - loss: 0.0354\n",
      "\u001b[1m218/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8920 - loss: 0.0354\n",
      "\u001b[1m223/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8924 - loss: 0.0353\n",
      "\u001b[1m228/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8927 - loss: 0.0352\n",
      "\u001b[1m233/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8931 - loss: 0.0352\n",
      "\u001b[1m238/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8935 - loss: 0.0351\n",
      "\u001b[1m243/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8938 - loss: 0.0350\n",
      "\u001b[1m248/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8942 - loss: 0.0350\n",
      "\u001b[1m253/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8945 - loss: 0.0349\n",
      "\u001b[1m258/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8949 - loss: 0.0349\n",
      "\u001b[1m263/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8952 - loss: 0.0348\n",
      "                                                                                 \n",
      "Epoch 2: val_loss improved from 0.04076 to 0.03850, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8955 - loss: 0.0348 - val_accuracy: 0.9944 - val_loss: 0.0385\n",
      "\n",
      "Epoch 3/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.9375 - loss: 0.0064\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9694 - loss: 0.0208\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9752 - loss: 0.0243\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9792 - loss: 0.0238\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0231\n",
      "\u001b[1m 26/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9829 - loss: 0.0229\n",
      "\u001b[1m 31/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9837 - loss: 0.0230\n",
      "\u001b[1m 36/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9839 - loss: 0.0232\n",
      "\u001b[1m 40/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9835 - loss: 0.0236\n",
      "\u001b[1m 45/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9829 - loss: 0.0239\n",
      "\u001b[1m 50/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9815 - loss: 0.0243\n",
      "\u001b[1m 55/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9795 - loss: 0.0247\n",
      "\u001b[1m 60/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9774 - loss: 0.0251\n",
      "\u001b[1m 64/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9758 - loss: 0.0253\n",
      "\u001b[1m 69/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9739 - loss: 0.0257\n",
      "\u001b[1m 73/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9728 - loss: 0.0259\n",
      "\u001b[1m 78/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9716 - loss: 0.0261\n",
      "\u001b[1m 83/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9706 - loss: 0.0263\n",
      "\u001b[1m 88/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.0265\n",
      "\u001b[1m 93/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0267\n",
      "\u001b[1m 98/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9677 - loss: 0.0268\n",
      "\u001b[1m103/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9663 - loss: 0.0269\n",
      "\u001b[1m108/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: 0.0271\n",
      "\u001b[1m113/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9637 - loss: 0.0272\n",
      "\u001b[1m118/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9625 - loss: 0.0273\n",
      "\u001b[1m122/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9616 - loss: 0.0274\n",
      "\u001b[1m127/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9606 - loss: 0.0275\n",
      "\u001b[1m132/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9596 - loss: 0.0275\n",
      "\u001b[1m137/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9586 - loss: 0.0276\n",
      "\u001b[1m139/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9583 - loss: 0.0276\n",
      "\u001b[1m143/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9577 - loss: 0.0276\n",
      "\u001b[1m147/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9570 - loss: 0.0277\n",
      "\u001b[1m152/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9564 - loss: 0.0277\n",
      "\u001b[1m157/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9557 - loss: 0.0277\n",
      "\u001b[1m162/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9550 - loss: 0.0277\n",
      "\u001b[1m167/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9542 - loss: 0.0277\n",
      "\u001b[1m172/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9535 - loss: 0.0277\n",
      "\u001b[1m177/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9528 - loss: 0.0277\n",
      "\u001b[1m181/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9521 - loss: 0.0277\n",
      "\u001b[1m186/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9513 - loss: 0.0277\n",
      "\u001b[1m191/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9504 - loss: 0.0277\n",
      "\u001b[1m196/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9493 - loss: 0.0277\n",
      "\u001b[1m201/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9481 - loss: 0.0277\n",
      "\u001b[1m206/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9468 - loss: 0.0277\n",
      "\u001b[1m210/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9457 - loss: 0.0277\n",
      "\u001b[1m215/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9442 - loss: 0.0277\n",
      "\u001b[1m220/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9428 - loss: 0.0276\n",
      "\u001b[1m225/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9413 - loss: 0.0276\n",
      "\u001b[1m230/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9399 - loss: 0.0276\n",
      "\u001b[1m235/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9385 - loss: 0.0276\n",
      "\u001b[1m239/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9375 - loss: 0.0276\n",
      "\u001b[1m242/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9368 - loss: 0.0276\n",
      "\u001b[1m247/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9357 - loss: 0.0275\n",
      "\u001b[1m252/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9347 - loss: 0.0275\n",
      "\u001b[1m257/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9337 - loss: 0.0275\n",
      "\u001b[1m261/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9329 - loss: 0.0275\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9319 - loss: 0.0275\n",
      "                                                                                 \n",
      "Epoch 3: val_loss did not improve from 0.03850\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9317 - loss: 0.0275 - val_accuracy: 0.9854 - val_loss: 0.0413\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 16ms/step               \n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step       \n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step      \n",
      "\n",
      "[    0     3     8 ... 12762 12764 12765]                                        \n",
      "Epoch 1/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.8125 - loss: 0.0810\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8354 - loss: 0.0572\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8393 - loss: 0.0461\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8428 - loss: 0.0417\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8488 - loss: 0.0402\n",
      "\u001b[1m 26/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8555 - loss: 0.0398\n",
      "\u001b[1m 31/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8626 - loss: 0.0391\n",
      "\u001b[1m 35/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8679 - loss: 0.0388\n",
      "\u001b[1m 40/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8736 - loss: 0.0387\n",
      "\u001b[1m 45/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8767 - loss: 0.0385\n",
      "\u001b[1m 50/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8768 - loss: 0.0383\n",
      "\u001b[1m 54/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8751 - loss: 0.0381\n",
      "\u001b[1m 59/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8720 - loss: 0.0380\n",
      "\u001b[1m 63/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8692 - loss: 0.0378\n",
      "\u001b[1m 67/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8662 - loss: 0.0377\n",
      "\u001b[1m 70/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8636 - loss: 0.0376\n",
      "\u001b[1m 75/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8588 - loss: 0.0374\n",
      "\u001b[1m 80/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8534 - loss: 0.0372\n",
      "\u001b[1m 84/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8493 - loss: 0.0370\n",
      "\u001b[1m 89/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8451 - loss: 0.0368\n",
      "\u001b[1m 93/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8423 - loss: 0.0367\n",
      "\u001b[1m 98/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8395 - loss: 0.0366\n",
      "\u001b[1m103/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8372 - loss: 0.0364\n",
      "\u001b[1m107/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8359 - loss: 0.0363\n",
      "\u001b[1m112/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8346 - loss: 0.0362\n",
      "\u001b[1m117/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8338 - loss: 0.0361\n",
      "\u001b[1m121/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8333 - loss: 0.0360\n",
      "\u001b[1m126/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8327 - loss: 0.0359\n",
      "\u001b[1m131/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8320 - loss: 0.0358\n",
      "\u001b[1m135/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8314 - loss: 0.0357\n",
      "\u001b[1m139/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8308 - loss: 0.0356\n",
      "\u001b[1m144/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8302 - loss: 0.0355\n",
      "\u001b[1m148/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8299 - loss: 0.0354\n",
      "\u001b[1m152/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8298 - loss: 0.0353\n",
      "\u001b[1m156/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8297 - loss: 0.0353\n",
      "\u001b[1m160/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8297 - loss: 0.0352\n",
      "\u001b[1m165/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8298 - loss: 0.0351\n",
      "\u001b[1m170/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8300 - loss: 0.0350\n",
      "\u001b[1m175/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8303 - loss: 0.0350\n",
      "\u001b[1m180/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8307 - loss: 0.0349\n",
      "\u001b[1m185/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8312 - loss: 0.0349\n",
      "\u001b[1m189/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8317 - loss: 0.0348\n",
      "\u001b[1m194/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8322 - loss: 0.0347\n",
      "\u001b[1m198/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8325 - loss: 0.0347\n",
      "\u001b[1m203/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8329 - loss: 0.0346\n",
      "\u001b[1m208/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8332 - loss: 0.0345\n",
      "\u001b[1m213/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8335 - loss: 0.0345\n",
      "\u001b[1m218/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8337 - loss: 0.0344\n",
      "\u001b[1m223/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8339 - loss: 0.0343\n",
      "\u001b[1m228/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8342 - loss: 0.0343\n",
      "\u001b[1m232/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8343 - loss: 0.0342\n",
      "\u001b[1m235/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8345 - loss: 0.0342\n",
      "\u001b[1m239/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8347 - loss: 0.0342\n",
      "\u001b[1m244/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8348 - loss: 0.0341\n",
      "\u001b[1m249/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8349 - loss: 0.0341\n",
      "\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8349 - loss: 0.0341\n",
      "\u001b[1m258/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8347 - loss: 0.0340\n",
      "\u001b[1m263/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8343 - loss: 0.0340\n",
      "                                                                                 \n",
      "Epoch 1: val_loss improved from inf to 0.02507, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8339 - loss: 0.0340 - val_accuracy: 0.6280 - val_loss: 0.0251\n",
      "\n",
      "Epoch 2/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.6562 - loss: 0.0474\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7641 - loss: 0.0284\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8205 - loss: 0.0257\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8519 - loss: 0.0256\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8712 - loss: 0.0259\n",
      "\u001b[1m 26/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8843 - loss: 0.0257\n",
      "\u001b[1m 31/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8945 - loss: 0.0254\n",
      "\u001b[1m 36/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9023 - loss: 0.0252\n",
      "\u001b[1m 39/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9060 - loss: 0.0250\n",
      "\u001b[1m 43/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9096 - loss: 0.0247\n",
      "\u001b[1m 48/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9124 - loss: 0.0245\n",
      "\u001b[1m 53/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9129 - loss: 0.0244\n",
      "\u001b[1m 58/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9117 - loss: 0.0244\n",
      "\u001b[1m 63/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9096 - loss: 0.0244\n",
      "\u001b[1m 68/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9072 - loss: 0.0244\n",
      "\u001b[1m 73/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9050 - loss: 0.0243\n",
      "\u001b[1m 78/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9031 - loss: 0.0243\n",
      "\u001b[1m 83/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9012 - loss: 0.0244\n",
      "\u001b[1m 88/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8993 - loss: 0.0245\n",
      "\u001b[1m 93/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8969 - loss: 0.0246\n",
      "\u001b[1m 98/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8940 - loss: 0.0246\n",
      "\u001b[1m103/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8915 - loss: 0.0247\n",
      "\u001b[1m108/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8891 - loss: 0.0247\n",
      "\u001b[1m113/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8864 - loss: 0.0248\n",
      "\u001b[1m118/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8833 - loss: 0.0249\n",
      "\u001b[1m122/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8805 - loss: 0.0249\n",
      "\u001b[1m126/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8776 - loss: 0.0249\n",
      "\u001b[1m131/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8741 - loss: 0.0250\n",
      "\u001b[1m136/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8709 - loss: 0.0250\n",
      "\u001b[1m141/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8679 - loss: 0.0251\n",
      "\u001b[1m146/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8652 - loss: 0.0251\n",
      "\u001b[1m151/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8627 - loss: 0.0251\n",
      "\u001b[1m156/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8604 - loss: 0.0251\n",
      "\u001b[1m161/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8583 - loss: 0.0251\n",
      "\u001b[1m166/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8565 - loss: 0.0252\n",
      "\u001b[1m171/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8547 - loss: 0.0252\n",
      "\u001b[1m176/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8530 - loss: 0.0252\n",
      "\u001b[1m181/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8511 - loss: 0.0252\n",
      "\u001b[1m186/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8494 - loss: 0.0253\n",
      "\u001b[1m191/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8478 - loss: 0.0253\n",
      "\u001b[1m196/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8464 - loss: 0.0253\n",
      "\u001b[1m200/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8454 - loss: 0.0253\n",
      "\u001b[1m204/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8444 - loss: 0.0253\n",
      "\u001b[1m209/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8432 - loss: 0.0253\n",
      "\u001b[1m214/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8419 - loss: 0.0253\n",
      "\u001b[1m219/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8407 - loss: 0.0254\n",
      "\u001b[1m224/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8397 - loss: 0.0254\n",
      "\u001b[1m229/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8387 - loss: 0.0254\n",
      "\u001b[1m234/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8379 - loss: 0.0254\n",
      "\u001b[1m239/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8370 - loss: 0.0254\n",
      "\u001b[1m244/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8362 - loss: 0.0254\n",
      "\u001b[1m249/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8354 - loss: 0.0254\n",
      "\u001b[1m254/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8346 - loss: 0.0254\n",
      "\u001b[1m259/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8338 - loss: 0.0254\n",
      "\u001b[1m264/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8330 - loss: 0.0254\n",
      "                                                                                 \n",
      "Epoch 2: val_loss improved from 0.02507 to 0.02316, saving model to best_model_cnn.keras\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8326 - loss: 0.0254 - val_accuracy: 0.9746 - val_loss: 0.0232\n",
      "\n",
      "Epoch 3/3                                                                        \n",
      "\n",
      "\u001b[1m  1/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.8750 - loss: 0.0175\n",
      "\u001b[1m  6/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8582 - loss: 0.0141\n",
      "\u001b[1m 11/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8405 - loss: 0.0140\n",
      "\u001b[1m 16/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8222 - loss: 0.0140\n",
      "\u001b[1m 21/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8131 - loss: 0.0143\n",
      "\u001b[1m 25/266\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8082 - loss: 0.0148\n",
      "\u001b[1m 30/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8032 - loss: 0.0155\n",
      "\u001b[1m 35/266\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7982 - loss: 0.0160\n",
      "\u001b[1m 40/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7934 - loss: 0.0163\n",
      "\u001b[1m 45/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7889 - loss: 0.0165\n",
      "\u001b[1m 50/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7854 - loss: 0.0167\n",
      "\u001b[1m 55/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7834 - loss: 0.0169\n",
      "\u001b[1m 58/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7829 - loss: 0.0170\n",
      "\u001b[1m 62/266\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7828 - loss: 0.0171\n",
      "\u001b[1m 67/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7833 - loss: 0.0172\n",
      "\u001b[1m 72/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7846 - loss: 0.0173\n",
      "\u001b[1m 77/266\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7860 - loss: 0.0174\n",
      "\u001b[1m 82/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7873 - loss: 0.0175\n",
      "\u001b[1m 87/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7885 - loss: 0.0175\n",
      "\u001b[1m 92/266\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7894 - loss: 0.0177\n",
      "\u001b[1m 97/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7900 - loss: 0.0178\n",
      "\u001b[1m101/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7903 - loss: 0.0179\n",
      "\u001b[1m105/266\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7904 - loss: 0.0179\n",
      "\u001b[1m110/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7905 - loss: 0.0180\n",
      "\u001b[1m114/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7906 - loss: 0.0181\n",
      "\u001b[1m118/266\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7907 - loss: 0.0182\n",
      "\u001b[1m123/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7909 - loss: 0.0183\n",
      "\u001b[1m128/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7912 - loss: 0.0183\n",
      "\u001b[1m131/266\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7914 - loss: 0.0184\n",
      "\u001b[1m135/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7916 - loss: 0.0185\n",
      "\u001b[1m140/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7918 - loss: 0.0185\n",
      "\u001b[1m145/266\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7918 - loss: 0.0186\n",
      "\u001b[1m150/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7914 - loss: 0.0186\n",
      "\u001b[1m154/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7909 - loss: 0.0187\n",
      "\u001b[1m158/266\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7901 - loss: 0.0187\n",
      "\u001b[1m163/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7891 - loss: 0.0187\n",
      "\u001b[1m167/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7881 - loss: 0.0187\n",
      "\u001b[1m171/266\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7872 - loss: 0.0188\n",
      "\u001b[1m176/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7861 - loss: 0.0188\n",
      "\u001b[1m181/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7851 - loss: 0.0188\n",
      "\u001b[1m186/266\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7841 - loss: 0.0188\n",
      "\u001b[1m190/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7832 - loss: 0.0189\n",
      "\u001b[1m195/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7819 - loss: 0.0189\n",
      "\u001b[1m198/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7810 - loss: 0.0189\n",
      "\u001b[1m202/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7798 - loss: 0.0189\n",
      "\u001b[1m207/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7781 - loss: 0.0189\n",
      "\u001b[1m212/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7763 - loss: 0.0190\n",
      "\u001b[1m217/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7745 - loss: 0.0190\n",
      "\u001b[1m222/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7726 - loss: 0.0190\n",
      "\u001b[1m227/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7707 - loss: 0.0190\n",
      "\u001b[1m232/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7689 - loss: 0.0191\n",
      "\u001b[1m237/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7670 - loss: 0.0191\n",
      "\u001b[1m242/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7649 - loss: 0.0191\n",
      "\u001b[1m247/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7627 - loss: 0.0192\n",
      "\u001b[1m252/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7604 - loss: 0.0192\n",
      "\u001b[1m257/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7580 - loss: 0.0192\n",
      "\u001b[1m260/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7565 - loss: 0.0192\n",
      "\u001b[1m264/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7547 - loss: 0.0192\n",
      "                                                                                 \n",
      "Epoch 3: val_loss did not improve from 0.02316\n",
      "\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.7533 - loss: 0.0193 - val_accuracy: 0.7969 - val_loss: 0.0273\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 16ms/step               \n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step       \n",
      "\u001b[1m 32/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m106/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step      \n",
      "\u001b[1m128/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step      \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step      \n",
      "\n",
      "100%|██████████| 2/2 [02:40<00:00, 80.45s/trial, best loss: -0.4752855495018105] \n",
      "Best hyperparameters: {'batch_size': 1, 'dense_units': 1, 'dropout_rate': 0.20693163905050424, 'embed_dim': 2, 'epochs': 0, 'filters': 2, 'kernel_size': 0, 'max_len': 1}\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter space\n",
    "space = {\n",
    "    'max_len': hp.choice('max_len', [100, 200, 300]),\n",
    "    'embed_dim': hp.choice('embed_dim', [64, 128, 256]),\n",
    "    'filters': hp.choice('filters', [64, 128, 256]),\n",
    "    'kernel_size': hp.choice('kernel_size', [3, 5, 7]),\n",
    "    'dense_units': hp.choice('dense_units', [64, 128, 256]),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'batch_size': hp.choice('batch_size', [32, 64, 128]),\n",
    "    'epochs': hp.choice('epochs', [3]),\n",
    "}\n",
    "\n",
    "def pad_sequences_custom(sequences, max_len):\n",
    "    return np.array([np.pad(seq, (0, max_len - len(seq)), mode='constant')[:max_len] for seq in sequences])\n",
    "\n",
    "def objective(params):\n",
    "    # Cross-validation setup\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    val_scores_cnn = []\n",
    "    \n",
    "    # Define the CNN model\n",
    "    inputs = Input(shape=(params['max_len'],))\n",
    "    embedding = Embedding(input_dim=max_words, output_dim=params['embed_dim'], input_length=params['max_len'])(inputs)\n",
    "    conv1 = Conv1D(filters=params['filters'], kernel_size=params['kernel_size'], activation='relu')(embedding)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "    conv2 = Conv1D(filters=params['filters'], kernel_size=params['kernel_size'], activation='relu')(pool1)\n",
    "    pool2 = GlobalMaxPooling1D()(conv2)\n",
    "    dense1 = Dense(params['dense_units'], activation='relu')(pool2)\n",
    "    dropout = Dropout(params['dropout_rate'])(dense1)\n",
    "    outputs = Dense(6, activation='sigmoid')(dropout)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_train2):\n",
    "        print(train_index)\n",
    "        X_train_fold, X_val_fold = X_train2[train_index], X_train2[val_index]\n",
    "        y_train_fold, y_val_fold = y_train2[train_index], y_train2[val_index]\n",
    "\n",
    "        # Adjust the input data to match max_len\n",
    "        X_train_fold = pad_sequences_custom(X_train_fold, params['max_len'])\n",
    "        X_val_fold = pad_sequences_custom(X_val_fold, params['max_len'])\n",
    "        \n",
    "        # Define callbacks\n",
    "        checkpoint = ModelCheckpoint('best_model_cnn.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=2, mode='min', verbose=1)\n",
    "\n",
    "        # Train the model\n",
    "        history_cnn = model.fit(X_train_fold, y_train_fold, epochs=params['epochs'], batch_size=params['batch_size'], validation_data=(X_val_fold, y_val_fold), callbacks=[checkpoint, early_stop])\n",
    "\n",
    "        # Evaluate the model\n",
    "        val_preds = model.predict(X_val_fold)\n",
    "        val_preds_binary = (val_preds > 0.5).astype(int)\n",
    "        f1 = f1_score(y_val_fold, val_preds_binary, average='macro')\n",
    "        val_scores_cnn.append(f1)\n",
    "\n",
    "    # Calculate the average F1 score over all folds\n",
    "    avg_f1 = np.mean(val_scores_cnn)\n",
    "    \n",
    "    # Return the negative average F1 score to minimize\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK}\n",
    "\n",
    "# Initialize Trials object to keep track of results\n",
    "trials = Trials()\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "best_cnn = fmin(objective, space, algo=tpe.rand.suggest, max_evals=2, trials=trials)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:', best_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     2     4 ... 12758 12763 12765]            \n",
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:44\u001b[0m 5s/step - accuracy: 0.0078 - loss: 0.6943\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 213ms/step - accuracy: 0.0117 - loss: 0.6907\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 250ms/step - accuracy: 0.0122 - loss: 0.6867\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 246ms/step - accuracy: 0.0135 - loss: 0.6817\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 234ms/step - accuracy: 0.0139 - loss: 0.6755\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 228ms/step - accuracy: 0.0142 - loss: 0.6677\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 224ms/step - accuracy: 0.0149 - loss: 0.6582\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 225ms/step - accuracy: 0.0155 - loss: 0.6475\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 227ms/step - accuracy: 0.0165 - loss: 0.6355\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 225ms/step - accuracy: 0.0182 - loss: 0.6235 \n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 223ms/step - accuracy: 0.0204 - loss: 0.6109\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 221ms/step - accuracy: 0.0226 - loss: 0.5983\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 220ms/step - accuracy: 0.0252 - loss: 0.5860\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 219ms/step - accuracy: 0.0283 - loss: 0.5742\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.0316 - loss: 0.5627\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.0351 - loss: 0.5517\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 217ms/step - accuracy: 0.0393 - loss: 0.5414\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 217ms/step - accuracy: 0.0441 - loss: 0.5317\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 0.0494 - loss: 0.5225\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 0.0552 - loss: 0.5136\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 215ms/step - accuracy: 0.0612 - loss: 0.5052\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 216ms/step - accuracy: 0.0676 - loss: 0.4972\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 216ms/step - accuracy: 0.0740 - loss: 0.4896\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - accuracy: 0.0806 - loss: 0.4826\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - accuracy: 0.0871 - loss: 0.4757\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.0936 - loss: 0.4692\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 0.1001 - loss: 0.4630\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 0.1065 - loss: 0.4570\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.1128 - loss: 0.4513\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.1189 - loss: 0.4458\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 213ms/step - accuracy: 0.1249 - loss: 0.4405\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 213ms/step - accuracy: 0.1307 - loss: 0.4355\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - accuracy: 0.1363 - loss: 0.4305\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - accuracy: 0.1417 - loss: 0.4258\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - accuracy: 0.1469 - loss: 0.4213\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 213ms/step - accuracy: 0.1520 - loss: 0.4168\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 213ms/step - accuracy: 0.1570 - loss: 0.4126\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 212ms/step - accuracy: 0.1619 - loss: 0.4085\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 212ms/step - accuracy: 0.1667 - loss: 0.4045\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - accuracy: 0.1714 - loss: 0.4007\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - accuracy: 0.1760 - loss: 0.3970\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 214ms/step - accuracy: 0.1805 - loss: 0.3935\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - accuracy: 0.1850 - loss: 0.3901\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - accuracy: 0.1893 - loss: 0.3868\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 213ms/step - accuracy: 0.1935 - loss: 0.3836\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 213ms/step - accuracy: 0.1976 - loss: 0.3805\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - accuracy: 0.2016 - loss: 0.3776\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - accuracy: 0.2055 - loss: 0.3747\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - accuracy: 0.2093 - loss: 0.3718\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.2130 - loss: 0.3691\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.2167 - loss: 0.3665\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.2202 - loss: 0.3639\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.2237 - loss: 0.3614\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.2271 - loss: 0.3590\n",
      "                                                     \n",
      "Epoch 1: val_loss improved from inf to 0.16594, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 239ms/step - accuracy: 0.2303 - loss: 0.3567 - val_accuracy: 0.9941 - val_loss: 0.1659\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - accuracy: 0.6328 - loss: 0.1195\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - accuracy: 0.6562 - loss: 0.1261\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.6606 - loss: 0.1296\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 218ms/step - accuracy: 0.6585 - loss: 0.1327\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 212ms/step - accuracy: 0.6546 - loss: 0.1366\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.6495 - loss: 0.1388\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.6447 - loss: 0.1402\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 220ms/step - accuracy: 0.6402 - loss: 0.1412\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - accuracy: 0.6357 - loss: 0.1419 \n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - accuracy: 0.6320 - loss: 0.1422\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - accuracy: 0.6293 - loss: 0.1418\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 225ms/step - accuracy: 0.6270 - loss: 0.1416\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 225ms/step - accuracy: 0.6257 - loss: 0.1415\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 224ms/step - accuracy: 0.6247 - loss: 0.1417\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 223ms/step - accuracy: 0.6237 - loss: 0.1424\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 221ms/step - accuracy: 0.6231 - loss: 0.1430\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 223ms/step - accuracy: 0.6224 - loss: 0.1436\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 224ms/step - accuracy: 0.6218 - loss: 0.1440\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.6213 - loss: 0.1444\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 222ms/step - accuracy: 0.6208 - loss: 0.1449\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.6203 - loss: 0.1452\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.6199 - loss: 0.1455\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.6191 - loss: 0.1457\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.6182 - loss: 0.1460\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.6173 - loss: 0.1464\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.6164 - loss: 0.1468\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - accuracy: 0.6156 - loss: 0.1471\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.6148 - loss: 0.1473\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.6142 - loss: 0.1475\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.6137 - loss: 0.1476\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - accuracy: 0.6133 - loss: 0.1478\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.6130 - loss: 0.1480\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.6127 - loss: 0.1482\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - accuracy: 0.6124 - loss: 0.1484\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.6121 - loss: 0.1486\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 0.6119 - loss: 0.1487\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 0.6117 - loss: 0.1489\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 0.6115 - loss: 0.1490\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 0.6114 - loss: 0.1491\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 0.6114 - loss: 0.1492\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6113 - loss: 0.1493\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6113 - loss: 0.1494\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6113 - loss: 0.1495\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6114 - loss: 0.1496\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.6114 - loss: 0.1497\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.6115 - loss: 0.1498\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.6115 - loss: 0.1499\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.6115 - loss: 0.1500\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.6115 - loss: 0.1501\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6115 - loss: 0.1502\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6115 - loss: 0.1503\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6114 - loss: 0.1504\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6114 - loss: 0.1504\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.6114 - loss: 0.1505\n",
      "                                                     \n",
      "Epoch 2: val_loss improved from 0.16594 to 0.16447, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 235ms/step - accuracy: 0.6114 - loss: 0.1506 - val_accuracy: 0.9941 - val_loss: 0.1645\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 247ms/step - accuracy: 0.6094 - loss: 0.1144\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - accuracy: 0.6504 - loss: 0.1372\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - accuracy: 0.6576 - loss: 0.1409\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 211ms/step - accuracy: 0.6621 - loss: 0.1411\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 210ms/step - accuracy: 0.6616 - loss: 0.1426\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.6609 - loss: 0.1439\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - accuracy: 0.6607 - loss: 0.1436 \n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - accuracy: 0.6603 - loss: 0.1444\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - accuracy: 0.6601 - loss: 0.1449\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - accuracy: 0.6599 - loss: 0.1450\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.6594 - loss: 0.1452\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 211ms/step - accuracy: 0.6594 - loss: 0.1455\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 213ms/step - accuracy: 0.6594 - loss: 0.1457\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.6593 - loss: 0.1459\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 219ms/step - accuracy: 0.6592 - loss: 0.1459\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 219ms/step - accuracy: 0.6593 - loss: 0.1461\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.6596 - loss: 0.1463\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 220ms/step - accuracy: 0.6602 - loss: 0.1464\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 222ms/step - accuracy: 0.6611 - loss: 0.1465\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 222ms/step - accuracy: 0.6620 - loss: 0.1466\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 222ms/step - accuracy: 0.6631 - loss: 0.1466\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 221ms/step - accuracy: 0.6642 - loss: 0.1464\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.6650 - loss: 0.1463\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - accuracy: 0.6656 - loss: 0.1462\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.6660 - loss: 0.1462\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.6662 - loss: 0.1462\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 219ms/step - accuracy: 0.6662 - loss: 0.1461\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.6659 - loss: 0.1461\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.6656 - loss: 0.1461\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.6653 - loss: 0.1462\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.6650 - loss: 0.1461\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - accuracy: 0.6647 - loss: 0.1461\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 221ms/step - accuracy: 0.6645 - loss: 0.1462\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 221ms/step - accuracy: 0.6644 - loss: 0.1462\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 221ms/step - accuracy: 0.6643 - loss: 0.1462\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 0.6643 - loss: 0.1463\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 0.6644 - loss: 0.1463\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 0.6645 - loss: 0.1463\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 221ms/step - accuracy: 0.6646 - loss: 0.1463\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 221ms/step - accuracy: 0.6647 - loss: 0.1463\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6648 - loss: 0.1462\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6649 - loss: 0.1462\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6649 - loss: 0.1461\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - accuracy: 0.6650 - loss: 0.1461\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.6650 - loss: 0.1460\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.6650 - loss: 0.1459\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.6649 - loss: 0.1459\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - accuracy: 0.6649 - loss: 0.1458\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 0.6648 - loss: 0.1458\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6648 - loss: 0.1458\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6647 - loss: 0.1458\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.6646 - loss: 0.1458\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.6646 - loss: 0.1458\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6645 - loss: 0.1458\n",
      "                                                     \n",
      "Epoch 3: val_loss improved from 0.16447 to 0.15471, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 239ms/step - accuracy: 0.6644 - loss: 0.1458 - val_accuracy: 0.9941 - val_loss: 0.1547\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 486ms/step\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step   \n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 27ms/step\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 27ms/step\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step\n",
      "\n",
      "[    0     1     2 ... 12762 12763 12764]            \n",
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 218ms/step - accuracy: 0.7031 - loss: 0.1081\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - accuracy: 0.7148 - loss: 0.1036\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - accuracy: 0.7153 - loss: 0.1023\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 200ms/step - accuracy: 0.7176 - loss: 0.1005 \n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 200ms/step - accuracy: 0.7182 - loss: 0.1017\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 201ms/step - accuracy: 0.7202 - loss: 0.1023\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 201ms/step - accuracy: 0.7210 - loss: 0.1029\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 201ms/step - accuracy: 0.7219 - loss: 0.1042\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 201ms/step - accuracy: 0.7217 - loss: 0.1055\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7211 - loss: 0.1065\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 206ms/step - accuracy: 0.7206 - loss: 0.1076\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.7205 - loss: 0.1084\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.7203 - loss: 0.1091\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 216ms/step - accuracy: 0.7201 - loss: 0.1097\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 217ms/step - accuracy: 0.7197 - loss: 0.1104\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 220ms/step - accuracy: 0.7195 - loss: 0.1113\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 223ms/step - accuracy: 0.7189 - loss: 0.1121\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 226ms/step - accuracy: 0.7182 - loss: 0.1129\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.7174 - loss: 0.1137\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.7165 - loss: 0.1144\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 233ms/step - accuracy: 0.7157 - loss: 0.1150\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 233ms/step - accuracy: 0.7147 - loss: 0.1157\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 238ms/step - accuracy: 0.7138 - loss: 0.1163\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 239ms/step - accuracy: 0.7127 - loss: 0.1169\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.7115 - loss: 0.1175\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 240ms/step - accuracy: 0.7102 - loss: 0.1181\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.7089 - loss: 0.1185\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.7077 - loss: 0.1190\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 239ms/step - accuracy: 0.7064 - loss: 0.1194\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 239ms/step - accuracy: 0.7051 - loss: 0.1198\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 238ms/step - accuracy: 0.7040 - loss: 0.1201\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 238ms/step - accuracy: 0.7030 - loss: 0.1204\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 238ms/step - accuracy: 0.7020 - loss: 0.1206\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 241ms/step - accuracy: 0.7011 - loss: 0.1209\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 241ms/step - accuracy: 0.7002 - loss: 0.1212\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 241ms/step - accuracy: 0.6995 - loss: 0.1214\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 239ms/step - accuracy: 0.6987 - loss: 0.1217\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - accuracy: 0.6981 - loss: 0.1219\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - accuracy: 0.6975 - loss: 0.1221\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - accuracy: 0.6971 - loss: 0.1223\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - accuracy: 0.6966 - loss: 0.1225\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - accuracy: 0.6963 - loss: 0.1226\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - accuracy: 0.6961 - loss: 0.1228\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - accuracy: 0.6959 - loss: 0.1229\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 233ms/step - accuracy: 0.6957 - loss: 0.1230\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 232ms/step - accuracy: 0.6955 - loss: 0.1232\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 231ms/step - accuracy: 0.6953 - loss: 0.1233\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 231ms/step - accuracy: 0.6951 - loss: 0.1234\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 230ms/step - accuracy: 0.6948 - loss: 0.1235\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6945 - loss: 0.1236\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.6942 - loss: 0.1237\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6938 - loss: 0.1238\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.6934 - loss: 0.1239\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.6930 - loss: 0.1240\n",
      "                                                     \n",
      "Epoch 1: val_loss improved from inf to 0.11279, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 244ms/step - accuracy: 0.6926 - loss: 0.1241 - val_accuracy: 0.9971 - val_loss: 0.1128\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - accuracy: 0.6094 - loss: 0.0896\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 212ms/step - accuracy: 0.6172 - loss: 0.0971\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - accuracy: 0.6259 - loss: 0.0974\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - accuracy: 0.6291 - loss: 0.0978\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - accuracy: 0.6320 - loss: 0.0989\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 205ms/step - accuracy: 0.6350 - loss: 0.0998 \n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 205ms/step - accuracy: 0.6382 - loss: 0.1010\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.6407 - loss: 0.1019\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 209ms/step - accuracy: 0.6417 - loss: 0.1022\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 208ms/step - accuracy: 0.6431 - loss: 0.1024\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.6447 - loss: 0.1025\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 208ms/step - accuracy: 0.6460 - loss: 0.1027\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.6476 - loss: 0.1032\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 206ms/step - accuracy: 0.6490 - loss: 0.1034\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.6501 - loss: 0.1036\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 208ms/step - accuracy: 0.6511 - loss: 0.1037\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.6520 - loss: 0.1038\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.6529 - loss: 0.1039\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.6539 - loss: 0.1039\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.6546 - loss: 0.1038\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - accuracy: 0.6555 - loss: 0.1038\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - accuracy: 0.6563 - loss: 0.1038\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.6570 - loss: 0.1037\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.6576 - loss: 0.1037\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 208ms/step - accuracy: 0.6583 - loss: 0.1036\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.6588 - loss: 0.1036\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.6592 - loss: 0.1036\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - accuracy: 0.6596 - loss: 0.1036\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 208ms/step - accuracy: 0.6598 - loss: 0.1036\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.6602 - loss: 0.1036\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.6604 - loss: 0.1036\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.6607 - loss: 0.1036\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.6608 - loss: 0.1036\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - accuracy: 0.6609 - loss: 0.1036\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.6610 - loss: 0.1035\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.6611 - loss: 0.1035\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.6611 - loss: 0.1034\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.6610 - loss: 0.1033\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 207ms/step - accuracy: 0.6610 - loss: 0.1033\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - accuracy: 0.6610 - loss: 0.1032\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.6611 - loss: 0.1031\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.6611 - loss: 0.1031\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.6612 - loss: 0.1030\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.6613 - loss: 0.1029\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.6615 - loss: 0.1028\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.6617 - loss: 0.1027\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.6620 - loss: 0.1026\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.6622 - loss: 0.1025\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.6625 - loss: 0.1024\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6628 - loss: 0.1023\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6631 - loss: 0.1022\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6635 - loss: 0.1021\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.6639 - loss: 0.1020\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6642 - loss: 0.1019\n",
      "                                                     \n",
      "Epoch 2: val_loss improved from 0.11279 to 0.09569, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 225ms/step - accuracy: 0.6646 - loss: 0.1018 - val_accuracy: 0.9971 - val_loss: 0.0957\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 267ms/step - accuracy: 0.7578 - loss: 0.0609\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 228ms/step - accuracy: 0.7637 - loss: 0.0594\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 220ms/step - accuracy: 0.7773 - loss: 0.0601\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 218ms/step - accuracy: 0.7861 - loss: 0.0636\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.7933 - loss: 0.0646\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.7976 - loss: 0.0648\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.8010 - loss: 0.0651\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.8034 - loss: 0.0652 \n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.8057 - loss: 0.0653\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - accuracy: 0.8077 - loss: 0.0656\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.8097 - loss: 0.0656\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 214ms/step - accuracy: 0.8115 - loss: 0.0655\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 213ms/step - accuracy: 0.8126 - loss: 0.0654\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 213ms/step - accuracy: 0.8136 - loss: 0.0656\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 212ms/step - accuracy: 0.8141 - loss: 0.0658\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 211ms/step - accuracy: 0.8144 - loss: 0.0659\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.8146 - loss: 0.0659\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.8148 - loss: 0.0662\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 212ms/step - accuracy: 0.8149 - loss: 0.0663\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.8149 - loss: 0.0665\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 212ms/step - accuracy: 0.8149 - loss: 0.0667\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.8149 - loss: 0.0669\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.8148 - loss: 0.0671\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 211ms/step - accuracy: 0.8145 - loss: 0.0672\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.8142 - loss: 0.0673\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.8138 - loss: 0.0673\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - accuracy: 0.8133 - loss: 0.0674\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - accuracy: 0.8128 - loss: 0.0676\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.8123 - loss: 0.0677\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.8118 - loss: 0.0678\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.8113 - loss: 0.0678\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.8107 - loss: 0.0679\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.8101 - loss: 0.0680\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.8094 - loss: 0.0680\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - accuracy: 0.8087 - loss: 0.0681\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 211ms/step - accuracy: 0.8080 - loss: 0.0681\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - accuracy: 0.8073 - loss: 0.0682\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - accuracy: 0.8066 - loss: 0.0682\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - accuracy: 0.8059 - loss: 0.0682\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - accuracy: 0.8052 - loss: 0.0682\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - accuracy: 0.8045 - loss: 0.0682\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - accuracy: 0.8038 - loss: 0.0682\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.8032 - loss: 0.0682\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.8025 - loss: 0.0681\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - accuracy: 0.8018 - loss: 0.0681\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - accuracy: 0.8012 - loss: 0.0681\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - accuracy: 0.8006 - loss: 0.0680\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.8000 - loss: 0.0680\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.7995 - loss: 0.0679\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7989 - loss: 0.0679\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7984 - loss: 0.0678\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7980 - loss: 0.0678\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7975 - loss: 0.0677\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.7971 - loss: 0.0677\n",
      "                                                     \n",
      "Epoch 3: val_loss improved from 0.09569 to 0.08326, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 225ms/step - accuracy: 0.7966 - loss: 0.0676 - val_accuracy: 0.9971 - val_loss: 0.0833\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 39ms/step\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 27ms/step\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step\n",
      "\n",
      "[    0     3     8 ... 12762 12764 12765]            \n",
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - accuracy: 0.8281 - loss: 0.0549\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - accuracy: 0.8086 - loss: 0.0649\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.7908 - loss: 0.0662\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - accuracy: 0.7845 - loss: 0.0671\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.7829 - loss: 0.0678\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 206ms/step - accuracy: 0.7829 - loss: 0.0685 \n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.7834 - loss: 0.0693\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.7843 - loss: 0.0693\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.7840 - loss: 0.0690\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.7838 - loss: 0.0685\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.7833 - loss: 0.0681\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.7818 - loss: 0.0678\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 206ms/step - accuracy: 0.7803 - loss: 0.0676\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 206ms/step - accuracy: 0.7788 - loss: 0.0673\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.7774 - loss: 0.0672\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 208ms/step - accuracy: 0.7761 - loss: 0.0670\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.7751 - loss: 0.0667\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.7743 - loss: 0.0665\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.7738 - loss: 0.0664\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 210ms/step - accuracy: 0.7735 - loss: 0.0663\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.7734 - loss: 0.0661\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.7735 - loss: 0.0659\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - accuracy: 0.7737 - loss: 0.0657\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.7740 - loss: 0.0656\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.7744 - loss: 0.0655\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.7747 - loss: 0.0654\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.7750 - loss: 0.0653\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.7753 - loss: 0.0653\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - accuracy: 0.7756 - loss: 0.0652\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - accuracy: 0.7760 - loss: 0.0651\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.7763 - loss: 0.0650\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.7766 - loss: 0.0649\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.7769 - loss: 0.0648\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.7772 - loss: 0.0647\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - accuracy: 0.7775 - loss: 0.0645\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - accuracy: 0.7778 - loss: 0.0645\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - accuracy: 0.7781 - loss: 0.0644\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - accuracy: 0.7784 - loss: 0.0643\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - accuracy: 0.7787 - loss: 0.0642\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.7790 - loss: 0.0642\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.7792 - loss: 0.0641\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.7794 - loss: 0.0640\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.7796 - loss: 0.0640\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.7798 - loss: 0.0639\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.7800 - loss: 0.0639\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - accuracy: 0.7803 - loss: 0.0639\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - accuracy: 0.7805 - loss: 0.0639\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.7807 - loss: 0.0638\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 0.7810 - loss: 0.0638\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7813 - loss: 0.0638\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7816 - loss: 0.0637\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7820 - loss: 0.0637\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7823 - loss: 0.0637\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.7827 - loss: 0.0637\n",
      "                                                     \n",
      "Epoch 1: val_loss improved from inf to 0.07079, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 226ms/step - accuracy: 0.7831 - loss: 0.0636 - val_accuracy: 0.9947 - val_loss: 0.0708\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 232ms/step - accuracy: 0.8906 - loss: 0.0335\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - accuracy: 0.8984 - loss: 0.0308\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 224ms/step - accuracy: 0.8993 - loss: 0.0324\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 217ms/step - accuracy: 0.8986 - loss: 0.0344\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 216ms/step - accuracy: 0.8983 - loss: 0.0354\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.8965 - loss: 0.0357\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.8939 - loss: 0.0361 \n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.8910 - loss: 0.0366\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.8881 - loss: 0.0376\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.8853 - loss: 0.0383\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 210ms/step - accuracy: 0.8827 - loss: 0.0390\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 209ms/step - accuracy: 0.8807 - loss: 0.0395\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - accuracy: 0.8791 - loss: 0.0399\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - accuracy: 0.8778 - loss: 0.0403\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - accuracy: 0.8769 - loss: 0.0407\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - accuracy: 0.8762 - loss: 0.0410\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 216ms/step - accuracy: 0.8756 - loss: 0.0411\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 217ms/step - accuracy: 0.8751 - loss: 0.0413\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 218ms/step - accuracy: 0.8748 - loss: 0.0415\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 218ms/step - accuracy: 0.8744 - loss: 0.0416\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.8739 - loss: 0.0417\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 219ms/step - accuracy: 0.8736 - loss: 0.0417\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.8731 - loss: 0.0419\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.8727 - loss: 0.0420\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.8723 - loss: 0.0422\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.8719 - loss: 0.0423\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.8717 - loss: 0.0425\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.8714 - loss: 0.0427\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.8712 - loss: 0.0429\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.8711 - loss: 0.0431\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.8710 - loss: 0.0433\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - accuracy: 0.8709 - loss: 0.0434\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 220ms/step - accuracy: 0.8708 - loss: 0.0436\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.8709 - loss: 0.0438\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.8709 - loss: 0.0440\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 0.8710 - loss: 0.0442\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - accuracy: 0.8712 - loss: 0.0443\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - accuracy: 0.8713 - loss: 0.0444\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - accuracy: 0.8715 - loss: 0.0446\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 218ms/step - accuracy: 0.8716 - loss: 0.0447\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - accuracy: 0.8717 - loss: 0.0448\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - accuracy: 0.8718 - loss: 0.0449\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - accuracy: 0.8718 - loss: 0.0451\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - accuracy: 0.8718 - loss: 0.0452\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.8718 - loss: 0.0453\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.8718 - loss: 0.0453\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.8718 - loss: 0.0454\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.8718 - loss: 0.0455\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.8717 - loss: 0.0456\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.8717 - loss: 0.0457\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.8716 - loss: 0.0457\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.8715 - loss: 0.0458\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.8714 - loss: 0.0459\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.8714 - loss: 0.0459\n",
      "                                                     \n",
      "Epoch 2: val_loss did not improve from 0.07079\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 230ms/step - accuracy: 0.8713 - loss: 0.0460 - val_accuracy: 0.9947 - val_loss: 0.0768\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 38ms/step\n",
      "\u001b[1m  3/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m  5/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 31ms/step\n",
      "\u001b[1m  7/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step\n",
      "\u001b[1m  9/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 13/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n",
      "\u001b[1m 17/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 19/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 23/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m 27/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 29/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 33/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 35/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 37/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 39/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 45/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 47/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 49/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 55/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 59/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m 65/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 67/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 69/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 77/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 93/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 97/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m101/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m105/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m111/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m115/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m123/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m125/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m127/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step\n",
      "\n",
      "[    1     2     4 ... 12758 12763 12765]                                         \n",
      " 50%|█████     | 1/2 [02:00<02:00, 120.79s/trial, best loss: -0.23911120151419962]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:37\u001b[0m 6s/step - accuracy: 0.0234 - loss: 0.6935\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.0234 - loss: 0.6898\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.0252 - loss: 0.6863\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.0282 - loss: 0.6827\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.0316 - loss: 0.6789\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.0344 - loss: 0.6753\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.0373 - loss: 0.6715\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.0399 - loss: 0.6675\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.0421 - loss: 0.6634\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.0436 - loss: 0.6594\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.0453 - loss: 0.6554\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.0469 - loss: 0.6513\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.0487 - loss: 0.6473\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.0505 - loss: 0.6433\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.0524 - loss: 0.6393\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.0539 - loss: 0.6353\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.0553 - loss: 0.6314\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.0566 - loss: 0.6275\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0579 - loss: 0.6236\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0591 - loss: 0.6197\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.0601 - loss: 0.6158\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.0610 - loss: 0.6120\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.0620 - loss: 0.6082\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0628 - loss: 0.6045\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0635 - loss: 0.6008\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0641 - loss: 0.5972\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0647 - loss: 0.5935\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0652 - loss: 0.5900\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.0657 - loss: 0.5864\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.0662 - loss: 0.5829\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.0666 - loss: 0.5794\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.0670 - loss: 0.5760\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.0673 - loss: 0.5726\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.0676 - loss: 0.5692\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0680 - loss: 0.5659\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0683 - loss: 0.5626\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0686 - loss: 0.5594\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0689 - loss: 0.5562\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0692 - loss: 0.5530\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0695 - loss: 0.5498\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0697 - loss: 0.5467\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0700 - loss: 0.5437\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0703 - loss: 0.5406\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0706 - loss: 0.5376\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0710 - loss: 0.5346\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0713 - loss: 0.5317\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.0717 - loss: 0.5288\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0720 - loss: 0.5259\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0724 - loss: 0.5231\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0729 - loss: 0.5204\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0734 - loss: 0.5177\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0739 - loss: 0.5150\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0745 - loss: 0.5123\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0751 - loss: 0.5098\n",
      "                                                                                  \n",
      "Epoch 1: val_loss improved from inf to 0.17395, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.0756 - loss: 0.5074 - val_accuracy: 0.9941 - val_loss: 0.1739\n",
      "\n",
      "Epoch 2/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.2969 - loss: 0.2034\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.3066 - loss: 0.2032 \n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.3190 - loss: 0.2004\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.3286 - loss: 0.1970\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.3345 - loss: 0.1950\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.3410 - loss: 0.1953\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3487 - loss: 0.1972\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3549 - loss: 0.1976\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3605 - loss: 0.1971\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3650 - loss: 0.1962\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3688 - loss: 0.1951\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.3717 - loss: 0.1946\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3742 - loss: 0.1940\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3766 - loss: 0.1939\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3787 - loss: 0.1936\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.3806 - loss: 0.1936\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.3824 - loss: 0.1934\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3844 - loss: 0.1936\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.3860 - loss: 0.1936\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.3874 - loss: 0.1935\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.3890 - loss: 0.1933\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.3904 - loss: 0.1931\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3918 - loss: 0.1930\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3931 - loss: 0.1930\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3942 - loss: 0.1930\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3953 - loss: 0.1930\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3962 - loss: 0.1930\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3972 - loss: 0.1930\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.3981 - loss: 0.1929\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.3991 - loss: 0.1929\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4000 - loss: 0.1928\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4009 - loss: 0.1928\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4017 - loss: 0.1927\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4025 - loss: 0.1927\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4032 - loss: 0.1926\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4040 - loss: 0.1926\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4048 - loss: 0.1925\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4056 - loss: 0.1925\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.4064 - loss: 0.1925\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.4071 - loss: 0.1924\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.4078 - loss: 0.1924\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4084 - loss: 0.1924\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4091 - loss: 0.1924\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4098 - loss: 0.1923\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4105 - loss: 0.1923\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4111 - loss: 0.1923\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4118 - loss: 0.1924\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4124 - loss: 0.1924\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4131 - loss: 0.1924\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4137 - loss: 0.1925\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4143 - loss: 0.1925\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4150 - loss: 0.1925\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4156 - loss: 0.1925\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4163 - loss: 0.1925\n",
      "                                                                                  \n",
      "Epoch 2: val_loss improved from 0.17395 to 0.16939, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.4169 - loss: 0.1925 - val_accuracy: 0.9941 - val_loss: 0.1694\n",
      "\n",
      "Epoch 3/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.3984 - loss: 0.1674\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.4297 - loss: 0.1738 \n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.4427 - loss: 0.1773\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4531 - loss: 0.1813\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4603 - loss: 0.1814\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4656 - loss: 0.1814\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4683 - loss: 0.1818\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.4710 - loss: 0.1815\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.4727 - loss: 0.1818\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.4743 - loss: 0.1824\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.4762 - loss: 0.1825\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.4775 - loss: 0.1826\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4786 - loss: 0.1827\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4798 - loss: 0.1828\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4808 - loss: 0.1829\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4813 - loss: 0.1829\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.4819 - loss: 0.1828\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.4823 - loss: 0.1826\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4827 - loss: 0.1824\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4831 - loss: 0.1823\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4836 - loss: 0.1821\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4840 - loss: 0.1819\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4843 - loss: 0.1817\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4846 - loss: 0.1816\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4848 - loss: 0.1814\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4850 - loss: 0.1813\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4852 - loss: 0.1810\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4853 - loss: 0.1807\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.4854 - loss: 0.1805\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.4854 - loss: 0.1802\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4852 - loss: 0.1799\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4851 - loss: 0.1797\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4850 - loss: 0.1794\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4848 - loss: 0.1793\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4847 - loss: 0.1792\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4846 - loss: 0.1792\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4845 - loss: 0.1792\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4845 - loss: 0.1792\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4844 - loss: 0.1792\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4843 - loss: 0.1792\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4843 - loss: 0.1792\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4843 - loss: 0.1792\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4843 - loss: 0.1792\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4843 - loss: 0.1792\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4843 - loss: 0.1792\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4844 - loss: 0.1791\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4844 - loss: 0.1791\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4845 - loss: 0.1790\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4846 - loss: 0.1790\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4847 - loss: 0.1789\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4849 - loss: 0.1788\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4850 - loss: 0.1788\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4851 - loss: 0.1787\n",
      "                                                                                  \n",
      "Epoch 3: val_loss improved from 0.16939 to 0.16440, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.4854 - loss: 0.1786 - val_accuracy: 0.9941 - val_loss: 0.1644\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 524ms/step             \n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step               \n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step       \n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step       \n",
      "\u001b[1m 36/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step       \n",
      "\u001b[1m 41/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step       \n",
      "\u001b[1m 46/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 51/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 56/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 76/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 81/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step       \n",
      "\u001b[1m 85/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m109/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m114/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m119/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m124/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m129/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step       \n",
      "\n",
      "[    0     1     2 ... 12762 12763 12764]                                         \n",
      "Epoch 1/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.5156 - loss: 0.1658\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5215 - loss: 0.1673\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.5239 - loss: 0.1689\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.5194 - loss: 0.1696\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5158 - loss: 0.1719\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5138 - loss: 0.1730\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5133 - loss: 0.1742\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5115 - loss: 0.1751\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5096 - loss: 0.1754\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5083 - loss: 0.1753\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5075 - loss: 0.1751\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5066 - loss: 0.1744\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.5059 - loss: 0.1736\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5052 - loss: 0.1727\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5046 - loss: 0.1716\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5042 - loss: 0.1707\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5035 - loss: 0.1698\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5028 - loss: 0.1692\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5019 - loss: 0.1687\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5012 - loss: 0.1682\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5005 - loss: 0.1676\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.4997 - loss: 0.1672\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.4990 - loss: 0.1669\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.4983 - loss: 0.1665\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.4976 - loss: 0.1661\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.4969 - loss: 0.1657\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.4963 - loss: 0.1654\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.4957 - loss: 0.1651\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.4952 - loss: 0.1650\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4947 - loss: 0.1648\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4943 - loss: 0.1646\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4940 - loss: 0.1644\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4938 - loss: 0.1642\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4936 - loss: 0.1640\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4935 - loss: 0.1638\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4935 - loss: 0.1636\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4935 - loss: 0.1634\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4936 - loss: 0.1632\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4937 - loss: 0.1630\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4938 - loss: 0.1628\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.4940 - loss: 0.1626\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4942 - loss: 0.1624\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4944 - loss: 0.1622\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4946 - loss: 0.1619\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4948 - loss: 0.1617\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4950 - loss: 0.1615\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4952 - loss: 0.1613\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4954 - loss: 0.1610\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.4957 - loss: 0.1608\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4960 - loss: 0.1605\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4963 - loss: 0.1603\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4965 - loss: 0.1601\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4968 - loss: 0.1599\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4970 - loss: 0.1598\n",
      "                                                                                  \n",
      "Epoch 1: val_loss improved from inf to 0.11575, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.4973 - loss: 0.1596 - val_accuracy: 0.9971 - val_loss: 0.1158\n",
      "\n",
      "Epoch 2/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.6094 - loss: 0.1192\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.6113 - loss: 0.1251 \n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.6072 - loss: 0.1276\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6073 - loss: 0.1270\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6074 - loss: 0.1278\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6064 - loss: 0.1276\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6060 - loss: 0.1275\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.6039 - loss: 0.1280\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6019 - loss: 0.1283\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6005 - loss: 0.1288\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5989 - loss: 0.1291\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5978 - loss: 0.1294\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5971 - loss: 0.1296\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5964 - loss: 0.1299\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5960 - loss: 0.1303\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5957 - loss: 0.1306\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5953 - loss: 0.1309\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5946 - loss: 0.1309\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5937 - loss: 0.1308\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5929 - loss: 0.1307\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5920 - loss: 0.1305\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5913 - loss: 0.1303\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5905 - loss: 0.1300\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5897 - loss: 0.1299\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5890 - loss: 0.1298\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5882 - loss: 0.1296\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5874 - loss: 0.1295\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5866 - loss: 0.1293\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5858 - loss: 0.1292\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5851 - loss: 0.1290\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5843 - loss: 0.1287\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5836 - loss: 0.1285\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5830 - loss: 0.1282\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5824 - loss: 0.1280\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5818 - loss: 0.1277\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5813 - loss: 0.1274\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5807 - loss: 0.1271\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5801 - loss: 0.1268\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5795 - loss: 0.1265\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5790 - loss: 0.1262\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5785 - loss: 0.1259\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5780 - loss: 0.1256\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5775 - loss: 0.1253\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5770 - loss: 0.1250\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5765 - loss: 0.1247\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5760 - loss: 0.1244\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5754 - loss: 0.1241\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5749 - loss: 0.1238\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5744 - loss: 0.1236\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5738 - loss: 0.1233\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5733 - loss: 0.1230\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5728 - loss: 0.1227\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5723 - loss: 0.1224\n",
      "                                                                                  \n",
      "Epoch 2: val_loss improved from 0.11575 to 0.07148, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.5714 - loss: 0.1219 - val_accuracy: 0.9965 - val_loss: 0.0715\n",
      "\n",
      "Epoch 3/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.5625 - loss: 0.0766\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.5703 - loss: 0.0831\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.5625 - loss: 0.0864\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.5625 - loss: 0.0864\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.5647 - loss: 0.0865\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.5663 - loss: 0.0862\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.5669 - loss: 0.0857\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.5666 - loss: 0.0854\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.5668 - loss: 0.0850\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.5663 - loss: 0.0847\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5658 - loss: 0.0842\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5653 - loss: 0.0836\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.5647 - loss: 0.0831\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5639 - loss: 0.0825\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5631 - loss: 0.0819\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5622 - loss: 0.0813\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.5613 - loss: 0.0807\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5604 - loss: 0.0801\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5593 - loss: 0.0796\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5584 - loss: 0.0790\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5574 - loss: 0.0785\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5565 - loss: 0.0780\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.5556 - loss: 0.0775\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.5549 - loss: 0.0771\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.5542 - loss: 0.0767\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5537 - loss: 0.0763\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5533 - loss: 0.0760\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5529 - loss: 0.0757\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5526 - loss: 0.0754\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5524 - loss: 0.0751\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5523 - loss: 0.0748\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5522 - loss: 0.0746\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5521 - loss: 0.0744\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5521 - loss: 0.0741\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5521 - loss: 0.0739\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5522 - loss: 0.0737\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.5523 - loss: 0.0735\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5524 - loss: 0.0733\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5526 - loss: 0.0731\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5528 - loss: 0.0729\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5530 - loss: 0.0727\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.5533 - loss: 0.0725\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5536 - loss: 0.0723\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5539 - loss: 0.0721\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5542 - loss: 0.0720\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5545 - loss: 0.0718\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5548 - loss: 0.0716\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5552 - loss: 0.0715\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5556 - loss: 0.0713\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5561 - loss: 0.0712\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5566 - loss: 0.0710\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5571 - loss: 0.0709\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5576 - loss: 0.0708\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5581 - loss: 0.0707\n",
      "                                                                                  \n",
      "Epoch 3: val_loss improved from 0.07148 to 0.06120, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.5586 - loss: 0.0706 - val_accuracy: 0.9900 - val_loss: 0.0612\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 30ms/step                \n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step                \n",
      "\u001b[1m 10/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 15/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 20/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 25/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 30/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 57/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 61/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 66/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 71/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 75/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 79/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 84/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 89/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 94/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m104/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m108/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m113/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m118/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m122/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m130/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step       \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step       \n",
      "\n",
      "[    0     3     8 ... 12762 12764 12765]                                         \n",
      "Epoch 1/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.6562 - loss: 0.0476\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6680 - loss: 0.0537 \n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.6762 - loss: 0.0556\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.6829 - loss: 0.0556\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.6860 - loss: 0.0559\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6885 - loss: 0.0568\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6913 - loss: 0.0575\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6934 - loss: 0.0585\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6948 - loss: 0.0591\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6962 - loss: 0.0596\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6971 - loss: 0.0598\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6976 - loss: 0.0601\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6981 - loss: 0.0603\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6988 - loss: 0.0603\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6997 - loss: 0.0604\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7008 - loss: 0.0604\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7019 - loss: 0.0604\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7029 - loss: 0.0605\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7039 - loss: 0.0605\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7047 - loss: 0.0605\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7053 - loss: 0.0605\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7060 - loss: 0.0605\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7066 - loss: 0.0605\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7073 - loss: 0.0605\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7079 - loss: 0.0605\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7085 - loss: 0.0605\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7092 - loss: 0.0604\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7099 - loss: 0.0604\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7106 - loss: 0.0604\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7113 - loss: 0.0605\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7120 - loss: 0.0605\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7127 - loss: 0.0605\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7135 - loss: 0.0606\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7142 - loss: 0.0606\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7150 - loss: 0.0606\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7157 - loss: 0.0606\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7164 - loss: 0.0606\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7173 - loss: 0.0606\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7181 - loss: 0.0606\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7189 - loss: 0.0606\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7197 - loss: 0.0606\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.7205 - loss: 0.0606\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7213 - loss: 0.0606\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7220 - loss: 0.0606\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7227 - loss: 0.0606\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7234 - loss: 0.0605\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7240 - loss: 0.0605\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7246 - loss: 0.0605\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7252 - loss: 0.0605\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7258 - loss: 0.0605\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7264 - loss: 0.0605\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7269 - loss: 0.0605\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7274 - loss: 0.0605\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7279 - loss: 0.0605\n",
      "                                                                                  \n",
      "Epoch 1: val_loss improved from inf to 0.06312, saving model to save_best_model_lstm.keras\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.7284 - loss: 0.0604 - val_accuracy: 0.9947 - val_loss: 0.0631\n",
      "\n",
      "Epoch 2/3                                                                         \n",
      "\n",
      "\u001b[1m 1/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.7578 - loss: 0.0461\n",
      "\u001b[1m 2/54\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.7441 - loss: 0.0478\n",
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.7383 - loss: 0.0524\n",
      "\u001b[1m 4/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.7388 - loss: 0.0543\n",
      "\u001b[1m 5/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.7391 - loss: 0.0553\n",
      "\u001b[1m 6/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7394 - loss: 0.0558\n",
      "\u001b[1m 7/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7393 - loss: 0.0557\n",
      "\u001b[1m 8/54\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7397 - loss: 0.0553\n",
      "\u001b[1m 9/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7403 - loss: 0.0551\n",
      "\u001b[1m10/54\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.7409 - loss: 0.0546\n",
      "\u001b[1m11/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.7420 - loss: 0.0541\n",
      "\u001b[1m12/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7428 - loss: 0.0536\n",
      "\u001b[1m13/54\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7434 - loss: 0.0533\n",
      "\u001b[1m14/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7438 - loss: 0.0531\n",
      "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7441 - loss: 0.0529\n",
      "\u001b[1m16/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7443 - loss: 0.0527\n",
      "\u001b[1m17/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7445 - loss: 0.0526\n",
      "\u001b[1m18/54\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7446 - loss: 0.0524\n",
      "\u001b[1m19/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7445 - loss: 0.0523\n",
      "\u001b[1m20/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7443 - loss: 0.0522\n",
      "\u001b[1m21/54\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7441 - loss: 0.0520\n",
      "\u001b[1m22/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7440 - loss: 0.0519\n",
      "\u001b[1m23/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7440 - loss: 0.0518\n",
      "\u001b[1m24/54\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7441 - loss: 0.0517\n",
      "\u001b[1m25/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7443 - loss: 0.0516\n",
      "\u001b[1m26/54\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7446 - loss: 0.0515\n",
      "\u001b[1m27/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7449 - loss: 0.0515\n",
      "\u001b[1m28/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7451 - loss: 0.0514\n",
      "\u001b[1m29/54\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.7453 - loss: 0.0513\n",
      "\u001b[1m30/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.7455 - loss: 0.0512\n",
      "\u001b[1m31/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7457 - loss: 0.0511\n",
      "\u001b[1m32/54\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7458 - loss: 0.0510\n",
      "\u001b[1m33/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7460 - loss: 0.0508\n",
      "\u001b[1m34/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7461 - loss: 0.0507\n",
      "\u001b[1m35/54\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7462 - loss: 0.0506\n",
      "\u001b[1m36/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7463 - loss: 0.0505\n",
      "\u001b[1m37/54\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7465 - loss: 0.0504\n",
      "\u001b[1m38/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7467 - loss: 0.0503\n",
      "\u001b[1m39/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7469 - loss: 0.0502\n",
      "\u001b[1m40/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7471 - loss: 0.0502\n",
      "\u001b[1m41/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.7473 - loss: 0.0501\n",
      "\u001b[1m42/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7476 - loss: 0.0500\n",
      "\u001b[1m43/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7478 - loss: 0.0500\n",
      "\u001b[1m44/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7481 - loss: 0.0500\n",
      "\u001b[1m45/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7484 - loss: 0.0499\n",
      "\u001b[1m46/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7488 - loss: 0.0499\n",
      "\u001b[1m47/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7491 - loss: 0.0499\n",
      "\u001b[1m48/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7494 - loss: 0.0499\n",
      "\u001b[1m49/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7498 - loss: 0.0499\n",
      "\u001b[1m50/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7501 - loss: 0.0499\n",
      "\u001b[1m51/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7505 - loss: 0.0498\n",
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7509 - loss: 0.0498\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7513 - loss: 0.0498\n",
      "                                                                                  \n",
      "Epoch 2: val_loss did not improve from 0.06312\n",
      "\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7520 - loss: 0.0498 - val_accuracy: 0.9947 - val_loss: 0.0659\n",
      "\n",
      "\u001b[1m  1/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 24ms/step                \n",
      "\u001b[1m  6/133\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step                \n",
      "\u001b[1m 11/133\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 16/133\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 21/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 26/133\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 31/133\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 34/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step       \n",
      "\u001b[1m 38/133\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step       \n",
      "\u001b[1m 43/133\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 13ms/step       \n",
      "\u001b[1m 48/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step       \n",
      "\u001b[1m 53/133\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 58/133\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 63/133\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 68/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 73/133\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 78/133\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 83/133\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 87/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 91/133\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 95/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m 99/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m103/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step       \n",
      "\u001b[1m107/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step       \n",
      "\u001b[1m112/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step       \n",
      "\u001b[1m117/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m121/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m126/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m131/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step       \n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step       \n",
      "\n",
      "100%|██████████| 2/2 [02:56<00:00, 88.04s/trial, best loss: -0.24998173872662088] \n",
      "Best hyperparameters: {'batch_size': 1, 'dense_units': 0, 'dropout_rate': 0.3021400220523167, 'embed_dim': 1, 'epochs': 0, 'lstm_units': 0, 'max_len': 1, 'recurrent_dropout': 0.28202504542899054}\n"
     ]
    }
   ],
   "source": [
    "# LSTM Parameter Optimization\n",
    "\n",
    "space = {\n",
    "    'max_len': hp.choice('max_len', [100, 200, 300]),\n",
    "    'embed_dim': hp.choice('embed_dim', [64, 128, 256]),\n",
    "    'lstm_units': hp.choice('lstm_units', [32, 64, 128]),\n",
    "    'recurrent_dropout': hp.uniform('recurrent_dropout', 0.1, 0.3),\n",
    "    'dense_units': hp.choice('dense_units', [32, 64, 128]),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.4),\n",
    "    'batch_size': hp.choice('batch_size', [64, 128, 256]),\n",
    "    'epochs': hp.choice('epochs', [3]),\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    # Cross-validation setup\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    val_scores_lstm = []\n",
    "    inputs = Input(shape=(params['max_len'],))\n",
    "    layer = Embedding(input_dim=max_words, output_dim=params['embed_dim'], input_length=params['max_len'])(inputs)\n",
    "    layer = Bidirectional(LSTM(params['lstm_units'], return_sequences=True, recurrent_dropout=params['recurrent_dropout']))(layer)\n",
    "    layer = GlobalMaxPool1D()(layer)\n",
    "    layer = Dropout(params['dropout_rate'])(layer)\n",
    "    layer = Dense(params['dense_units'], activation='relu')(layer)\n",
    "    layer = Dropout(params['dropout_rate'])(layer)\n",
    "    layer = Dense(6, activation='sigmoid')(layer)\n",
    "    model = Model(inputs=inputs, outputs=layer)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train2):\n",
    "        X_train_fold, X_val_fold = X_train2[train_index], X_train2[val_index]\n",
    "        y_train_fold, y_val_fold = y_train2[train_index], y_train2[val_index]\n",
    "\n",
    "        # Adjust the input data to match max_len\n",
    "        X_train_fold = pad_sequences_custom(X_train_fold, params['max_len'])\n",
    "        X_val_fold = pad_sequences_custom(X_val_fold, params['max_len'])\n",
    "    \n",
    "        checkpoint = ModelCheckpoint('save_best_model_lstm.keras', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=1)\n",
    "\n",
    "        history_lstm = model.fit(X_train_fold, y_train_fold, batch_size=params['batch_size'], epochs=params['epochs'], validation_split=0.2, callbacks=[checkpoint, early_stop])\n",
    "\n",
    "        # Evaluate the model\n",
    "        val_preds = model.predict(X_val_fold)\n",
    "        val_preds_binary = (val_preds > 0.5).astype(int)\n",
    "        f1 = f1_score(y_val_fold, val_preds_binary, average='macro')\n",
    "        val_scores_lstm.append(f1)\n",
    "\n",
    "    # Calculate the average F1 score over all folds\n",
    "    avg_f1 = np.mean(val_scores_lstm)\n",
    "\n",
    "    return {'loss': -avg_f1, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_lstm = fmin(objective, space, algo=tpe.rand.suggest, max_evals=2, trials=trials)\n",
    "\n",
    "print('Best hyperparameters:', best_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters CNN: {'batch_size': 128, 'dense_units': 64, 'dropout_rate': 0.20693163905050424, 'embed_dim': 256, 'epochs': 3, 'filters': 256, 'kernel_size': 3, 'max_len': 200}\n",
      "Best hyperparameters CNN: {'batch_size': 128, 'dense_units': 32, 'dropout_rate': 0.3021400220523167, 'embed_dim': 128, 'epochs': 3, 'lstm_units': 32, 'max_len': 200, 'recurrent_dropout': 0.28202504542899054}\n"
     ]
    }
   ],
   "source": [
    "# Map best indices to actual values\n",
    "best_cnn['max_len'] = [100, 200, 300][best_cnn['max_len']]\n",
    "best_cnn['embed_dim'] = [64, 128, 256][best_cnn['embed_dim']]\n",
    "best_cnn['kernel_size'] = [3, 5, 7][best_cnn['kernel_size']]\n",
    "best_cnn['filters'] = [64, 128, 256][best_cnn['filters']]\n",
    "best_cnn['dense_units'] = [32, 64, 128][best_cnn['dense_units']]\n",
    "best_cnn['batch_size'] = [64, 128, 256][best_cnn['batch_size']]\n",
    "best_cnn['epochs'] = [3][best_cnn['epochs']]  # Only one choice, but maintaining structure\n",
    "\n",
    "print('Best hyperparameters CNN:', best_cnn)\n",
    "\n",
    "# Map best indices to actual values\n",
    "best_lstm['max_len'] = [100, 200, 300][best_lstm['max_len']]\n",
    "best_lstm['embed_dim'] = [64, 128, 256][best_lstm['embed_dim']]\n",
    "best_lstm['lstm_units'] = [32, 64, 128][best_lstm['lstm_units']]\n",
    "best_lstm['dense_units'] = [32, 64, 128][best_lstm['dense_units']]\n",
    "best_lstm['batch_size'] = [64, 128, 256][best_lstm['batch_size']]\n",
    "best_lstm['epochs'] = [3][best_lstm['epochs']]  # Only one choice, but maintaining structure\n",
    "\n",
    "print('Best hyperparameters LSTM:', best_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     2     4 ... 12758 12763 12765]\n",
      "Epoch 1/5\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.3897 - loss: 0.5589\n",
      "Epoch 1: val_loss improved from inf to 0.18244, saving model to save_best_model_lstm.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.3873 - loss: 0.5537 - val_accuracy: 0.0018 - val_loss: 0.1824\n",
      "Epoch 2/5\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.3646 - loss: 0.2084\n",
      "Epoch 2: val_loss improved from 0.18244 to 0.17224, saving model to save_best_model_lstm.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.3657 - loss: 0.2078 - val_accuracy: 0.9324 - val_loss: 0.1722\n",
      "Epoch 3/5\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.4341 - loss: 0.1844\n",
      "Epoch 3: val_loss improved from 0.17224 to 0.15504, saving model to save_best_model_lstm.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.4345 - loss: 0.1840 - val_accuracy: 0.9941 - val_loss: 0.1550\n",
      "Epoch 4/5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5273 - loss: 0.1447\n",
      "Epoch 4: val_loss improved from 0.15504 to 0.10641, saving model to save_best_model_lstm.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5274 - loss: 0.1446 - val_accuracy: 0.9935 - val_loss: 0.1064\n",
      "Epoch 5/5\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5321 - loss: 0.0941\n",
      "Epoch 5: val_loss improved from 0.10641 to 0.07677, saving model to save_best_model_lstm.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.5329 - loss: 0.0938 - val_accuracy: 0.9941 - val_loss: 0.0768\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step\n",
      "[    0     1     2 ... 12762 12763 12764]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  # we assume the user will be removing warnings if zero_division is set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5815 - loss: 0.0669\n",
      "Epoch 1: val_loss improved from inf to 0.05832, saving model to save_best_model_lstm.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.5816 - loss: 0.0669 - val_accuracy: 0.9971 - val_loss: 0.0583\n",
      "Epoch 2/5\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6678 - loss: 0.0535\n",
      "Epoch 2: val_loss did not improve from 0.05832\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.6678 - loss: 0.0535 - val_accuracy: 0.9971 - val_loss: 0.0606\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
      "[    0     3     8 ... 12762 12764 12765]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  # we assume the user will be removing warnings if zero_division is set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6712 - loss: 0.0505\n",
      "Epoch 1: val_loss improved from inf to 0.06385, saving model to save_best_model_lstm.keras\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.6717 - loss: 0.0505 - val_accuracy: 0.9947 - val_loss: 0.0639\n",
      "Epoch 2/5\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7202 - loss: 0.0436\n",
      "Epoch 2: val_loss did not improve from 0.06385\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.7203 - loss: 0.0437 - val_accuracy: 0.9947 - val_loss: 0.0708\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  # we assume the user will be removing warnings if zero_division is set\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHHCAYAAABTMjf2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAACgyElEQVR4nOzdd1gUV9sH4N+ywFIExKCAihSxK6BYUaPYwILBFgxYsEV9o0asWGKJLfYSRdEkAgoq1hAbseFnwQaiqAgK2EHBhnTYPd8fhMF1l7JSBtjnvi7ed+fMmZlnVwIPpwoYYwyEEEIIIUpIhe8ACCGEEEL4QokQIYQQQpQWJUKEEEIIUVqUCBFCCCFEaVEiRAghhBClRYkQIYQQQpQWJUKEEEIIUVqUCBFCCCFEaVEiRAghhBClRYkQIaTSWrt2LSwsLCAUCmFjY8N3OKQI7u7uMDMz+6pru3fvju7du5dpPISUFCVChBTCx8cHAoGA+1JVVUW9evXg7u6Oly9fyr2GMYY9e/bg22+/Rc2aNaGlpYVWrVrh119/RVpaWqHPOnr0KPr27QsDAwOoq6ujbt26+P7773H+/PkSxZqZmYmNGzeiQ4cO0NPTg4aGBho3bowpU6YgJibmq94/3/7991/MmTMHnTt3xu7du7Fy5cpyfZ67uztq1KhRbL3IyEgMHToUpqam0NDQQL169dC7d2/8/vvvAIAlS5ZIfd8U9pX/i9/d3R0CgQC6urrIyMiQed6jR4+4a9atW1dsfPl1x48fL/f8ggULuDrJycnF3o+Q6k6V7wAIqex+/fVXmJubIzMzE9euXYOPjw8uX76Me/fuQUNDg6snFovh6uqKwMBAdO3aFUuWLIGWlhYuXbqEpUuX4uDBgzh79iwMDQ25axhjGDt2LHx8fNC6dWvMmDEDRkZGSEhIwNGjR9GzZ09cuXIFdnZ2hcaXnJwMR0dHhIWFYcCAAXB1dUWNGjUQHR2N/fv3Y+fOncjOzi7Xz6g8nD9/HioqKvjzzz+hrq7OdzgAgKtXr8Le3h4NGjTAhAkTYGRkhOfPn+PatWvYvHkzpk6disGDB8PS0pK7JjU1FZMnT8agQYMwePBgrvzz7wNVVVWkp6fjn3/+wffffy/1TH9/f2hoaCAzM7PEcWpoaODw4cPw8vKS+ez27dun8P0IqdYYIUSu3bt3MwDs5s2bUuVz585lANiBAwekyleuXMkAsFmzZsncKygoiKmoqDBHR0ep8rVr1zIAbPr06Uwikchc5+fnx65fv15knP3792cqKirs0KFDMucyMzPZzJkzi7y+pHJyclhWVlaZ3KskxowZw7S1tcvsfhKJhKWnpxd6fvTo0cU+r1+/fqx27drs/fv3Mudev34t95qkpCQGgC1evLjI5/bp04c5OzvLnG/UqBEbMmQIA8DWrl1bZHyMMQaAOTs7MxUVFXbs2DGpc1euXGEAuPslJSUVe7+SGj16NDM1Nf2qa7t168a6detWZrEQogjqGiNEQV27dgUAxMbGcmUZGRlYu3YtGjdujFWrVslc4+TkhNGjR+P06dO4du0ad82qVavQtGlTrFu3DgKBQOa6kSNHon379oXGcv36dZw4cQLjxo3DkCFDZM6LRCKp7pTCxmJ8Ob7jyZMnXFfMpk2b0LBhQ4hEIty+fRuqqqpYunSpzD2io6MhEAiwdetWruzDhw+YPn06TExMIBKJYGlpidWrV0MikRT6noC87p3du3cjLS2N68bx8fEBAOTm5mLZsmVcTGZmZpg/fz6ysrKk7mFmZoYBAwYgODgYbdu2haamJry9vYt8bnFiY2PRokUL1KxZU+ZcnTp1SnVvV1dXnDp1Ch8+fODKbt68iUePHsHV1VWhe9WrVw/ffvstAgICpMr9/f3RqlUrtGzZUu51Bw8ehK2tLTQ1NWFgYIARI0bI7QY+duwYWrZsCQ0NDbRs2RJHjx6Vez+JRIJNmzahRYsW0NDQgKGhISZOnIj3798r9H4IKU+UCBGioCdPngAA9PX1ubLLly/j/fv3cHV1haqq/B7nUaNGAQCOHz/OXfPu3Tu4urpCKBR+VSxBQUEA8hKm8rB79278/vvv+PHHH7F+/XoYGxujW7duCAwMlKl74MABCIVCDBs2DACQnp6Obt26Ye/evRg1ahS2bNmCzp07Y968eZgxY0aRz92zZw+6du0KkUiEPXv2cOOuAGD8+PFYtGgR2rRpg40bN6Jbt25YtWoVhg8fLnOf6Oho/PDDD+jduzc2b95c6gHXpqamCAsLw71790p1H3kGDx4MgUCAI0eOcGUBAQFo2rQp2rRpo/D9XF1d8c8//yA1NRVAXgJ58ODBQpMqHx8ffP/99xAKhVi1ahUmTJiAI0eOoEuXLlLJ2b///oshQ4ZAIBBg1apVcHZ2xpgxY3Dr1i2Ze06cOBGzZ89G586dsXnzZowZMwb+/v5wcHBATk6Owu+JkHLBd5MUIZVVftfY2bNnWVJSEnv+/Dk7dOgQq127NhOJROz58+dc3U2bNjEA7OjRo4Xe7927dwwAGzx4MGOMsc2bNxd7TXEGDRrEAMjtqpGnsC6IL7s14uPjGQCmq6vL3rx5I1XX29ubAWCRkZFS5c2bN2c9evTgjpctW8a0tbVZTEyMVD1PT08mFArZs2fPioxVXldVREQEA8DGjx8vVT5r1iwGgJ0/f54rMzU1ZQDY6dOni3xOUc/70r///suEQiETCoWsU6dObM6cOSw4OJhlZ2cXek1Ju8YYY2zo0KGsZ8+ejDHGxGIxMzIyYkuXLuX+PUraNfbTTz+xd+/eMXV1dbZnzx7GGGMnTpxgAoGAPXnyhC1evFiqayw7O5vVqVOHtWzZkmVkZHD3On78OAPAFi1axJXZ2NgwY2Nj9uHDB6nPBYDU99ClS5cYAObv7y8V3+nTp2XKqWuM8IlahAgpRq9evVC7dm2YmJhg6NCh0NbWRlBQEOrXr8/V+fTpEwBAR0en0Pvkn0tJSZH6/6KuKU5Z3KMoQ4YMQe3ataXKBg8eDFVVVRw4cIAru3fvHh48eAAXFxeu7ODBg+jatSv09fWRnJzMffXq1QtisRj/93//p3A8J0+eBACZFqWZM2cCAE6cOCFVbm5uDgcHB4WfU5jevXsjNDQUAwcOxJ07d7BmzRo4ODigXr16XOtcabi6uiIkJASJiYk4f/48EhMTFe4Wy6evrw9HR0fs27cPQF7rkp2dHUxNTWXq3rp1C2/evMH//vc/qQkA/fv3R9OmTbnPNSEhARERERg9ejT09PS4er1790bz5s2l7nnw4EHo6emhd+/eUv/+tra2qFGjBi5cuPBV74uQskaJECHF2LZtG86cOYNDhw6hX79+SE5OhkgkkqqTn4jkJ0TyfJks6erqFntNccriHkUxNzeXKTMwMEDPnj2luscOHDgAVVVVqVlRjx49wunTp1G7dm2pr169egEA3rx5o3A8T58+hYqKitSsLAAwMjJCzZo18fTp02LjL6127drhyJEjeP/+PW7cuIF58+bh06dPGDp0KB48eFCqe/fr1w86Ojo4cOAA/P390a5dO5n3qghXV1ecOXMGz549w7FjxwpNqvI/tyZNmsica9q0KXc+//8bNWokU+/Lax89eoSPHz+iTp06Mt8DqampX/XvT0h5oOnzhBSjffv2aNu2LQDA2dkZXbp0gaurK6Kjo7l1Z5o1awYAuHv3LpydneXe5+7duwDA/eXctGlTAHnr0hR2TXE+v0f+IO6iCAQCMMZkysVisdz6mpqacsuHDx+OMWPGICIiAjY2NggMDETPnj1hYGDA1ZFIJOjduzfmzJkj9x6NGzcuNt7CyBtYLk9h8ZcFdXV1tGvXDu3atUPjxo0xZswYHDx4EIsXL/7qe4pEIgwePBi+vr6Ii4vDkiVLShXjwIEDIRKJMHr0aGRlZclMzS9PEokEderUgb+/v9zzX7Y0EsIXahEiRAH5A0lfvXolNTuqS5cuqFmzJgICAgpNKvz8/AAAAwYM4K7R19fHvn37Cr2mOE5OTgCAvXv3lqi+vr6+1MDXfF+2pBTH2dkZ6urqOHDgACIiIhATEyMzWLlhw4ZITU1Fr1695H41aNBAoWcCeYOVJRIJHj16JFX++vVrfPjwQW63T0XIT5QTEhJKfS9XV1fcvn0bnz59kjsAXBGamppwdnZGSEgIevfuLZWofi7/c4uOjpY5Fx0dzZ3P//8vP3951zZs2BBv375F586d5f77W1tbl+q9EVJWKBEiREHdu3dH+/btsWnTJm5ROi0tLcyaNQvR0dFYsGCBzDUnTpyAj48PHBwc0LFjR+6auXPnIioqCnPnzpXbUrN3717cuHGj0Fg6deoER0dH/PHHHzh27JjM+ezsbMyaNYs7btiwIR4+fIikpCSu7M6dO7hy5UqJ3z8A1KxZEw4ODggMDMT+/fuhrq4u06r1/fffIzQ0FMHBwTLXf/jwAbm5uQo9E8jrOgKATZs2SZVv2LABQN6YlvJ04cIFuf9O+WOX5HUtKcre3h7Lli3D1q1bYWRkVOr7zZo1C4sXL8Yvv/xSaJ22bduiTp062LFjh9QyBKdOnUJUVBT3uRobG8PGxga+vr74+PEjV+/MmTMy3YLff/89xGIxli1bJvO83NxcuQk5IXygrjFCvsLs2bMxbNgw+Pj4YNKkSQAAT09P3L59G6tXr0ZoaCiGDBkCTU1NXL58GXv37kWzZs3g6+src5/79+9j/fr1uHDhAoYOHQojIyMkJibi2LFjuHHjBq5evVpkLH5+fujTpw8GDx4MJycn9OzZE9ra2nj06BH279+PhIQEbi2hsWPHYsOGDXBwcMC4cePw5s0b7NixAy1atOAGXpeUi4sLRowYAS8vLzg4OMisrTN79mwEBQVhwIABcHd3h62tLdLS0hAZGYlDhw7hyZMnhbZQFMba2hqjR4/Gzp078eHDB3Tr1g03btyAr68vnJ2dYW9vr9D9vpSTk4Ply5fLlNeqVQv/+9//MHXqVKSnp2PQoEFo2rQpsrOzcfXqVRw4cABmZmYYM2ZMqZ4PACoqKli4cGGp75PP2tq62NYXNTU1rF69GmPGjEG3bt3www8/4PXr19i8eTPMzMzg4eHB1V21ahX69++PLl26YOzYsXj37h1+//13tGjRgpuqDwDdunXDxIkTsWrVKkRERKBPnz5QU1PDo0ePcPDgQWzevBlDhw4ts/dJyFfjedYaIZVWYStLM5Y3tblhw4asYcOGLDc3V6p89+7drHPnzkxXV5dpaGiwFi1asKVLl7LU1NRCn3Xo0CHWp08fVqtWLaaqqsqMjY2Zi4sLCwkJKVGs6enpbN26daxdu3asRo0aTF1dnTVq1IhNnTqVPX78WKru3r17mYWFBVNXV2c2NjYsODi40OnzRU3XTklJYZqamgwA27t3r9w6nz59YvPmzWOWlpZMXV2dGRgYMDs7O7Zu3boip5wzVvh09pycHLZ06VJmbm7O1NTUmImJCZs3bx7LzMyUqmdqasr69+9f5DO+fB4AuV8NGzZkjDF26tQpNnbsWNa0aVPuc7a0tGRTp04t9crSRfma6fNF+XL6fL4DBw6w1q1bM5FIxGrVqsXc3NzYixcvZK4/fPgwa9asGROJRKx58+bsyJEjha4svXPnTmZra8s0NTWZjo4Oa9WqFZszZw579eoVV4emzxM+CRiT085LCCGEEKIEaIwQIYQQQpQWJUKEEEIIUVqUCBFCCCFEaVEiRAghhBClRYkQIYQQQpQWJUKEEEIIUVpKt6CiRCLBq1evoKOjU+L9igghhBDCL8YYPn36hLp160JFpezacZQuEXr16hVMTEz4DoMQQgghX+H58+eoX79+md1P6RIhHR0dAHkfpK6uLs/REEIIIaQkUlJSYGJiwv0eLytKlwjld4fp6upSIkQIIYRUMWU9rIUGSxNCCCFEaVEiRAghhBClRYkQIYQQQpQWJUKEEEIIUVqUCBFCCCFEaVEiRAghhBClRYkQIYQQQpQWJUKEEEIIUVqUCBFCCCFEaVEiRAghhBClxWsi9H//939wcnJC3bp1IRAIcOzYsWKvCQkJQZs2bSASiWBpaQkfH59yj5MQQggh1ROviVBaWhqsra2xbdu2EtWPj49H//79YW9vj4iICEyfPh3jx49HcHBwOUdKCCGEkOqI101X+/bti759+5a4/o4dO2Bubo7169cDAJo1a4bLly9j48aNcHBwKK8wCSGEEFJNVand50NDQ9GrVy+pMgcHB0yfPp2fgAgpDYkYeHIZyPpU4ktyJGLc/BSHjNizgEAFKONdmKsrBuBgbjK0IeQ7FELIV2AShoTYkv+sVESVSoQSExNhaGgoVWZoaIiUlBRkZGRAU1NT5pqsrCxkZWVxxykpKeUeJ6k6MnMzcS/5Hti7eCBb9j+y88l3kCrOgBAqQGoikJWal4CUgZy3jxCkUwMaEglKms5kqND8BkKIcsn5kIOXf7xEanRqudy/SiVCX2PVqlVYunQp32GQoqS9BT4lFH4+MRJIvItUAfBCnPbVj/nw8B8s0dNCzn+tKDkC4L0Kjy0qOjUAAJmU3BBCiFwp4Sl4ufslxJ/E5faMKpUIGRkZ4fXr11Jlr1+/hq6urtzWIACYN28eZsyYwR2npKTAxMSkXONUNhm5GXiX+Y47Fr+NxaVj7kjTrFl8103qGwBAnLoazmtpom5urtxqserqpQ/0mxqlv0d5YUCtHO0SVc0U5kA/Rwu1MwzxTKUuWCHtSalZ8j9LZSbI1YYwrQFQRBvcNzXK4HuNEFJq2amfELVjPsTZeUmQeg0dZKeWffdYlUqEOnXqhJMnT0qVnTlzBp06dSr0GpFIBJFIVN6hVSmZuZnIlmQXWy8yKRL3397HgYcHULdGXUCSC2S8AxgDMt4D4hzcVxEjR97vlJraAHKKD6ZWTanDMkl4SshIzAAAiUIBemfkoIGYAUYtufPv03OQ8DEDEAOWGTUhZCpQAUOYSktkQOOrn/s+veCzfw8dvM8xASQiKPKf92sADxWob6T79fFWO1ryi7VFQszs0wT9WhlXbDyEkEL9YaaLCRMmwNnZGRs2bICFhUWZP4PXRCg1NRWPHz/mjuPj4xEREYFatWqhQYMGmDdvHl6+fAk/Pz8AwKRJk7B161bMmTMHY8eOxfnz5xEYGIgTJ07w9RYqLbFEjOsJ1/EuK6+l5tKLS0jKSMLNxJtfdb83GW9kC8tp3Klm3ogcGUxFiHRJNgYZ2UFNoPi37uuUTDxIykJKpg1UM1pziYc2gKv/feFjQf3ElEzu9b8KP61kjHQ1YFSOeTr9cieEVBVisRi5ublSjRfjxo2DiYkJ+vTpg0+fymewtIAxxsrlziUQEhICe3t7mfLRo0fDx8cH7u7uePLkCUJCQqSu8fDwwIMHD1C/fn388ssvcHd3L/EzU1JSoKenh48fP0JXV7cM3kXFevT+EX6//Ts0VKX/wj8Vf4qniAr0SU3jciMJAEH9dhjQ5n8lvl5FoAJbQ1toqWnhxN0EbDgTjbSssusX/jyxUVRZt6hQgkIIIQWeP3+OUaNGoWXLlvj999/l1imv39+8JkJ8qKqJUPS7aAz9Z2iZ3rNzekaxdd4JhXBL+QTbzEzUzf0vKbFxAxrYAZp6gIU9IFSDyuczqQQqgMrXNxeduJuAnwLCv/r6kihpYkMJCyGElK/AwEBMnDgRHz58AACcOHEC/fr1k6lXXr+/q9QYIWWSkZuBgKgAbArfhLradfEq7VWJr7WqbQUAyMzJQA0VNTjoNALCdkOTMXTOyEQNiQRaJc1/LeyBVn0Kjpt/B+jVU+StyFVUi8+XLTdl2RpDiQ0hhFQOKSkpmDZtGnx9fbkyExMT6OjoVGgclAhVQuk56egQ0IE7lpcEebb3xLf1v5Uqq/n+BXQOjAKyE4CMD8C72P/OnC7+oUP/AoysC47VtQDdul8RvSx5SU9Ju6m83NpQ0kIIIdVMaGgoRowYgbi4OK7MxcUF27dvh76+foXGQokQz3LEOTj37By2RWyDgaYBIpMjkSXOkltXT6SHaa2n4fsm3+cVMJa3OvGLG8C/C4GXYXnlaXIGNucz6wrUaZ73WkUIdJgI6JuV3Rv6TH4CFJtU9No/8lp8qOWGEEKqn9zcXKxYsQLLli2DWJz3x7GOjg62bduGESNGQMDDavmUCPFo2D/D8PBdwSToJylP5Na7PPwy9ER6BQUSMXBxdd5XkQQAGGDRHVDTBtqOBRr1KuYaxRXWzSWv1efzpIeSHUIIUR5v376Fk5MTQkNDuTI7Ozvs3bsX5ubmvMVFiRBPxgaPlUqC5BnYcCCWdV4mPRAZAH6tVfTNh+4GWg4uZYTFK2mLDwA0rK1NSQ8hhCixmjVrQlU1L+0QCoVYtGgR5s+fz5XxhRKhCvYp+xPs9tnJlFvWtMS6butgopO36rW68IuFBWPPA4/PAdFypsnXbgYwMdBzMdDYERCWzT9rcVPYi2vxAajVhxBCSB6hUIg9e/Zg8ODB2LZtGzp27Mh3SAAoEapQJ+JOwPOSp0z52aFnYahtKHvBmyhgd9+8VZwLMz0SqNmg9LGVYkAzQC0+hBBCpF28eBGamppo3749V2Zqaopbt27xMhaoMJQIVQDf+77wj/JHQprsxqI33G5AU/W/fdJys4AXN4Hzy4FnoTJ1ZcyMBnSMyiTG4rq4CpvCTi0+hBBCPpednY3Fixdj9erVMDc3R0REhNSU+MqUBAGUCJW7eZfm4XjccZnyH61+xNTWUwsKlujJ1JHLeXteC1DdNnlT3EspvyUoPjkvCVIRAHV0aEAzIYQQxUVHR8PV1RXh4XmL4sbFxWH79u2YM2cOz5EVjhKhcrT19la5SdD0NtMxDnrAQfe82VwR/kXf6DsvoLVbmcT0ZRfYl91f5gbaODeze5k8ixBCiHJgjGHXrl2YPn06MjLydi1QU1PDihUrMHPmTJ6jKxolQuXkyccn8L7rLVV2fth51E5NBryKGSBm0ATovRRo2ANQLdsdOYvqAssf50MIIYSUVFJSEiZMmIC///6bK2vSpAkCAgLQpk0bHiMrGUqEygFjDE7HnKTK/nH+B7XD9wJnlxR98Zx4QKuY6fFf6cTdBC4J+rwLjLq/CCGEfI3g4GC4u7sjMTGRK5s0aRLWr18PLa3SD9+oCJQIlYON4Ruljj3be8JMz0x+EjT6H6DGfzPG9M0BVXXZOqUkb70f6gIjhBBSGq9fv4azszMyM/OGWBgYGOCvv/6Ck5NTMVdWLpQIlaGPWR9xPO44dt/bLVXu1swN2NldurKLP9BsQLnHVNhO7tQFRgghpDQMDQ3x22+/Yfr06XBwcICPjw+MjMpmJnNFokSoFBhjkDAJbr6+ieSMZMy7NE+mzv+5/B9wZhHw6nZBYZ0W5Z4EFbbqM633Qwgh5GtIJBKIxWKoqalxZVOnTkX9+vUxaNAgqKioFHF15UWJ0Ff4lP0JXfZ3gYRJiqw3wNQR+r+ZyZ4Yc6LMYypuNhhAO7kTQgj5OgkJCXB3d4eNjQ1Wry7Y51JFRQVDhgzhMbLSo0RIQSnZKei8r3Ox9U5+9w9MNlnLnpgcCmjql2lMhXV/5aNWIEIIIV/r77//xrhx4/D27VucOXMGDg4O6NGjB99hlRlKhBQ0+G/ZzUyb1WoGVRVVDLAYgFqatdDTpCfU7h2WvbiMZ4QV1v2Vvwo0zQYjhBDytdLS0jBz5kx4excsBWNoKGc7qCqOEiEF/PvkX7xOf80dm+iY4OTgk/Irh/lKHy/+AJThsuKFtQJR9xchhJDSCgsLg6urK2JiYriy7777Dn/88QcMDAx4jKzsUSKkgC8HQxeaBGWlAs+uFhz/71qZJUE0CJoQQkh5EYvFWLduHRYuXIjc3FwAgJaWFjZt2oTx48dXun3CygIlQiXkc88H2ZJs7nhP3z2FV15VT/q4dtMyiYFagQghhJSX5ORkDBs2DCEhIVyZra0tAgIC0LhxY/4CK2eUCJWAf5Q/1oet54471+sMmzo28iu/fiB93LBHqVqDPp8N9uVMMGoFIoQQUlb09PSQmpoKIG+HeE9PTyxZsgTq6mW/0G9lQolQMXIkOfjtxm9SZR5tPORXTk0CtneSLht5tFTPL2xvMGoFIoQQUpbU1NTg7+8PZ2dnbN++Hd26deM7pApBiVAxjj6STmT+cvgLTWrJWZU55DcgZJV02TBf2Xol8Hkr0JtPea1A+XuD0UwwQgghZSE0NBRaWlqwti5Y6qVx48a4d+9elV0c8WtQIlSMv+79xb020TFBO6N28it+mQTVbgq0cFb4eYWNA6K9wQghhJSF3NxcrFixAsuWLUPjxo1x69YtqQ1SlSkJAigRKlJyRjJepr7kjtd1Wye/Yuob6eNeS4Eu0xV6VlFrAuW3AhFCCCGlERcXhxEjRiA0NBQAEBUVBS8vL8yaNYvnyPhDiVAR7APtpY6b6BeSjEQeLHhdw0jhJAiQPxaIxgERQggpC4wx7NmzB1OmTMGnT58AAEKhEIsXL8b06dP5DY5nlAgVgjEmdTymxRgIVYTyKwfPL3jdbvxXPS9/jzAVQV43GI0DIoQQUhbev3+PSZMmITAwkCtr2LAh9u7di44dO/IYWeVAiVAhvvv7O6njGW1nyK+Y+VH62GqYws86cTeBmxpfR0eDxgIRQggpEyEhIRg5ciRevHjBlY0ZMwabN2+Gjo4Oj5FVHpQIFSL+Yzz3uq9538Irft4aBAD6ZiV+hrxxQdqiQlqdCCGEEAUkJCTAwcEB2dl5iwHr6+vD29sbw4Yp/gd7daZcQ8NL6MtuseWdl8urBPwzHbi9t6Cs/Y8KPUfeuCAaFE0IIaQsGBsbY/HixQAAe3t73L17l5IgOahFSI5tEdu41zVFNaEulLOq5pNLQNhu6bLey0r8jBN3E7gkiMYFEUIIKS3GGCQSCYTCgp6FuXPnwsTEBG5ubko3Lb6k6FORw/uuN/daW01bfiVfJ+njAZsANY0SP2PDmWjudf4aQZQEEUII+RpJSUkYNGgQli+X7sEQCoUYOXIkJUFFoBahL8R9iJM63t9/v2yl2/7Sxy7+QLMBJbp//rig+OSCLjHqDiOEEPK1goOD4e7ujsTERBw/fhx9+vRBp06dir+QAKAWIRm/XPlF6rimRk3ZSn//T/q4af8S3z9/XJDkv2FIDWtrU0sQIYQQhWVmZsLDwwOOjo5ITEwEkDcgOn+dIFIy1CL0hbvJd7nXizstlq3w4bn08aTLJd5dvrBxQYQQQogiIiMj4ebmhsjISK7MwcEBPj4+MDIy4jGyqocSoc/kSHKkjr9r+J1spftHCl4LVACjViW+v7xxQYQQQkhJSSQS/P7775g7dy6ysrIAACKRCGvWrMGUKVNoLNBXoEToM533dZY6VhOqSVcQ5wJnFhUctx1X4nt/3hoE0LggQgghinn79i3c3NwQHBzMlbVq1QoBAQFo2bIlj5FVbZQ6/udd5jtk5GZwx53rdZattOwb6eP2E0p8/89bg2hcECGEEEVpa2vj5cuCjcA9PDxw48YNSoJKiRKh/4S/Dpc6/r3H79IVlujJXlS7ZK061BpECCGktDQ0NBAQEABzc3MEBwdjw4YN0NAo+bItRD7qGvtPyPMQ7vWQRkOgpvJZt9iTK7IXLPkoW1YIag0ihBCiqLCwMGhra6Np06ZcWatWrRATEwNVVfr1XVaoReg/eqKCFh8THRPpk0+vSh8veF3i+1JrECGEEEWIxWKsXr0aHTt2xA8//MANis5HSVDZokToP6EJodxrW0Nb6ZMXPlupc/CuEq8gfeJuAn4KKOhyo9YgQgghRXn+/Dl69uwJT09P5ObmIiIiAl5eXnyHVa1RIvSfXEku97qWRq2CE6lJ0hVN7Up8z8+7xABqDSKEEFK4wMBAWFlZ4eLFiwAAgUCAefPm4aeffuI5suqN2tf+k5yRzL020DQoOHFpvXRFvfolut+XXWJebm2oNYgQQoiMlJQUTJs2Db6+vlyZiYkJ9uzZg27duvEYmXKgFqH/6Krrcq+11LQKTsRfLHjdaUqJ70cDpAkhhBQnNDQUrVu3lkqCXFxccOfOHUqCKgi1CP3nZWre2gxG2l8sTf7mQcHrtmNLdC8aIE0IIaQ4L1++RPfu3ZGdnQ0A0NHRwbZt2zBixAgISrh1Eyk9ahEC8DqtYBZYYlpiwYmPL6Qr6psXey8aIE0IIaQk6tWrh1mzZgEA7OzscOfOHYwcOZKSoApGLUIA3me9514LBcKCE19usFqCPVxogDQhhBB5GGMAIJXoLFmyBA0aNMC4ceNoWjxPqEUIwM3Em9zrrvW7FpxIuFPwul3x22nQAGlCCCHyvH//HsOHD8f69dITcNTU1DBx4kRKgnhEiRCAsNdh3GupGWMPjxe8VhUVex8aIE0IIeRLISEhsLKyQmBgIObPn4/bt2/zHRL5DCVCAOI+xnGvezboWXDi+fWC1yYdirwHDZAmhBDyuezsbHh6eqJHjx548SJvzGmNGjWQmJhYzJWkIlFbHID0nHTudYtvWhScEGcXvG7Qqch7UGsQIYSQfNHR0XB1dUV4eMHkGXt7e/j5+aF+/ZKtR0cqBrUIAXidXjBrrKaoZt6L1DfSlWrULvIeaVli7jW1BhFCiHJijMHb2xutW7fmkiA1NTWsWbMGZ8+epSSoElL6FiEJk0gdc6P5t7Uv8T1O3E1AYkomAMBIV4NagwghRAm9e/cOY8aMQVBQEFfWpEkTBAQEoE2bNjxGRoqi9C1Cb9LfyBYyBmQUTKlH9/mFXv/lukHaImGhdQkhhFRfIpEIDx8+5I4nT56M8PBwSoIqOaVPhF58Klg00ULPIu/F/SPSlbrNKfR6WjeIEEIIAGhra8Pf3x9169ZFUFAQvLy8oKWlVfyFhFdK3zX27NMz7nWTWv8lMYc+20pDTRsoZJVPWjeIEEKUV2RkJLS1tWFhYcGVtW3bFnFxcRCJil9yhVQOSt8i9PmWGiY6JnkvTDsXVHDZU+i1NFOMEEKUj0QiwebNm9GuXTu4ubkhNzdX6jwlQVWL0idCn48R4rrGnl4pqGBqV+i1NFOMEEKUS0JCAvr27Yvp06cjKysL165dw/bt2/kOi5QC74nQtm3bYGZmBg0NDXTo0AE3btwosv6mTZvQpEkTaGpqwsTEBB4eHsjMzPzq52uoanCvjbWNpQdJA8Bn5wtDM8UIIaT6+/vvv9GqVSv8+++/XJmHhwcmTCh+CyZSefGaCB04cAAzZszA4sWLER4eDmtrazg4OODNGzkzuQAEBATA09MTixcvRlRUFP78808cOHAA8+cXPqurODniHO61lpoWsNpMukIR44Pyp8wTQgipvtLS0jBp0iQ4Ozvj7du3AABjY2MEBwdjw4YN0NAo/g9mUnnxmght2LABEyZMwJgxY9C8eXPs2LEDWlpa+Ouvv+TWv3r1Kjp37gxXV1eYmZmhT58++OGHH4ptRSpKYEwg91rty4+jiI1WPx8fRFPmCSGkegoLC0ObNm3g7e3NlTk7O+Pu3bvo06cPj5GRssJbIpSdnY2wsDD06tWrIBgVFfTq1QuhoaFyr7Gzs0NYWBiX+MTFxeHkyZPo169foc/JyspCSkqK1NfnamsWrBhtGHdZ+uL+6wq9L40PIoSQ6u358+ews7NDTEwMAEBLSwu7du3CkSNHYGBgUMzVpKrgLRFKTk6GWCyGoaGhVLmhoWGhG9K5urri119/RZcuXaCmpoaGDRuie/fuRXaNrVq1Cnp6etyXiYmJ1PmkjCTudY3PxwfVskBhaCVpQgip/kxMTPC///0PAGBra4vbt29j/PjxBTsQkGqB98HSiggJCcHKlSvh5eWF8PBwHDlyBCdOnMCyZcsKvWbevHn4+PEj9/X8+fPCHxATXPC65+JCq1G3GCGEVE+MManjVatWYcOGDbh69SoaN27MU1SkPPG2oKKBgQGEQiFev34tVf769WsYGRnJveaXX37ByJEjMX78eABAq1atkJaWhh9//BELFiyAiopsXicSiQpd00EsKejeql+jPnD/s7FGhbQIfbmIInWLEUJI1ZeSkoJp06ahffv2XCsQAGhoaMDDw4PHyEh5461FSF1dHba2tjh37hxXJpFIcO7cOXTq1EnuNenp6TLJjlCY1yLzZRZfEh+zP3KvX6W9AiSfLYpVp7lM/S/3FaNFFAkhpOoLDQ2FjY0NfH19MXPmTERFRfEdEqlAvHaNzZgxA7t27YKvry+ioqIwefJkpKWlYcyYMQCAUaNGYd68eVx9JycnbN++Hfv370d8fDzOnDmDX375BU5OTlxCpIgPmR+41wMsBhScUFEFhLKNZbSvGCGEVB+5ublYsmQJunbtivj4eACAmpoaYmNjeY6MVCRe9xpzcXFBUlISFi1ahMTERNjY2OD06dPcAOpnz55JtQAtXLgQAoEACxcuxMuXL1G7dm04OTlhxYoVX/X8F6kFG67qJ3/2ja+uLbf+5zPFaF8xQgipuuLi4jBixAipWcp2dnbYu3cvzM3NeYyMVDQB+5o+pSosJSUFenp6+PjxI66/v44ZITMAAIPTsrD0zX/jlRrYAWNPyVzbceU5JKZkwkhXA9fm96zIsAkhhJQBxhj8/PwwZcoUpKamAsgbYrFo0SLMnz8fqqpKvxd5pfX5729dXd0yu69S/4t/yv7EvbbITC84MWSXTF1aSZoQQqq2Dx8+YOLEiQgMLFhI18LCAv7+/ujYsSOPkRE+Vanp82Xtyccn3GuNzxvG9OrL1KUp84QQUrUJBAJcv36dO3Z3d0dERAQlQUpOqROhe2/vca9FxfQQ0krShBBStenp6WHPnj0wMDBAYGAgdu/eDR0dHb7DIjxT6q6xlKyC7TZMc/7bfPWbRjL1aCVpQgipeqKjo6GtrY369Qta+bt27YonT55AW1v+pBiifJS6RUhLTYt7XTf3vxafxg4y9ahbjBBCqg7GGLy9vdG6dWuMGjUKEolE6jwlQeRzSp0I3X5zm3tdM3+V6Zx0qTq0kjQhhFQdSUlJcHZ2xqRJk5CRkYELFy5g586dfIdFKjGlToQ+33lelD9EqFEfqTqftwbRStKEEFJ5BQcHw8rKCkFBQVzZpEmTMGrUKB6jIpWd0iZCjDGpnec5XyymSIOkCSGkcsvMzISHhwccHR2RmJgIIG8/y6CgIGzfvh1aWlrF3IEoM6UdLJ0tyZZ/Qih/g1YaJE0IIZVPZGQk3NzcEBkZyZU5ODjAx8en0A28Cfmc0iZCOeIc7nULgWbBCaEaD9EQQghR1NOnT9GuXTtkZWUBAEQiEdasWYMpU6bIbNBNSGGU9jslR1KQCH2T9q7ghE7BXxC0mjQhhFRepqam3PifVq1a4datW5g2bRolQUQhStsilJlbkOCIPz+h9Q33kqbNE0JI5bZx40aYmppi5syZ0NDQ4DscUgUpbdqcLS4YI/Tq8032VAvGCNFAaUIIqRzS0tIwadIk+Pj4SJVra2tjwYIFlASRr6a0idDnXWNt/utfhkZNroxWkyaEkMohLCwMtra28Pb2xtSpUxEbG8t3SKQaUdpE6G3GW+61Wv4+Y5/tN0bdYoQQwi+xWIzVq1ejY8eOiI7O+5kskUhw7969Yq4kpOSUdoxQWm7BatHJwv8SnfbjC85TtxghhPDm+fPnGDlyJC5evMiV2draIiAgAI0bN+YxMlLdKG2L0OdjhKzyu8ZqyK45Qd1ihBBSsQIDA2FlZcUlQQKBAPPmzcPVq1cpCSJlTmlbhB5/eMy91snfkC+XpsoTQghfPn36hKlTp8LX15crMzExwZ49e9CtWzceIyPVmdK2COmo63CvcyDIe6GaN+uA1g8ihJCKl5WVhX///Zc7dnFxwZ07dygJIuVKaROhmPcx3GvT3Ny8F7p5XWA0UJoQQiqegYEBfH19oaurCz8/P+zbtw/6+vp8h0WqOaXtGhN9vqdY/mSx/zZcpYHShBBS/uLi4qCtrQ1DQ0OurHfv3nj69Clq1qzJX2BEqShti5CaSsGeYt+I/0t8DFtK1aGB0oQQUvYYY/D19YW1tTXGjh0L9tnSJQAoCSIVSmkTITEraPVRzW8SqlGHxgcRQkg5ev/+PYYPHw53d3ekpqbi5MmT2L17N99hESWmtF1jYklBIiRk4FaVpvFBhBBSPkJCQjBy5Ei8ePGCK3N3d8ewYcN4jIooO6VtEcpludxrIRg3Y4zGBxFCSNnKzs6Gp6cnevTowSVB+vr6CAwMxO7du6Gjo1PMHQgpP0rbIiRhEu61KgOQ8V7qPI0PIoSQ0nv48CHc3NwQHh7Oldnb28PPzw/169fnMTJC8ihtInTu2TkINfO6vvL+lxVVnRBCiILi4uLQpk0bZGRkAADU1NSwYsUKzJw5EyoqStshQSoZ+k4EoCcRA2ZdaKA0IYSUIQsLCwwePBgA0KRJE1y7dg2zZ8+mJIhUKkrbIqQqUAX7rxVIxAC8isCGNzRQmhBCytK2bdtgamqKBQsWQEtLi+9wCJFRqrQ8M7Pqtp58vsUGAKBJXxooTQghXykzMxMeHh44ePCgVLmenh5WrFhBSRCptBROhCQSCZYtW4Z69eqhRo0aiIuLAwD88ssv+PPPP8s8wPKSK8mbNWaak5NXIFTnztFAaUIIKbnIyEi0b98emzZtwo8//ojnz5/zHRIhJaZwIrR8+XL4+PhgzZo1UFcvSB5atmyJP/74o0yDK0/56wip5q9omp3KYzSEEFL1SCQSbN68Ge3atUNkZCQAICMjA7du3eI5MkJKTuFEyM/PDzt37oSbmxuEwoJxNNbW1nj48GGZBlee0sXpAP6bOg8Aapr8BUMIIVVMQkIC+vXrh+nTpyMrKwsA0KpVK9y6dQuDBg3iOTpCSk7hROjly5ewtLSUKZdIJMjJ72aqQnIF/73QN+c1DkIIqSr+/vtvWFlZITg4mCvz8PDAjRs30LJlyyKuJKTyUTgRat68OS5duiRTfujQIbRu3bpMgqpIz9T+23w18wOvcRBCSGWXlpaGSZMmwdnZGcnJyQAAY2NjBAcHY8OGDdDQ0OA5QkIUp/D0+UWLFmH06NF4+fIlJBIJjhw5gujoaPj5+eH48ePlEWO56pSRN/MtVNiW1hAihJAipKSk4PDhw9yxs7Mzdu3aBQMDAx6jIqR0FG4R+u677/DPP//g7Nmz0NbWxqJFixAVFYV//vkHvXv3Lo8Yy1WmIK9vbO+tBK6M1hAihBBZxsbG+OOPP6ClpYVdu3bhyJEjlASRKu+rFlTs2rUrzpw5U9ax8EL036yxhJwaXBmtIUQIIcDz58+hra2NWrVqcWXfffcd4uPjUadOHR4jI6TsKNwiZGFhgbdv38qUf/jwARYWFmUSVEXSk+RtvpqNvKUAaA0hQggBAgMDYWVlhYkTJ4Ix6b0YKQki1YnCidCTJ08gFotlyrOysvDy5csyCaoiWWTnzXRLQY1iahJCSPWXkpICd3d3uLi44MOHDzh06BACAgL4DouQclPirrGgoCDudXBwMPT09LhjsViMc+fOwczMrEyDqwhNsrMBAM8+SXiOhBBC+BUaGgo3NzfEx8dzZS4uLujXrx+PURFSvkqcCDk7OwMABAIBRo8eLXVOTU0NZmZmWL9+fZkGVxFUALwWFAz2o4HShBBlk5ubixUrVmDZsmVci7+Ojg62bduGESNGQCAQFHMHQqquEidCkv/G0pibm+PmzZvVZqaAUa4YKow2WyWEKKe4uDiMGDECoaGhXJmdnR327t0Lc3NaaJZUfwrPGvu8ybQ60JZIoIM0ADRQmhCiXB4/fow2bdrg06dPAAChUIhFixZh/vz5UFX9qknFhFQ5X/WdnpaWhosXL+LZs2fI/m+MTb5p06aVSWAVRV8iwW1BK77DIISQCtewYUP07NkTx44dg4WFBfz9/dGxY0e+wyKkQimcCN2+fRv9+vVDeno60tLSUKtWLSQnJ0NLSwt16tSpcomQiDE0QfVq5SKEkJIQCATYtWsXTE1NsWzZMujo6PAdEiEVTuHp8x4eHnBycsL79++hqamJa9eu4enTp7C1tcW6devKI8ZyJQBwOrcN32EQQki5ys7OhqenJ06cOCFVbmBggE2bNlESRJSWwolQREQEZs6cCRUVFQiFQmRlZcHExARr1qzB/PnzyyPGcvNNbt4g6ZqCvDFCNGOMEFIdRUdHo1OnTli9ejXGjh2L169f8x0SIZWGwomQmpoaVFTyLqtTpw6ePXsGANDT08Pz58/LNrpypoL/ttdg3wCgGWOEkOqFMQZvb2+0bt0a4eHhAID379/jypUrPEdGSOWh8Bih1q1b4+bNm2jUqBG6deuGRYsWITk5GXv27EHLli3LI8Zyk78yxktmQDPGCCHVSlJSEsaPHy+1GG6TJk0QEBCANm1oOAAh+RRuEVq5ciWMjfMShhUrVkBfXx+TJ09GUlISvL29yzzA8pTfEZYD6hIjhFQfwcHBsLKykkqCJk+ejPDwcEqCCPmCwi1Cbdu25V7XqVMHp0+fLtOAKpLKf/sICkHbaxBCqr7MzEzMmzcPmzZt4soMDAzw119/wcnJib/ACKnEFG4RKkx4eDgGDBhQVrerEIL/xghlQY3nSAghpPTevHmD3bt3c8eOjo6IjIykJIiQIiiUCAUHB2PWrFmYP38+4uLiAAAPHz6Es7Mz2rVrx23DUVUkC/O6xJJYTX4DIYSQMtCgQQNs374dIpEIW7ZswcmTJ2FkZMR3WIRUaiXuGvvzzz8xYcIE1KpVC+/fv8cff/yBDRs2YOrUqXBxccG9e/fQrFmz8oy1zGX+N/stl8YIEUKqoISEBGhra0NXV5cr++GHH9ClSxeYmJjwGBkhVUeJW4Q2b96M1atXIzk5GYGBgUhOToaXlxciIyOxY8eOKpcEAUDzrCwA1DVGCKl6/v77b1hZWcldzZ+SIEJKrsSJUGxsLIYNGwYAGDx4MFRVVbF27VrUr1+/3IIrb8L/Bks/lNAPDUJI1ZCWloZJkybB2dkZycnJ8PX1xeHDh/kOi5Aqq8RdYxkZGdDS0gKQtz+NSCTiptFXVflZYBo0IeI1EkIIKV5YWBhcXV0RExPDlTk7O6Nbt248RkVI1abQ9Pk//vgDNWrUAADk5ubCx8cHBgYGUnWq0qar+StLZyu+igAhhFQYsViMdevWYeHChcjNzQUAaGlpYfPmzRg3bhwEAkExdyCEFKbEGUCDBg2wa9cu7tjIyAh79uyRqiMQCBROhLZt24a1a9ciMTER1tbW+P3339G+fftC63/48AELFizAkSNH8O7dO5iammLTpk3o16+fQs8FCtYRKlhjmhBCKpfnz59j5MiRuHjxIldma2uLgIAANG7cmMfICKkeSpwIPXnypMwffuDAAcyYMQM7duxAhw4dsGnTJjg4OCA6Ohp16tSRqZ+dnY3evXujTp06OHToEOrVq4enT5+iZs2aX/V8IYCPqFG6N0EIIeUkJiYGHTp0wIcPHwDk/bHp6emJJUuWQF1dnd/gCKkmeO0T2rBhAyZMmIAxY8YAAHbs2IETJ07gr7/+gqenp0z9v/76C+/evcPVq1ehppY308vMzOyrn68CBj2kfvX1hBBSniwtLdGhQwcEBwfDxMQEe/bsofFAhJSxMltZWlHZ2dkICwtDr169CoJRUUGvXr0QGhoq95qgoCB06tQJP/30EwwNDdGyZUusXLkSYrH462IQCBAmafRV1xJCSHlTUVHB7t278eOPP+LOnTuUBBFSDnhLhJKTkyEWi2FoaChVbmhoiMTERLnXxMXF4dChQxCLxTh58iR++eUXrF+/HsuXLy/0OVlZWUhJSZH6yvdETQ1ZLK9lSVtEiyoSQviTm5uLpUuX4vz581LlxsbG8Pb2hr6+Pk+REVK9VanpUhKJBHXq1MHOnTshFApha2uLly9fYu3atVi8eLHca1atWoWlS5fKPWebmYXmKk8BADP7NCm3uAkhpChxcXEYMWIEQkNDUa9ePdy9exe1atXiOyxClAJvLUIGBgYQCoV4/fq1VPnr168L3RvH2NgYjRs3hlBY0HrTrFkzJCYmIjs7W+418+bNw8ePH7mv58+fc+eEjOGmpAmMdDXQr1XVXhOJEFL1MMbg5+cHGxsbbkhAYmIiLly4wHNkhCiPr0qEYmNjsXDhQvzwww948+YNAODUqVO4f/9+ie+hrq4OW1tbnDt3jiuTSCQ4d+4cOnXqJPeazp074/Hjx1Kbu8bExMDY2LjQGRQikQi6urpSX/mEAFKgXeKYCSGkrLx//x7Dhw/H6NGj8enTJwCAhYUFLl++jCFDhvAcHSHKQ+FE6OLFi2jVqhWuX7+OI0eOIDU1b9bVnTt3Cu2eKsyMGTOwa9cu+Pr6IioqCpMnT0ZaWho3i2zUqFGYN28eV3/y5Ml49+4dfv75Z8TExODEiRNYuXIlfvrpJ0XfBoC8FiEx461RjBCipEJCQmBlZYXAwECuzN3dHREREejYsSOPkRGifBQeI+Tp6Ynly5djxowZ0NHR4cp79OiBrVu3KnQvFxcXJCUlYdGiRUhMTISNjQ1Onz7NDaB+9uwZVFQKEhUTExMEBwfDw8MDVlZWqFevHn7++WfMnTtX0bcBIK9FKJe/3kFCiJLJzs7G4sWLsXr1ajCWt6JrzZo1sXPnTm4vR0JIxVI4EYqMjERAQIBMeZ06dZCcnKxwAFOmTMGUKVPkngsJCZEp69SpE65du6bwc+QRAxCDZosRQirGixcv8Pvvv3NJUPfu3eHn50e7xRPCI4WbQ2rWrImEhASZ8tu3b6NevXplElRFeSsUQkwtQoSQCmJhYYHNmzdDTU0Na9aswblz5ygJIoRnCmcBw4cPx9y5c5GYmAiBQACJRIIrV65g1qxZGDVqVHnEWG6ss7LQQPCG7zAIIdVUcnIy0tPTpcrGjh2LBw8eYPbs2VJd/4QQfij8X+HKlSvRtGlTmJiYIDU1Fc2bN8e3334LOzs7LFy4sDxiLDdqDLglofWDCCFlLzg4GK1atcLs2bOlygUCASwtLXmKihDyJYUTIXV1dezatQuxsbE4fvw49u7di4cPH2LPnj1S6/tUBW+FKqghyOA7DEJINZKZmQkPDw84OjoiMTERXl5eOHHiBN9hEUIKofBg6cuXL6NLly5o0KABGjRoUB4xVRiznFxEsm/4DoMQUk1ERkbCzc0NkZGRXJmjoyNsbW15jIoQUhSFW4R69OgBc3NzzJ8/Hw8ePCiPmCqMiDGkMFpQkRBSOhKJBJs3b0a7du24JEgkEmHLli04efJkoavlE0L4p3Ai9OrVK8ycORMXL15Ey5YtYWNjg7Vr1+LFixflEV+5EjKG7Kq13RohpJJJSEhAv379MH36dGRlZQEAWrVqhVu3bmHq1KkQCAQ8R0gIKYrCiZCBgQGmTJmCK1euIDY2FsOGDYOvry/MzMzQo0eP8oix3KgCeMNq8h0GIaSKio6OhpWVFYKDg7kyDw8P3LhxAy1btuQxMkJISZVq7qa5uTk8PT3x22+/oVWrVrh48WJZxVUhhIwhAyK+wyCEVFGWlpZo3rw5gLxNoYODg7FhwwZoaGjwHBkhpKS+OhG6cuUK/ve//8HY2Biurq5o2bJllZsZkS0QIIVp8R0GIaSKEgqF2LNnD0aOHIm7d++iT58+fIdECFGQwgNk5s2bh/379+PVq1fo3bs3Nm/ejO+++w5aWlUvodCVSJANVdpkgxBSLLFYjHXr1qFr166ws7Pjyhs0aAA/Pz8eIyOElIbCidD//d//Yfbs2fj+++9hYGBQHjFVGHXGkEOJECGkGM+fP8fIkSNx8eJFmJubIyIiArq6unyHRQgpAwonQleuXCmPOHihAiADIlBvPiGkMIGBgZg4cSI+fPgAAHjy5An+/fdfDB06lN/ACCFlokSJUFBQEPr27Qs1NTUEBQUVWXfgwIFlElhFEADIoenzhBA5UlJSMG3aNPj6+nJlJiYm2LNnD7p168ZjZISQslSiLMDZ2RmJiYmoU6cOnJ2dC60nEAggFovLKrZyJwAgAa3xQQiRFhoaihEjRiAuLo4rc3Fxwfbt26Gvr89jZISQslaiREgikch9XdWJmQoAAbRFNEqIEALk5uZixYoVWLZsGfdHnY6ODrZt24YRI0bQ4oiEVEMKT5/38/PjVk/9XHZ2dtWbOcHyfqjN7EM70BNCgNjYWKxatYpLguzs7HDnzh2MHDmSkiBCqimFE6ExY8bg48ePMuWfPn3CmDFjyiSoisKgAiNdDfRrZcx3KISQSqBJkyZYs2YNhEIhli5dys0SI4RUXwqPFGaMyf3L6MWLF9DT0yuToCqKpiAbYHxHQQjhy/v376GlpQWRqGCF+alTp6JHjx60RQYhSqLEiVDr1q0hEAggEAjQs2dPqKoWXCoWixEfHw9HR8dyCbK8qFASRIjSCgkJwciRIzF8+HCsXbuWKxcIBJQEEaJESpwI5c8Wi4iIgIODA2rUqMGdU1dXh5mZGYYMGVLmAZanl8wANGmMEOWSnZ2NxYsXY/Xq1WCMYd26dXB0dETPnj35Do0QwoMSJ0KLFy8GAJiZmcHFxaVabCqogwy+QyCEVKDo6Gi4uroiPDycK7O3t0eTJjRhghBlpfBg6dGjR1eLJAgAaiCT7xAIIRWAMQZvb2+0bt2aS4LU1NSwZs0anD17FvXr1+c5QkIIX0rUIlSrVi3ExMTAwMAA+vr6RU4jfffuXZkFV96iJKagjcYIqd6SkpIwfvx4qVXxmzRpgoCAALRp04bHyAghlUGJEqGNGzdCR0eHe11d1tNgNECIkGotOjoa3bt3R2JiIlc2efJkrFu3DlpaWjxGRgipLEqUCI0ePZp77e7uXl6xVDimeM8gIaQKsbCwgImJCRITE2FgYIC//voLTk5OfIdFCKlEFM4EwsPDERkZyR3//fffcHZ2xvz585GdnV2mwZU3VUYtQoRUZ2pqavD398fgwYMRGRlJSRAhRIbCidDEiRMRExMDAIiLi4OLiwu0tLRw8OBBzJkzp8wDLE8aYmoRIqS6kEgk2LJlC27fvi1V3qhRIxw+fBhGRkY8RUYIqcwUzgRiYmJgY2MDADh48CC6deuGgIAA+Pj44PDhw2UdX7lqrvKM7xAIIWUgISEB/fr1w88//wxXV1ekp6fzHRIhpIpQOBFijHE70J89exb9+vUDAJiYmCA5OblsoytnV8RWfIdACCmlv//+G1ZWVggODgYAPHz4EKdOneI5KkJIVaFwItS2bVssX74ce/bswcWLF9G/f38AQHx8PAwNDcs8wPIkZjR3npCqKi0tDZMmTYKzszP3R5ixsTGCg4Or3Cr3hBD+KLzp6qZNm+Dm5oZjx45hwYIFsLS0BAAcOnQIdnZ2ZR5geWqoksB3CISQrxAWFgZXV1duvCKQtw3Qrl27YGBgwGNkhJCqRuFEyMrKSmrWWL61a9dCKKxaLSz3xJZ8h0AIUYBYLMbatWvxyy+/IDc3FwCgpaWFTZs2Yfz48dVmjTNCSMVROBHKFxYWhqioKABA8+bNq+QKrTlf//YJITx4+PChVBJka2uLgIAANG7cmOfICCFVlcJjhN68eQN7e3u0a9cO06ZNw7Rp09C2bVv07NkTSUlJ5RFjucmlMUKEVCktWrTAsmXLIBAIMG/ePFy9epWSIEJIqSicCE2dOhWpqam4f/8+3r17h3fv3uHevXtISUnBtGnTyiPGciOGGt8hEEKK8OnTJ671J9/s2bNx48YNrFy5Eurq6jxFRgipLhROhE6fPg0vLy80a9aMK2vevDm2bdtWpaasChiDvuAT32EQQgoRGhoKGxsbLF++XKpcKBSibdu2PEVFCKluFE6EJBIJ1NRkW1LU1NS49YWqAgGA10yf7zAIIV/Izc3F0qVL0bVrV8TFxWHZsmW4evUq32ERQqophROhHj164Oeff8arV6+4spcvX8LDwwM9e/Ys0+DKkwBAKjT5DoMQ8pm4uDh8++23WLJkCcRiMQCgY8eOMDY25jkyQkh1pXAitHXrVqSkpMDMzAwNGzZEw4YNYW5ujpSUFPz+++/lEWO5EACQgKbaElIZMMbg5+cHGxsbhIaGAsjrAlu6dCkuXrwIc3NzniMkhFRXCs8fNzExQXh4OM6dO8dNn2/WrBl69epV5sGVJwEACaNNVwnh2/v37zF58mQcOHCAK7OwsIC/vz86duzIY2SEEGWgUCJ04MABBAUFITs7Gz179sTUqVPLK65yJ2DUIkQI36Kjo9G7d288f/6cK3N3d8eWLVugo6PDY2SEEGVR4iaR7du344cffsCtW7fw6NEj/PTTT5g9e3Z5xlauBGAQK94zSAgpQ6ampqhZsyYAQF9fH4GBgdi9ezclQYSQClPiTGDr1q1YvHgxoqOjERERAV9fX3h5eZVnbOVKAIBRixAhvNLQ0EBAQAD69euHu3fvYtiwYXyHRAhRMiVOhOLi4jB69Gju2NXVFbm5uUhIqJoblwoAahEipAIxxrBz5048ePBAqrxly5Y4ceIE6tevz1NkhBBlVuJMICsrC9ra2gUXqqhAXV0dGRkZ5RJYRZBQIkRIhUhKSoKzszMmTpwIV1dXZGVl8R0SIYQAUHCw9C+//AItLS3uODs7GytWrICenh5XtmHDhrKLrhwJAKgjt9h6hJDSCQ4Ohru7OxITEwEAd+7cwfHjxzFkyBCeIyOEEAUSoW+//RbR0dFSZXZ2doiLi+OOBYKqM+ZGACCbdp8npNxkZmbC09MTmzdv5soMDAzw119/wcnJicfICCGkQIkzgZCQkHIMo+IJGJAOEd9hEFItRUZGwtXVFffu3ePKHBwc4OPjAyMjIx4jI4QQaUo9SIYGSxNStiQSCTZv3ox27dpxSZBIJMLmzZtx8uRJSoIIIZWO0vYNCcBosDQhZSwyMhIzZszgNmBu1aoVAgIC0LJlS54jI4QQ+ZQ2E6B1hAgpe9bW1pg/fz4AwMPDAzdu3KAkiBBSqSlxixAgYZQIEVIa6enp0NDQgIpKwd9UixYtQp8+fdC1a1ceIyOEkJJR6hYh2muMkK8XFhaG1q1bY/369VLlampqlAQRQqqMr0qELl26hBEjRqBTp054+fIlAGDPnj24fPlymQZXnvISIaXNAwn5amKxGKtXr0bHjh0RExODBQsWIDw8nO+wCCHkqyicCRw+fBgODg7Q1NTE7du3uRViP378iJUrV5Z5gOXlvVBIY4QIUdDz58/Rs2dPeHp6Ijc3b0FSKysr1KhRg+fICCHk6yicCC1fvhw7duzArl27oKamxpV37ty5Sv1VWCtXDDFUoC0S8h0KIVVCYGAgrKyscPHiRQB5C6jOmzcPV69eRePGjXmOjhBCvo7Cg6Wjo6Px7bffypTr6enhw4cPZRFThVAFgwQCzOzThO9QCKnUUlJSMG3aNPj6+nJlJiYm2LNnD7p168ZjZIQQUnoKtwgZGRnh8ePHMuWXL1+GhYVFmQRVEQQAvtEWoV8rY75DIaTSio6ORuvWraWSIBcXF9y9e5eSIEJItaBwIjRhwgT8/PPPuH79OgQCAV69egV/f3/MmjULkydPLo8Yy81HgQ7fIRBSqdWvXx+qqnkNxzo6OvDz88O+fftQs2ZNfgMjhJAyonAi5OnpCVdXV/Ts2ROpqan49ttvMX78eEycOBFTp079qiC2bdsGMzMzaGhooEOHDrhx40aJrtu/fz8EAgGcnZ0VfqYAQAY0FL6OEGWira2NgIAAdO/eHXfu3MHIkSOr1ObKhBBSHIUTIYFAgAULFuDdu3e4d+8erl27hqSkJCxbtuyrAjhw4ABmzJiBxYsXIzw8HNbW1nBwcMCbN2+KvO7JkyeYNWtWqdYryYZa8ZUIURKMMfj5+SE2Nlaq3NbWFufPn4e5uTlPkRFCSPn56oV01NXV0bx5c7Rv375UU2c3bNiACRMmYMyYMWjevDl27NgBLS0t/PXXX4VeIxaL4ebmhqVLl371uCQBAzJp93lCAADv37/H8OHDMXr0aLi5uSEnJ0fqPLUCEUKqK4Vnjdnb2xf5Q/H8+fMlvld2djbCwsIwb948rkxFRQW9evVCaGhoodf9+uuvqFOnDsaNG4dLly4V+YysrCxurSMgbwZMPiagBRUJCQkJwciRI/HixQsAwPXr13H8+HEMGjSI58gIIaT8KZwI2djYSB3n5OQgIiIC9+7dw+jRoxW6V3JyMsRiMQwNDaXKDQ0N8fDhQ7nXXL58GX/++SciIiJK9IxVq1Zh6dKlCsVFiDLIzs7GokWLsGbNGjDGAAD6+vrYuXMnJUGEEKWhcCK0ceNGueVLlixBampqqQMqyqdPnzBy5Ejs2rULBgYGJbpm3rx5mDFjBneckpICExOT8gqRkCohOjoarq6uUoug2tvbw8/PD/Xr1+cxMkIIqVhltvv8iBEj0L59e6xbt67E1xgYGEAoFOL169dS5a9fv4aRkZFM/djYWDx58gROTk5cmUQiAQCoqqoiOjoaDRs2lLpGJBJBJJIdC0QjHogyYoxh586d8PDwQEZGBoC8TVJXrFiBmTNnSu0iTwghyqDMfuqFhoZCQ0Ox6ejq6uqwtbXFuXPnuDKJRIJz586hU6dOMvWbNm2KyMhIREREcF8DBw6Evb09IiIiqKWHkGLcvn0bkyZN4pKgJk2a4Nq1a5g9ezYlQYQQpaRwi9DgwYOljhljSEhIwK1bt/DLL78oHMCMGTMwevRotG3bFu3bt8emTZuQlpaGMWPGAABGjRqFevXqYdWqVdDQ0EDLli2lrs9f2O3LckKIrDZt2mDGjBnYsGEDJk+ejHXr1kFLS4vvsAghhDcKJ0J6enpSxyoqKmjSpAl+/fVX9OnTR+EAXFxckJSUhEWLFiExMRE2NjY4ffo0N4D62bNn9JcqIV8pKysL6urqUjM9V65cCUdHR/Tu3ZvHyAghpHIQsPzpIiUgFotx5coVtGrVCvr6+uUZV7lJSUmBnp4eem5pjNRPXrg2vyffIRFSLiIjI+Hq6orJkyfjf//7H9/hEEJIqeT//v748SN0dXXL7L4KNbUIhUL06dOnSu0yT4iykUgk2Lx5M9q1a4d79+5h5syZePDgAd9hEUJIpaRwn1PLli0RFxdXHrFUKJo1RqqjhIQE9OvXD9OnT+cWEm3UqBHPURFCSOWlcCK0fPlyzJo1C8ePH0dCQgJSUlKkvqqKEvcHElJF/P3337CyskJwcDBX5uHhgRs3bqB58+Y8RkYIIZVXiQdL//rrr5g5cyb69esHABg4cKDUAEzGGAQCAcRicdlHWQ4ElAmRaiItLQ0zZ86Et7c3V2ZsbAwfH5+vmsBACCHKpMSJ0NKlSzFp0iRcuHChPOOpMCoCCd8hEFJqMTExcHJyQkxMDFfm7Oys0OrrhBCizEqcCOVPLuvWrVu5BVORGKNRQqTqMzQ0RHZ2NgBAS0sLmzdvxrhx42i3eEIIKSGFxghVpx+ukrJbVJsQ3ujp6WHv3r3o0KEDbt++jfHjx1er/04JIaS8KbSgYuPGjYv9Ifvu3btSBVRR6FcFqYoOHjyIjh07Sm0n07lzZ4SGhlICRAghX0GhRGjp0qUyK0sTQspfSkoKpk2bBl9fX3Tv3h1nz56FUCjkzlMSRAghX0ehRGj48OGoU6dOecVCCJEjNDQUI0aM4NbvCgkJwfHjx/Hdd9/xHBkhhFR9JR4oQ39xElKxcnNzsXTpUnTt2pVLgnR0dODn54eBAwfyHB0hhFQPCs8aI4SUv7i4OIwYMQKhoaFcmZ2dHfbu3Qtzc3MeIyOEkOqlxC1CEomEusUIKWeMMfj5+cHGxoZLgoRCIZYuXYqLFy9SEkQIIWVMoTFChJDydevWLYwePZo7trCwgL+/Pzp27MhjVIQQUn3RYjqEVCLt2rXDxIkTAQDu7u6IiIigJIgQQsoRtQgRwqOcnByoqqpKTUZYv349+vXrRwOiCSGkAihtixDNgSN8i46ORseOHeHr6ytVrq2tTUkQIYRUEKVNhAjhC2MM3t7eaN26NcLDwzF16lQ8fvyY77AIIUQpKW3XmIBWAyA8SEpKwvjx4xEUFMSV1atXDxkZGTxGRQghyktpW4QYdY6RChYcHAwrKyupJGjSpEkIDw9Hq1ateIyMEEKUl9ImQpQGkYqSmZkJDw8PODo6IjExEQBgYGCAoKAgbN++HVpaWjxHSAghyktpu8YIqQiPHz/G4MGDERkZyZU5Ojpi9+7dMDIy4jEyQgghALUIEVKu9PX18fbtWwCASCTCli1bcPLkSUqCCCGkklDaRIjGSpOK8M0338DHxwfW1ta4desWpk6dShsYE0JIJaK0iRD9KiLl4Z9//uHGAeXr3bs3wsLC0LJlS56iIoQQUhilTYQIKUtpaWmYNGkSBg4ciLFjx4Ix6TZHoVDIU2SEEEKKQokQIaUUFhaGNm3awNvbGwBw6tQpHD9+nOeoCCGElAQlQoR8JbFYjNWrV6Njx46IiYkBAGhpaWHXrl0YMGAAz9ERQggpCaWdPk9jhEhpPH/+HCNHjsTFixe5MltbWwQEBKBx48Y8RkYIIUQR1CJEiIIOHDgAKysrLgkSCASYN28erl69SkkQIYRUMUrbIkRtQuRrXLt2DcOHD+eOTUxMsGfPHnTr1o3HqAghhHwtahEiRAEdO3bEyJEjAQAuLi64c+cOJUGEEFKFKW2LEO0+T0pCIpFARUX674WtW7eif//++P7772lxREIIqeKoRYiQQsTFxaFLly4IDAyUKtfV1YWLiwslQYQQUg1QIkTIFxhj8PPzg42NDUJDQzFx4kQ8f/6c77AIIYSUA0qECPnM+/fvMXz4cIwePRqfPn0CANSqVYvbOJUQQkj1QokQIf8JCQmBlZWVVFeYu7s7IiIiYGNjw19ghBBCyg0lQkTpZWdnw9PTEz169MCLFy8AADVr1kRgYCB2794NHR0dniMkhBBSXpR21tgTDUA3ne8oCN/i4uIwbNgwhIeHc2Xdu3eHn58fTExMeIyMEEJIRVDaFqG62XxHQCoDTU1NPHv2DACgpqaGNWvW4Ny5c5QEEUKIklDaREhbTAsJEcDY2Bh//vknmjZtimvXrmH27Nky6wYRQgipvpT2J76mgJqElNHZs2dlZoANHDgQd+/eRZs2bXiKihBCCF+UNhFKZZp8h0AqUGZmJjw8PNC7d29MnDgRjEm3CKqpqfEUGSGEED4pbSJElEdkZCTat2+PTZs2AQAOHz6M06dP8xsUIYSQSoESIVJtSSQSbN68Ge3atUNkZCQAQCQSYcuWLXB0dOQ5OkIIIZWB0k6fJ9VbQkICxowZg+DgYK6sVatWCAgIQMuWLXmMjBBCSGWixC1CtGFmdRUUFAQrKyupJMjDwwM3btygJIgQQogUahEi1cqVK1fw3XffccdGRkbw9fVFnz59eIyKEEJIZaXELUKkOrKzs8OgQYMAAN999x0iIyMpCSKEEFIoahEiVRpjDAJBQTenQCDArl27MHDgQIwePVrqHCGEEPIlpW0Rol+PVd/z58/Ro0cPHD9+XKr8m2++gbu7OyVBhBBCiqW0iRCp2gIDA2FlZYWQkBCMHTsWiYmJfIdECCGkClLqREhbJOQ7BKKglJQUuLu7w8XFBR8+fAAAaGho4NWrV/wGRgghpEpS6kRoZp8mfIdAFBAaGgobGxv4+vpyZS4uLrhz5w7tE0YIIeSrKG0ipCIA+rUy5jsMUgK5ublYsmQJunbtivj4eACAjo4O/Pz8sG/fPujr6/McISGEkKqKZo2RSu3JkydwdXVFaGgoV2ZnZ4e9e/fC3Nycx8gIIYRUB0rbIkSqBhUVFTx48AAAIBQKsXTpUly8eJGSIEIIIWVCeRMhRlOrq4IGDRpgx44dsLCwwOXLl7Fo0SKoqlJDJiGEkLKhvIkQqZQuXbqElJQUqbLhw4fj/v376NixI09REUIIqa4qxZ/W27Ztw9q1a5GYmAhra2v8/vvvaN++vdy6u3btgp+fH+7duwcAsLW1xcqVKwutT6qG7OxsLFq0CGvWrMHIkSOlZoYBeVPkSdUnkUiQnZ3NdxiEkEpKXV0dKioV20bDeyJ04MABzJgxAzt27ECHDh2wadMmODg4IDo6GnXq1JGpHxISgh9++AF2dnbQ0NDA6tWr0adPH9y/fx/16tXj4R2Q0oqOjoarqyvCw8MBAH5+fnBzc6M9wqqZ7OxsxMfHQyKR8B0KIaSSUlFRgbm5OdTV1SvsmQLGGKuwp8nRoUMHtGvXDlu3bgWQ9xejiYkJpk6dCk9Pz2KvF4vF0NfXx9atWzFq1Khi66ekpEBPTw/fbWiFYx53Sx0/+XqMMezcuRMeHh7IyMgAAKipqWHFihWYOXNmhf9VQMoPYwzPnj1DTk4O6tatS/+2hBAZEokEr169gpqaGho0aCCzTVL+7++PHz9CV1e3zJ7La4tQdnY2wsLCMG/ePK5MRUUFvXr1kpouXZT09HTk5OSgVq1acs9nZWUhKyuLO/5y/AnhR1JSEsaPH4+goCCurEmTJggICKDFEauh3NxcpKeno27dutDS0uI7HEJIJVW7dm28evUKubm5UFNTq5Bn8vpnWXJyMsRiMQwNDaXKDQ0NS7x31Ny5c1G3bl306tVL7vlVq1ZBT0+P+zIxMSl13KR0goODYWVlJZUETZ48GeHh4ZQEVVNisRgAKrS5mxBS9eT/jMj/mVERqnT79G+//Yb9+/fj6NGjhQ6mnTdvHj5+/Mh9PX/+vIKjJJ+7dOkSHB0duUTXwMAAQUFB8PLyopYCJfBlUzchhHyOj58RvCZCBgYGEAqFeP36tVT569evYWRkVOS169atw2+//YZ///0XVlZWhdYTiUTQ1dWV+iL86dKlCxwdHQEAjo6OiIyMhJOTE89REUIIUVa8JkLq6uqwtbXFuXPnuDKJRIJz586hU6dOhV63Zs0aLFu2DKdPn0bbtm0rIlRSRgQCAXbv3g0vLy+cPHmy2ISXkKqse/fumD59epF1zMzMsGnTpgqJh5TMt99+i4CAAL7DqHZ27NhRKf/w5b1rbMaMGdi1axd8fX0RFRWFyZMnIy0tDWPGjAEAjBo1Smow9erVq/HLL7/gr7/+gpmZGRITE5GYmIjU1FS+3gIpRGJiIvr37y+V6AKAkZERJk+eTN0kpNJzd3eHQCCQ+Xr8+HGFxXD//n0MGTIEZmZmEAgEJUqaQkJCpOKtXbs2+vXrh8jISJm6z58/x9ixY1G3bl2oq6vD1NQUP//8M96+fStT9/HjxxgzZgzq168PkUgEc3Nz/PDDD7h161ZZvNVKISgoCK9fv8bw4cP5DqXc3L17F127doWGhgZMTEywZs2aYq85d+4c7OzsoKOjAyMjI8ydOxe5ublSdRhjWLduHRo3bgyRSIR69ephxYoV3PmxY8ciPDwcly5dKvP3VBq8J0IuLi5Yt24dFi1aBBsbG0REROD06dPcAOpnz54hISGBq799+3ZkZ2dj6NChMDY25r7WrVun0HPpV3D5CgoKQqtWrXDy5EmMHj1a7g9VQqoCR0dHJCQkSH1V5F536enpsLCwwG+//aZwC2p0dDQSEhIQHByMrKws9O/fX2pBy7i4OLRt2xaPHj3Cvn378PjxY+zYsYNrlX/37h1X99atW7C1tUVMTAy8vb3x4MEDHD16FE2bNsXMmTPL7P0WRywWl+taVFu2bMGYMWNKtcRDecdYGikpKejTpw9MTU0RFhaGtWvXYsmSJdi5c2eh19y5cwf9+vWDo6Mjbt++jQMHDiAoKEhmiZuff/4Zf/zxB9atW4eHDx8iKChIarFjdXV1uLq6YsuWLeX2/r4KUzIfP35kANh3G1rxHUq1lJqayiZOnMgAcF/Gxsbs1q1bfIdGeJSRkcEePHjAMjIy+A5FIaNHj2bfffddoedDQkJYu3btmLq6OjMyMmJz585lOTk53Plu3bqxn3/+mTt+/fo1GzBgANPQ0GBmZmZs7969zNTUlG3cuLFE8ZS07oULFxgA9v79e64sKCiIAWB37tzhyhwdHVn9+vVZenq61PUJCQlMS0uLTZo0iTHGmEQiYS1atGC2trZMLBbLPO/z53xJLBaz1atXs4YNGzJ1dXVmYmLCli9fXmict2/fZgBYfHw8Y4yx3bt3Mz09Pfb333+zZs2aMaFQyLy9vZlIJJJ57rRp05i9vT13fOnSJdalSxemoaHB6tevz6ZOncpSU1MLjfXNmzdMIBCwe/fuSZWvX7+etWzZkmlpabH69euzyZMns0+fPnHn5cUYHx/PMjMz2cyZM1ndunWZlpYWa9++Pbtw4QJ3XXJyMhs+fDirW7cu09TUZC1btmQBAQGFxlcWvLy8mL6+PsvKyuLK5s6dy5o0aVLoNfPmzWNt27aVKgsKCmIaGhosJSWFMcbYgwcPmKqqKnv48GGRz7948SJTV1eX+Z7LV9TPivzf3x8/fizyGYrifWVpUn2EhYXBzc0N0dHRXJmzszN27doFAwMDHiMjlZHT75eR9Cmr+IplrLaOCP9M7VLq+7x8+RL9+vWDu7s7/Pz88PDhQ0yYMAEaGhpYsmSJ3Gvc3d3x6tUrXLhwAWpqapg2bRrevHlT6liK8/HjR+zfvx9AwfTkd+/eITg4GCtWrICmpqZUfSMjI7i5ueHAgQPw8vJCREQE7t+/j4CAALktJTVr1iz02fPmzcOuXbuwceNGdOnSBQkJCXj48KFC8aenp2P16tX4448/8M0336B+/fpYtGgRDh8+jHHjxgHIa4U5cOAA1xUTGxsLR0dHLF++HH/99ReSkpIwZcoUTJkyBbt375b7nMuXL0NLSwvNmjWTKldRUcGWLVtgbm6OuLg4/O9//8OcOXPg5eVVaIx16tTBlClT8ODBA+zfvx9169bF0aNHuUkijRo1QmZmJmxtbTF37lzo6urixIkTGDlyJBo2bFjotlHPnj1D8+bNi/y85s+fj/nz58s9Fxoaim+//VZqKQsHBwesXr0a79+/h76+vsw1WVlZMjOzNTU1kZmZibCwMHTv3h3//PMPLCwscPz4cTg6OoIxhl69emHNmjVS6/y1bdsWubm5uH79Orp3717k+6golAiRUhOLxVi3bh0WLlzI9RlraWlh8+bNGDduHI0FInIlfcpCYkom32EU6/jx46hRowZ33LdvXxw8eBBeXl4wMTHB1q1bIRAI0LRpU7x69Qpz587FokWLZBKGmJgYnDp1Cjdu3EC7du0AAH/++afML92yVL9+fQBAWloaAGDgwIFo2rQpAODRo0dgjBX6/GbNmuH9+/dISkrCo0ePAIC7tqQ+ffqEzZs3Y+vWrRg9ejQAoGHDhujSRbFENCcnB15eXrC2tubKhg8fjoCAAC4ROnfuHD58+IAhQ4YAyFtDzs3NjRus3qhRI2zZsgXdunXD9u3b5S658vTpUxgaGsr8230+4N3MzAzLly/HpEmTpBKhL2N89uwZdu/ejWfPnqFu3boAgFmzZuH06dPYvXs3Vq5ciXr16mHWrFncPaZOnYrg4GAEBgYWmgjVrVsXERERRX5ehS0wDOSN3fyyazd/KEpiYqLcRMjBwQGbNm3Cvn378P333yMxMRG//vorAHBDV+Li4vD06VMcPHgQfn5+EIvF8PDwwNChQ3H+/HnuXlpaWtDT08PTp0+LfA8VSWkTIfrVXDZevHiBkSNHIiQkhCuztbVFQEAAGjduzF9gpNKrrSOqEs+1t7fH9u3buWNtbW0AQFRUFDp16iSV6Hfu3Bmpqal48eIFGjRoIHWfqKgoqKqqwtbWlitr2rRpka0ppXXp0iVoaWnh2rVrWLlyJXbs2CFTh5Vgl6WS1JEnKioKWVlZ6Nmz51ddn09dXV1mmRQ3Nzd07NgRr169Qt26deHv74/+/ftzn+edO3dw9+5d+Pv7c9cwxiCRSBAfHy83AczIyJCbIJ09exarVq3Cw4cPkZKSgtzcXGRmZiI9PZ1b/+zLGCMjIyEWi2V+DmZlZeGbb74BkPdH5MqVKxEYGIiXL18iOzsbWVlZRa6ppqqqCktLy2I+sbLVp08frF27FpMmTcLIkSMhEonwyy+/4NKlS1zSKJFIkJWVBT8/P+49//nnn7C1tUV0dDSaNGnC3U9TUxPp6ekV+h6KorSJECkbGRkZuHnzJoC8qfGenp5YsmQJrSBMilUW3VMVQVtbu8J/8ZQVc3Nz1KxZE02aNMGbN2/g4uKC//u//wMAWFpaQiAQICoqCoMGDZK5NioqCvr6+qhduzb3i+3hw4do3bp1iZ//ZZfbl/J/iX6eaOXk5Mi9z5cty+3atUPDhg2xf/9+TJ48GUePHoWPjw93PjU1FRMnTsS0adNk7vdlkprPwMAA79+/lyp78uQJBgwYgMmTJ2PFihWoVasWLl++jHHjxiE7O5tLWr6MMTU1FUKhEGFhYRAKhVL3zG9hXLt2LTZv3oxNmzahVatW0NbWxvTp06UGtH+ptF1jRkZGctfuyz9XmBkzZsDDwwMJCQnQ19fHkydPMG/ePFhYWAAAjI2NoaqqKpX45Sebz549k0qE3r17h9q1axf5HiqSEidC1CZUFvKbm5csWYI9e/agW7dufIdESIVo1qwZDh8+DMYY9wvwypUr0NHR4bqkPte0aVPk5uYiLCyM6xqLjo7Ghw8fKiTen376CatWrcLRo0cxaNAgfPPNN+jduze8vLzg4eEhlbQkJibC398fo0aNgkAggI2NDZo3b47169fDxcVFpuvow4cPclu2GjVqBE1NTZw7dw7jx4+XOZ//yzD/lyuAYrt9Pufm5gZ/f3/Ur18fKioq6N+/P3euTZs2ePDggUJJbOvWrZGYmCg1ViYsLAwSiQTr16/n3ndgYGCJ7iUWi/HmzRt07dpVbp0rV67gu+++w4gRIwDktarExMQUmeiUtmusU6dOWLBgAXJycri9vM6cOYMmTZrI7Rb7nEAg4Lr59u3bBxMTE25bpM6dOyM3NxexsbFo2LAhgLzuYAAwNTXl7hEbG4vMzEyFEupyV6ZDr6uA/FHnzhus+A6lSrp+/TpLS0uTKpNIJFIzKAj5UnWcNfbixQumpaXFfvrpJxYVFcWOHTvGDAwM2OLFi7k6X84ac3R0ZK1bt2bXrl1jt27dYl26dGGamppFzgTLyspit2/fZrdv32bGxsZs1qxZ7Pbt2+zRo0eFXiNvNhZjjM2ZM4e1atWKSSQSxhhjMTExzMDAgHXt2pVdvHiRPXv2jJ06dYq1bNmSNWrUiL19+5a79vr160xHR4fZ2dmxEydOsNjYWHbnzh22fPly9u233xYay5IlS5i+vj7z9fVljx8/ZqGhoeyPP/5gjDGWnZ3NTExM2LBhw1hMTAw7fvw4a9KkidxZY/I8evSIAWBWVlZs3LhxUufu3LnDNDU12U8//cRu377NYmJi2LFjx9hPP/1UaKy5ubmsdu3a7J9//uHKIiIiGAC2adMmFhsby/z8/Fi9evWkPt/CYnRzc2NmZmbs8OHDLC4ujl2/fp2tXLmSHT9+nDHGmIeHBzMxMWFXrlxhDx48YOPHj2e6urpFzlQsrQ8fPjBDQ0M2cuRIdu/ePbZ//36mpaXFvL29uTpHjhyRmUW2Zs0advfuXXbv3j3266+/MjU1NXb06FHuvFgsZm3atGHffvstCw8PZ7du3WIdOnRgvXv3lrrP7t27mYWFRaHx8TFrjBIhUiI5OTlsyZIlTCgUssmTJ/MdDqliqmMixJji0+cTEhJY//79mUgkYg0aNGB+fn7FTomPj4+XWo4i/6tbt26FXlNYIvTs2TOmqqrKDhw4wJU9efKEjR49mhkaGjI1NTVmYmLCpk6dypKTk2XuGx0dzUaNGsXq1q3L1NXVmampKfvhhx9YeHh4obGIxWK2fPlyZmpqytTU1FiDBg3YypUrufOXL19mrVq1YhoaGqxr167s4MGDJU6EGGOsffv2DAA7f/68zLkbN26w3r17sxo1ajBtbW1mZWXFVqxYUei9GMtLFocPHy5VtmHDBmZsbMw0NTWZg4MD8/PzK1EilJ2dzRYtWsTMzMyYmpoaMzY2ZoMGDWJ3795ljDH29u1b9t1337EaNWqwOnXqsIULF7JRo0aVayLEWF6S2KVLFyYSiVi9evXYb7/9JnV+9+7d7Mt2Ent7e6anp8c0NDRYhw4d2MmTJ2Xu+/LlSzZ48GBWo0YNZmhoyNzd3aWSacYY69OnD1u1alWhsfGRCAkY+8pRcFVUSkoK9PT04LzBCkc97vAdTpUQFxeHESNGIDQ0lCs7f/487O3teYyKVCWZmZmIj4+Hubl5oRskE1IZJCYmokWLFggPD5fq0iGld//+ffTo0QMxMTHQ09OTW6eonxX5v78/fvxYpvuG8r6yNKm8GGPw8/ODjY0NlwQJhUIsXbq00D5vQgipyoyMjPDnn3/i2bNnfIdS7SQkJMDPz6/QJIgvSjtYmoZKF+39+/eYPHkyDhw4wJVZWFjA398fHTt25DEyQggpX87OznyHUC316tWL7xDkohYhIuPixYuwtraWSoLc3d0RERFBSRAhhJBqRWlbhIh8Fy9ehL29Pbeuh76+Pry9vTFs2DCeIyOEEELKHrUIESldunTBt99+CyBvRd27d+9SEkQIIaTaohYhIkUoFGLPnj04ePAgpk+fLneDRUIIIaS6oN9ySiwpKQlDhgzBlStXpMpNTEwwY8YMSoIIIYRUe9QipKSCg4Ph7u6OxMREhIeH486dO2W6LgMhhBBSFdCf/EomMzMT06dPh6OjIxITEwHkbQ6YvycMIYQQokyUNhESKNV62nkiIyPRrl07bN68mStzdHREZGQk2rZty2NkhFRP3bt3x/Tp04usY2Zmhk2bNlVIPKR42dnZsLS0xNWrV/kOpdrx9PTE1KlT+Q5DhtImQsqUB0kkEmzevBnt2rXDvXv3AAAikQhbtmzByZMnYWRkxHOEhFRO7u7uEAgEMl+PHz+usBh27dqFrl27Ql9fH/r6+ujVqxdu3LhR5DU+Pj5crCoqKjA2NoaLi4vc1ZLv37+P77//HrVr14ZIJELjxo2xaNEipKeny9S9ffs2hg0bBkNDQ2hoaKBRo0aYMGFCtWpR3rFjB8zNzWFnZ8d3KOUmJCQEbdq0gUgkgqWlJXx8fIq9JjAwEDY2NtDS0oKpqSnWrl0rU8ff3x/W1tbQ0tKCsbExxo4di7dv33LnZ82aBV9fX8TFxZXl2yk1pU2ElEVCQgL69euH6dOnIysrCwDQqlUr3Lp1C1OnToVAQGtsE1IUR0dHJCQkSH2Zm5tX2PNDQkLwww8/4MKFCwgNDYWJiQn69OmDly9fFnmdrq4uEhIS8PLlSxw+fBjR0dEyS2Fcu3YNHTp0QHZ2Nk6cOIGYmBisWLECPj4+6N27N7Kzs7m6x48fR8eOHZGVlQV/f39ERUVh79690NPTwy+//FIu712ez2Mqa4wxbN26FePGjSvVfcozxtKKj49H//79YW9vj4iICEyfPh3jx49HcHBwodecOnUKbm5umDRpEu7duwcvLy9s3LgRW7du5epcuXIFo0aNwrhx43D//n0cPHgQN27cwIQJE7g6BgYGcHBwwPbt28v1PSqsTLdwrQLyd68dvN6a71AqxL1795hIJOJ2rPbw8KhyO4CTqo92n8/z+vVrNmDAAKahocHMzMzY3r17i919/ku5ublMR0eH+fr6FlpH3m7oW7Zskdq5WyKRsObNm7O2bdsysVgsVTciIoIJBAJuV/K0tDRmYGDAnJ2d5T7vy13uP5eZmcnmzJnD6tevz9TV1VnDhg3ZH3/8UWicR48eldr5fPHixcza2prt2rWLmZmZMYFAwLy9vZmxsbFM3AMHDmRjxozhjo8dO8Zat27NRCIRMzc3Z0uWLJH69/nSzZs3mYqKCktJSZEqnzNnDmvUqBHT1NRk5ubmbOHChSw7O7vIGPM/l3HjxjEDAwOmo6PD7O3tWUREBHfd48eP2cCBA1mdOnWYtrY2a9u2LTtz5kyh8ZWFOXPmsBYtWkiVubi4MAcHh0Kv+eGHH9jQoUOlyrZs2cLq16/PJBIJY4yxtWvXMgsLC5k69erVkyrz9fVl9evXL/RZfOw+T7PGqrkWLVpg7dq1WLlyJXx9fdGnTx++QyIkj3c3IPVNxT+3Rh1g4sVS3+bly5fo168f3N3d4efnh4cPH2LChAnQ0NDAkiVL5F7j7u6OV69e4cKFC1BTU8O0adPw5o1in0F6ejpycnJQq1atEl/z5s0bHD16FEKhEEKhEAAQERGBBw8eICAgQGapDGtra/Tq1Qv79u3D3LlzERwcjOTkZMyZM0fu/WvWrFnos0eNGoXQ0FBs2bIF1tbWiI+PR3JycoljB4DHjx/j8OHDOHLkCIRCIUxMTDB16lRcuHABPXv2BAC8e/cOp0+fxsmTJwEAly5dwqhRo7BlyxZ07doVsbGx+PHHHwEAixcvlvucS5cuoXHjxtDR0ZEq19HRgY+PD+rWrYvIyEhMmDABOjo6Up/HlzECwLBhw6CpqYlTp05BT08P3t7e6NmzJ2JiYlCrVi2kpqaiX79+WLFiBUQiEfz8/ODk5ITo6Gg0aNCg0Bj79u1b5Ofl7e0NNzc3uedCQ0Nl9vxycHAocixbVlYWtLS0pMo0NTXx4sULPH36FGZmZujUqRPmz5+PkydPom/fvnjz5g0OHTqEfv36SV3Xvn17vHjxAk+ePIGZmVmR76OiUCJUzdy5cwdNmzaFSCTiyqZMmYIRI0ZAX1+fx8gI+ULqG+DTK76jKNbx48dRo0YN7rhv3744ePAgvLy8YGJigq1bt0IgEKBp06Z49eoV5s6di0WLFskkFzExMTh16hRu3LiBdu3aAQD+/PNPNGvWTKF45s6di7p16xa7geXHjx9Ro0YNMMa48T7Tpk2DtrY2Fw+AQp/frFkzXL58GQDw6NEjAEDTpk0VijUmJgaBgYE4c+YMF6+FhYVC9wDyupr8/PxQu3Ztrqxv374ICAjgEqFDhw7BwMAA9vb2AIClS5fC09MTo0eP5p67bNkyzJkzp9BE6OnTp6hbt65M+cKFC7nXZmZmmDVrFvbv3y+VCH0Z4+XLl3Hjxg28efOG+3m8bt06HDt2DIcOHcKPP/4Ia2trWFtbc/dYtmwZjh49iqCgIEyZMkVujG3btkVERESRn5ehoWGh5xITE2XOGxoaIiUlBRkZGdDU1JS5xsHBAR4eHnB3d4e9vT0eP36M9evXA8gbfmFmZobOnTvD398fLi4uyMzMRG5uLpycnLBt2zape+V/vvkJVGVAiVA1IRaLsW7dOixcuBA///wz1q1bx50TCASUBJHKp0adKvFce3t7qTEN+YlEVFQUOnXqJDXOrnPnzkhNTcWLFy9k/qKPioqCqqoqbG1tubKmTZsW2Zrypd9++w379+9HSEgINDQ0iqyro6OD8PBw5OTk4NSpU/D398eKFStk6jFW/NSRktSRJyIiAkKhEN26dfuq6/OZmppKJUEA4ObmhgkTJsDLywsikQj+/v4YPnw4l4DeuXMHV65ckXrPYrEYmZmZSE9Pl2nhAICMjAy5n+uBAwewZcsWxMbGIjU1Fbm5uTLrrn0Z4507d5CamopvvvlG5hmxsbEA8pYuWbJkCU6cOIGEhATk5uYiIyND7qD2fJqamrC0tCz0fHmYMGECYmNjMWDAAOTk5EBXVxc///wzlixZwn3eDx48wM8//4xFixbBwcEBCQkJmD17NiZNmoQ///xTKn4Acgfj80VpE6HqNET4+fPnGDlyJC5ezGvuX79+PZydndGlSxeeIyOkCGXQPVURtLW1K/wXjzzr1q3Db7/9hrNnz8LKyqrY+ioqKlzczZo1Q2xsLCZPnow9e/YAABo3bgwgL0Fr3bq1zPVRUVFcnfz/f/jwITp16lTimOW1LnwZ45dJVk5Ojky9/OTzc05OTmCM4cSJE2jXrh0uXbqEjRs3cudTU1OxdOlSDB48WObawpJIAwMDREZGSpWFhobCzc0NS5cuhYODA/T09LB//36uRaSwGFNTU2FsbIyQkBCZ5+Qnv7NmzcKZM2ewbt06WFpaQlNTE0OHDi1ysHVpu8aMjIzw+vVrqbLXr19DV1e30H8vgUCA1atXY+XKlUhMTETt2rVx7tw5AAUtfKtWrULnzp0xe/ZsAICVlRW0tbXRtWtXLF++HMbGxgDyujAByCS2fFLaRKi6CAwMxMSJE/HhwwcAed+wnp6eaN++Pb+BEVLNNWvWDIcPHwZjjGsVunLlCnR0dFC/fn2Z+k2bNkVubi7CwsK4rrHo6Gjuv92irFmzBitWrEBwcPBXr/nl6emJhg0bwsPDA23atIGNjQ2aNm2KjRs3SrWkAHmtGWfPnsWqVasAAH369IGBgQHWrFmDo0ePytz7w4cPclu2WrVqBYlEgosXL8rtyqtduzY+ffqEtLQ0LpEortsnn4aGBgYPHgx/f388fvwYTZo0QZs2bbjzbdq0QXR0tEJJbOvWrbF9+3apf9OrV6/C1NQUCxYs4Oo9ffq02Hu1adMGiYmJUFVVLbQL6MqVK3B3d8egQYMA5CVPT548KfK+pe0a69SpEzeOKt+ZM2dKlOAKhULUq1cPALBv3z506tSJS2jS09OhqqoqUx+QblG8d+8e1NTU0KJFi2KfV2HKdOh1FZA/6nxIFZ819vHjRzZ69GhuNhgAZmJiwkJCQvgOjRAZ1XHW2IsXL5iWlhb76aefWFRUFDt27BgzMDBgixcv5up8OWvM0dGRtW7dml27do3dunWLdenShWlqahY5a+y3335j6urq7NChQywhIYH7+vTpU6HXyJuNxRhj33//Pevfvz93fOXKFaalpcWcnZ3Z9evX2dOnT1lgYCAzMTFhdnZ2LDMzk6t77NgxpqamxpycnNiZM2dYfHw8u3nzJps9ezZzcXEpNBZ3d3dmYmLCjh49yuLi4tiFCxfYgQMHGGOMvX37lmlra7Np06axx48fM39/f1a3bl25s8bkOXPmDBOJRKxJkyZs2bJlUudOnz7NVFVV2ZIlS9i9e/fYgwcP2L59+9iCBQsKjTU5OZmpqamxyMhIruzvv/9mqqqqbN++fezx48ds8+bNrFatWlKfr7wYJRIJ69KlC7O2tmbBwcEsPj6eXblyhc2fP5/dvHmTMcbYoEGDmI2NDbt9+zaLiIhgTk5OTEdHR+p7pqzFxcUxLS0tNnv2bBYVFcW2bdvGhEIhO336NFfn999/Zz169OCOk5KS2Pbt21lUVBS7ffs2mzZtGtPQ0GDXr1/n6uzevZupqqoyLy8vFhsbyy5fvszatm3L2rdvL/X8xYsXS937S3zMGlPaRKgqT5+/evUqs7CwkEqCXFxc2Lt37/gOjRC5qmMixJji0+cTEhJY//79mUgkYg0aNGB+fn7FTp83NTWV+m89/+vzhOtLhSVCoaGhDIDUL7C7d++yIUOGsFq1ajE1NTXWsGFDtnDhQpaWliZz/c2bN9ngwYNZ7dq1mUgkYpaWluzHH39kjx49KjSWjIwM5uHhwYyNjZm6ujqztLRkf/31F3f+6NGjzNLSkmlqarIBAwawnTt3ljgREovFzNjYmAFgsbGxMudPnz7N7OzsmKamJtPV1WXt27dnO3fuLDRWxvKSRU9PT6my2bNns2+++YbVqFGDubi4sI0bNxabCDHGWEpKCps6dSqrW7cuU1NTYyYmJszNzY09e/aMMcZYfHw8s7e3Z5qamszExIRt3bpV5numPFy4cIHZ2NgwdXV1ZmFhwXbv3i11fvHixczU1JQ7TkpKYh07dmTa2tpMS0uL9ezZk127dk3mvlu2bGHNmzdnmpqazNjYmLm5ubEXL15I1WnSpAnbt29fobHxkQgJGPvKUXBVVEpKCvT09DBkvTUOzYjgOxyFhYSEoFevXhCLxQDyBkRu27YNI0aMoMURSaWVmZmJ+Ph4mJubFzvIlxA+3b17F71790ZsbKzUbEFSeqdOncLMmTNx9+5dmW60fEX9rMj//f3x48cy3SScVpauYjp37szNOrGzs8OdO3cwcuRISoIIIaQMWFlZYfXq1YiPj+c7lGonLS0Nu3fvLjQJ4kvlioYUS01NDf7+/jhw4ADmzp1b6b6hCCGkqnN3d+c7hGpp6NChfIcgF7UIVWLv37+Hm5sbwsLCpMotLS2xYMECSoIIIYSQUqLfpJVUSEgIRo4ciRcvXiAsLAzh4eFyFwAjhBBCyNejFqFKJjs7G56enujRowdevHgBIG+foPv37/McGSGEEFL9UItQJRIdHQ1XV1eEh4dzZfb29vDz85O7QBshhBBCSkdpW4Qq0xwrxhi8vb3RunVrLglSU1PDmjVrcPbsWUqCCCGEkHKitC1CrJKkQklJSRg/fjyCgoK4siZNmiAgIEBquXhCCCGElD2lbRGqLJ4/fy6178vkyZMRHh5OSRAhhBBSASgR4lmbNm2wfPlyGBgYICgoCF5eXjQ7jJBqonv37pg+fXqRdczMzLBp06YKiYcULzs7G5aWlrh69SrfoVQ7np6emDp1Kt9hyFDaRIivjrGHDx8iJydHqmzWrFm4f/8+nJyceIqKECKPu7s7BAKBzNfjx48rLIYjR46gbdu2qFmzJrS1tWFjY4M9e/YUeY2Pjw8Xq4qKCoyNjeHi4oJnz57J1L1//z6+//571K5dGyKRCI0bN8aiRYuQnp4uU/f27dsYNmwYDA0NoaGhgUaNGmHChAmIiYkps/fLtx07dsDc3Bx2dnZ8h1JuQkJC0KZNG4hEIlhaWsLHx6fYawIDA2FjYwMtLS2Ymppi7dq1MnX8/f1hbW0NLS0tGBsbY+zYsXj79i13ftasWfD19UVcXFxZvp1SU9pEqKJJJBJs3rwZNjY2WL58udQ5oVCIOnXq8BQZIaQojo6OSEhIkPoyNzevsOfXqlULCxYsQGhoKO7evYsxY8ZgzJgxCA4OLvI6XV1dJCQk4OXLlzh8+DCio6MxbNgwqTrXrl1Dhw4dkJ2djRMnTiAmJgYrVqyAj48PevfujezsbK7u8ePH0bFjR2RlZcHf3x9RUVHYu3cv9PT08Msvv5TLe5fn85jKGmMMW7duxbhx40p1n/KMsbTi4+PRv39/2NvbIyIiAtOnT8f48eOL/H46deoU3NzcMGnSJNy7dw9eXl7YuHEjtm7dytW5cuUKRo0ahXHjxuH+/fs4ePAgbty4gQkTJnB1DAwM4ODggO3bt5fre1RYmW7hWgXk7147dL1NhT3z1atXzMHBgds1WkVFRWr3Z0KqO9p9Ps/r16/ZgAEDmIaGBjMzM2N79+4tdvd5eVq3bs0WLlxY6Hl5u89v2bJFauduiUTCmjdvztq2bcvEYrFU3YiICCYQCNhvv/3GGGMsLS2NGRgYMGdnZ7nPe//+faGxZGZmsjlz5rD69eszdXV11rBhQ/bHH38UGufRo0fl7j6/a9cuZmZmxgQCAfP29mbGxsYycQ8cOJCNGTOGOz527Bhr3bo1E4lEzNzcnC1ZskTq3+dLN2/eZCoqKiwlJUWqfM6cOaxRo0ZMU1OTmZubs4ULF7Ls7OwiY8z/XMaNG8cMDAyYjo4Os7e3ZxEREdx1jx8/ZgMHDmR16tRh2trarG3btuzMmTOFxlcW5syZw1q0aCFV5uLiwhwcHAq95ocffmBDhw6VKtuyZQurX78+k0gkjDHG1q5dyywsLGTq1KtXT6rM19eX1a9fv9Bn8bH7vNLOGqsof//9N8aPH4/k5GSubNq0abCysuIxKkL453LcBckZycVXLGMGmgY4MOBAqe/z8uVL9OvXD+7u7vDz88PDhw8xYcIEaGhoYMmSJXKvcXd3x6tXr3DhwgWoqalh2rRpePPmTYmfyRjD+fPnER0djdWrV5f4ujdv3uDo0aMQCoUQCoUAgIiICDx48AABAQFQUZHuHLC2tkavXr2wb98+zJ07F8HBwUhOTsacOXPk3r9mzZqFPnvUqFEIDQ3Fli1bYG1tjfj4eKmfhyXx+PFjHD58GEeOHIFQKISJiQmmTp2KCxcuoGfPngCAd+/e4fTp09zkk0uXLmHUqFHYsmULunbtitjYWPz4448AgMWLF8t9zqVLl9C4cWPo6OhIlevo6MDHxwd169ZFZGQkJkyYAB0dHanP48sYAWDYsGHQ1NTEqVOnoKenB29vb/Ts2RMxMTGoVasWUlNT0a9fP6xYsQIikQh+fn5wcnJCdHQ0GjRoUGiMffv2LfLz8vb2hpubm9xzoaGh6NWrl1SZg4NDkWPZsrKyZMauampq4sWLF3j69CnMzMzQqVMnzJ8/HydPnkTfvn3x5s0bHDp0CP369ZO6rn379njx4gWePHkCMzOzIt9HRaFEqJykpaVh5syZ8Pb25sqMjIzg6+uLPn368BgZIZVDckYy3qSXPAngy/Hjx1GjRg3uuG/fvjh48CC8vLxgYmKCrVu3QiAQoGnTpnj16hXmzp2LRYsWySQXMTExOHXqFG7cuIF27doBAP788080a9as2Bg+fvyIevXqISsrC0KhEF5eXujdu3ex19SoUQOMMW68z7Rp06Ctrc3FA6DQ5zdr1gyXL18GADx69AgA0LRp02Jj/VxMTAwCAwNx5swZ7pevhYWFQvcA8rqa/Pz8ULt2ba6sb9++CAgI4BKhQ4cOwcDAAPb29gCApUuXwtPTE6NHj+aeu2zZMsyZM6fQROjp06eoW7euTPnChQu512ZmZpg1axb2798vlQh9GePly5dx48YNvHnzBiKRCACwbt06HDt2DIcOHcKPP/4Ia2trWFtbc/dYtmwZjh49iqCgIEyZMkVujG3btkVERESRn5ehoWGh5xITE2XOGxoaIiUlBRkZGdDU1JS5xsHBAR4eHnB3d4e9vT0eP36M9evXAwASEhJgZmaGzp07w9/fHy4uLsjMzERubi6cnJywbds2qXvlf775CVRlQIlQOQgLC4Orq6vUAMLvvvsOf/zxBwwMDHiMjJDKw0CTn/8WFH2uvb291JiG/EQiKioKnTp1gkBQMPWic+fOSE1NxYsXL2T+oo+KioKqqipsbW25sqZNmxbZmpJPR0cHERERSE1Nxblz5zBjxgxYWFige/fuRV4THh6OnJwcnDp1Cv7+/lixYoVMPcZYsc8vSR15IiIiIBQK0a1bt6+6Pp+pqalUEgQAbm5umDBhAry8vCASieDv74/hw4dzCeidO3dw5coVqfcsFouRmZmJ9PR0ubNzMzIyoKGhIVN+4MABbNmyBbGxsUhNTUVubi50dXWLjPHOnTtITU3FN998I/OM2NhYAEBqaiqWLFmCEydOICEhAbm5ucjIyJA7qD2fpqYmLC0tCz1fHiZMmIDY2FgMGDAAOTk50NXVxc8//4wlS5Zwn/eDBw/w888/Y9GiRXBwcEBCQgJmz56NSZMm4c8//5SKH4Dcwfh8oUSojJ0/fx4ODg7Izc0FAGhpaWHTpk0YP3681A9MQpRdWXRPVQRtbe0K/8XzJRUVFS4GGxsbREVFYdWqVUUmQp9f06xZM8TGxmLy5MncjLPGjRsDyEvQWrduLXN9VFQUVyf//x8+fIhOnTqVOG55rQtfxvhlkvXlrFqgIPn8nJOTExhjOHHiBNq1a4dLly5h48aN3PnU1FQsXboUgwcPlrlWXrID5A3mjYyMlCoLDQ2Fm5sbli5dCgcHB+jp6WH//v1ci0hhMaampsLY2BghISEyz8lPfmfNmoUzZ85g3bp1sLS0hKamJoYOHVrkYOvSdo0ZGRnh9evXUmWvX7+Grq5uof9eAoEAq1evxsqVK5GYmIjatWvj3LlzAApa+FatWoXOnTtj9uzZAAArKytoa2uja9euWL58OYyNjQHkdWECkEls+aS0iZDg6/7AKVbnzp3RvHlz3L17F7a2tggICOB+iBBCqo9mzZrh8OHDYIxxf+RcuXIFOjo6crfFadq0KXJzcxEWFsZ1jUVHR+PDhw8KP1sikSArK0uhazw9PdGwYUN4eHigTZs2sLGxQdOmTbFx40aplhQgrzXj7NmzWLVqFQCgT58+MDAwwJo1a3D06FGZe3/48EFuy1arVq0gkUhw8eJFmXEpQN4vw0+fPiEtLY1LJIrr9smnoaGBwYMHw9/fH48fP0aTJk2kFqJt06YNoqOjFUpiW7duje3bt0v9m169ehWmpqZYsGABV+/p06fF3qtNmzZITEyEqqpqoV1AV65cgbu7OwYNGgQgL3l68uRJkfctbddYp06dpBbxBYAzZ86UKMEVCoWoV68eAGDfvn3o1KkTl9Ckp6dDVVVVpj4g3aJ47949qKmpoUWLFsU+r8KU6dDrKiB/1PmwdeU3a+zevXtswYIFLCsrq9yeQUhVUh1njb148YJpaWmxn376iUVFRbFjx44xAwMDtnjxYq7Ol7PGHB0dWevWrdm1a9fYrVu3WJcuXZimpmaRs8ZWrlzJ/v33XxYbG8sePHjA1q1bx1RVVdmuXbsKvUbebCzGGPv+++9Z//79ueMrV64wLS0t5uzszK5fv86ePn3KAgMDmYmJCbOzs2OZmZlc3WPHjjE1NTXm5OTEzpw5w+Lj49nNmzfZ7NmzmYuLS6GxuLu7MxMTE3b06FEWFxfHLly4wA4cOMAYY+zt27dMW1ubTZs2jT1+/Jj5+/uzunXryp01Js+ZM2eYSCRiTZo0YcuWLZM6d/r0aaaqqsqWLFnC7t27xx48eMD27dvHFixYUGisycnJTE1NjUVGRnJlf//9N1NVVWX79u1jjx8/Zps3b2a1atWS+nzlxSiRSFiXLl2YtbU1Cw4OZvHx8ezKlSts/vz57ObNm4wxxgYNGsRsbGzY7du3WUREBHNycmI6OjpS3zNlLS4ujmlpabHZs2ezqKgotm3bNiYUCtnp06e5Or///jvr0aMHd5yUlMS2b9/OoqKi2O3bt9m0adOYhoaG1Ozn3bt3M1VVVebl5cViY2PZ5cuXWdu2bVn79u2lnr948WKpe3+Jj1ljlAiV8l7jx49n9+7dK4PICKm+qmMixJji0+cTEhJY//79mUgkYg0aNGB+fn7FTp9fsGABs7S0ZBoaGkxfX5916tSJ7d+/v8i4C0uEQkNDGQCpX2B3795lQ4YMYbVq1WJqamqsYcOGbOHChSwtLU3m+ps3b7LBgwez2rVrM5FIxCwtLdmPP/7IHj16VGgsGRkZzMPDgxkbGzN1dXVmaWnJ/vrrL+780aNHmaWlJdPU1GQDBgxgO3fuLHEiJBaLmbGxMQPAYmNjZc6fPn2a2dnZMU1NTaarq8vat2/Pdu7cWWisjOUli56enlJls2fPZt988w2rUaMGc3FxYRs3biw2EWKMsZSUFDZ16lRWt25dpqamxkxMTJibmxt79uwZY4yx+Ph4Zm9vzzQ1NZmJiQnbunWrzPdMebhw4QKzsbFh6urqzMLCgu3evVvq/OLFi5mpqSl3nJSUxDp27Mi0tbWZlpYW69mzJ7t27ZrMfbds2cKa/397dx4UxZ3FAfzLIDMMyBGXRQbFAw8SjciiYsBYrAYD0RhMopBIFBSPFVAjOWQVBeIqmigbdY0GE0ENK0jKgwoIK0R2Adn1AskKYoAhxAqgRgOKnDNv/0jR68ihgzhDZt6naqrsX/9+3a/nycyr7t90jxlDUqmUZDIZ+fn50fXr11X6ODg40JEjR7qMTRuFkAFRD2fB/UbV19fDwsIC87Y74eh7BT3eTn5+Pt555x1UVFTA0dER586dE34ZwBhT1dTUBLlcjuHDh3c5P4OxvqCoqAgzZsxAeXm5yq8F2ZM7deoU3nvvPRQVFXW4jNauu8+K9u/vurq6DpPVn4Qe31m6ZxOX29raEBUVhalTpwq3CZfL5SgqKurN4BhjjGmBo6Mjtm3bBrlcru1QdE5DQwPi4uK6LIK0pW9F08dVVFTgnXfeQX5+vtDm5uaGr776SqO33GeMMfb0BAQEaDsEnTR37lxth9ApPT4j9PiICIcOHYKTk5NQBBkaGiIqKgr//Oc/uQhijDHGfqP09ozQ414Yu3PnDlasWIGkpP/f88Te3h4JCQl44YUXnk5wjDHGGNMIPiP0CCUlJUhOThaWAwICUFhYyEUQYz2gZ7/NYIypSRufEXpbCD3uW+3m5ob169fD0tISR48eRVxcXIcH8jHGutd+Y7Xu7pjLGGPtnxHtnxmaoLeXxroil8sxZMgQlSRs2LABy5cvF+6oyRhTT79+/WBiYoKbN2/CyMiowwNJGWNMqVTi5s2bMDEx0egvy/S2EHp4jhARITY2FmvWrEFERATWrl0rrDMyMuIiiLEnYGBgAJlMBrlc/liPJ2CM6SeRSIQhQ4Zo9NmcelsIPejmzZtYsmQJUlJSAADh4eF4+eWXO30QIWOsZ8RiMUaNGsWXxxhjXRKLxRo/Y9wnCqE9e/bgk08+QU1NDcaPH4/du3fDxcWly/7JycnYsGEDKisrMWrUKGzbtg0zZ87s0b4zMjIQEBCAmpoaoW3JkiVwcHDo0fYYY10TiUR8Z2nGWJ+i9Qv1SUlJCA0NRUREBC5duoTx48fD09MTN27c6LT/2bNn8fbbbyMwMBAFBQWYM2cO5syZg//+979q7VfRpsS7774LLy8voQiysrJCSkoK9u7dCxMTkyc+NsYYY4z1bVp/1tjkyZMxadIk/O1vfwPw62QpOzs7rFy5EmFhYR36+/r6oqGhAd98843Q9sILL8DJyQn79u175P7an1VibmOM+pomod3LywtxcXGwsbHphaNijDHGWG/SyWeNtbS04OLFi/Dw8BDaRCIRPDw8VB5j8aD8/HyV/gDg6enZZf+utBdBEokEu3btQlpaGhdBjDHGmJ7R6hyhW7duQaFQYODAgSrtAwcOxNWrVzsdU1NT02n/B+f4PKi5uRnNzc3Ccl1dnfDvMWPG4Msvv8SYMWNw9+7dnh4GY4wxxp6y+vp6AL1/08U+MVn6aYqOjkZUVFSn64qLi+Hq6qrhiBhjjDHWUz///DMsLCx6bXtaLYSsrKxgaGiI2tpalfba2touL1PZ2Nio1f/Pf/4zQkNDheVffvkFQ4cORVVVVa++kUx99fX1sLOzw48//tir13tZz3A++g7ORd/Bueg76urqMGTIEAwYMKBXt6vVQkgsFmPChAnIysrCnDlzAPw6WTorKwshISGdjnF1dUVWVhbeffddoe306dNdntmRSCSQSCQd2i0sLPg/dR9hbm7OuehDOB99B+ei7+Bc9B29fZ8hrV8aCw0Nhb+/PyZOnAgXFxd8+umnaGhowKJFiwAACxcuxKBBgxAdHQ0AWL16Ndzd3bFjxw7MmjULiYmJuHDhAmJjY7V5GIwxxhj7DdJ6IeTr64ubN29i48aNqKmpgZOTE9LT04UJ0VVVVSrVn5ubG/7+978jPDwc69atw6hRo3DixAk8//zz2joExhhjjP1Gab0QAoCQkJAuL4VlZ2d3aJs3bx7mzZvXo31JJBJERER0ermMaRbnom/hfPQdnIu+g3PRdzytXGj9hoqMMcYYY9qi9UdsMMYYY4xpCxdCjDHGGNNbXAgxxhhjTG9xIcQYY4wxvaWThdCePXswbNgwGBsbY/LkyTh37ly3/ZOTk/Hss8/C2NgY48aNQ1pamoYi1X3q5GL//v2YOnUqnnnmGTzzzDPw8PB4ZO6YetT922iXmJgIAwMD4can7Mmpm4tffvkFwcHBkMlkkEgkGD16NH9W9RJ1c/Hpp5/CwcEBUqkUdnZ2WLNmDZqamjQUre7617/+hdmzZ8PW1hYGBgY4ceLEI8dkZ2fD2dkZEokEI0eORHx8vPo7Jh2TmJhIYrGYDhw4QFeuXKGlS5eSpaUl1dbWdto/Ly+PDA0N6eOPP6bi4mIKDw8nIyMj+u677zQcue5RNxfz58+nPXv2UEFBAZWUlFBAQABZWFjQ9evXNRy5blI3H+3kcjkNGjSIpk6dSt7e3poJVsepm4vm5maaOHEizZw5k3Jzc0kul1N2djYVFhZqOHLdo24uEhISSCKRUEJCAsnlcsrIyCCZTEZr1qzRcOS6Jy0tjdavX0/Hjh0jAHT8+PFu+1dUVJCJiQmFhoZScXEx7d69mwwNDSk9PV2t/epcIeTi4kLBwcHCskKhIFtbW4qOju60v4+PD82aNUulbfLkybR8+fKnGqc+UDcXD2trayMzMzM6ePDg0wpRr/QkH21tbeTm5kZffPEF+fv7cyHUS9TNxd69e8ne3p5aWlo0FaLeUDcXwcHBNH36dJW20NBQmjJlylONU988TiH04Ycf0tixY1XafH19ydPTU6196dSlsZaWFly8eBEeHh5Cm0gkgoeHB/Lz8zsdk5+fr9IfADw9Pbvszx5PT3LxsPv376O1tbXXH7Cnj3qaj48++gjW1tYIDAzURJh6oSe5SElJgaurK4KDgzFw4EA8//zz2LJlCxQKhabC1kk9yYWbmxsuXrwoXD6rqKhAWloaZs6cqZGY2f/11vd3n7izdG+5desWFAqF8HiOdgMHDsTVq1c7HVNTU9Np/5qamqcWpz7oSS4etnbtWtja2nb4j87U15N85Obm4ssvv0RhYaEGItQfPclFRUUFvv32W/j5+SEtLQ1lZWUICgpCa2srIiIiNBG2TupJLubPn49bt27hxRdfBBGhra0Nf/rTn7Bu3TpNhMwe0NX3d319PRobGyGVSh9rOzp1Rojpjq1btyIxMRHHjx+HsbGxtsPRO3fv3sWCBQuwf/9+WFlZaTscvadUKmFtbY3Y2FhMmDABvr6+WL9+Pfbt26ft0PROdnY2tmzZgs8++wyXLl3CsWPHkJqaik2bNmk7NNZDOnVGyMrKCoaGhqitrVVpr62thY2NTadjbGxs1OrPHk9PctFu+/bt2Lp1KzIzM+Ho6Pg0w9Qb6uajvLwclZWVmD17ttCmVCoBAP369UNpaSlGjBjxdIPWUT3525DJZDAyMoKhoaHQ9txzz6GmpgYtLS0Qi8VPNWZd1ZNcbNiwAQsWLMCSJUsAAOPGjUNDQwOWLVuG9evXqzwknD1dXX1/m5ubP/bZIEDHzgiJxWJMmDABWVlZQptSqURWVhZcXV07HePq6qrSHwBOnz7dZX/2eHqSCwD4+OOPsWnTJqSnp2PixImaCFUvqJuPZ599Ft999x0KCwuF12uvvYZp06ahsLAQdnZ2mgxfp/Tkb2PKlCkoKysTilEAuHbtGmQyGRdBT6Anubh//36HYqe9QCV+dKdG9dr3t3rzuPu+xMREkkgkFB8fT8XFxbRs2TKytLSkmpoaIiJasGABhYWFCf3z8vKoX79+tH37diopKaGIiAj++XwvUTcXW7duJbFYTF9//TVVV1cLr7t372rrEHSKuvl4GP9qrPeom4uqqioyMzOjkJAQKi0tpW+++Yasra3pL3/5i7YOQWeom4uIiAgyMzOjI0eOUEVFBf3jH/+gESNGkI+Pj7YOQWfcvXuXCgoKqKCggABQTEwMFRQU0A8//EBERGFhYbRgwQKhf/vP5z/44AMqKSmhPXv28M/n2+3evZuGDBlCYrGYXFxc6N///rewzt3dnfz9/VX6Hz16lEaPHk1isZjGjh1LqampGo5Yd6mTi6FDhxKADq+IiAjNB66j1P3beBAXQr1L3VycPXuWJk+eTBKJhOzt7Wnz5s3U1tam4ah1kzq5aG1tpcjISBoxYgQZGxuTnZ0dBQUF0Z07dzQfuI45c+ZMp98B7e+/v78/ubu7dxjj5OREYrGY7O3tKS4uTu39GhDxuTzGGGOM6SedmiPEGGOMMaYOLoQYY4wxpre4EGKMMcaY3uJCiDHGGGN6iwshxhhjjOktLoQYY4wxpre4EGKMMcaY3uJCiDGmIj4+HpaWltoOo8cMDAxw4sSJbvsEBARgzpw5GomHMda3cSHEmA4KCAiAgYFBh1dZWZm2Q0N8fLwQj0gkwuDBg7Fo0SLcuHGjV7ZfXV2NV155BQBQWVkJAwMDFBYWqvTZuXMn4uPje2V/XYmMjBSO09DQEHZ2dli2bBlu376t1na4aGPs6dKpp88zxv7Py8sLcXFxKm2///3vtRSNKnNzc5SWlkKpVOLy5ctYtGgRfvrpJ2RkZDzxtrt6aviDLCwsnng/j2Ps2LHIzMyEQqFASUkJFi9ejLq6OiQlJWlk/4yxR+MzQozpKIlEAhsbG5WXoaEhYmJiMG7cOJiamsLOzg5BQUG4d+9el9u5fPkypk2bBjMzM5ibm2PChAm4cOGCsD43NxdTp06FVCqFnZ0dVq1ahYaGhm5jMzAwgI2NDWxtbfHKK69g1apVyMzMRGNjI5RKJT766CMMHjwYEokETk5OSE9PF8a2tLQgJCQEMpkMxsbGGDp0KKKjo1W23X5pbPjw4QCAP/zhDzAwMMAf//hHAKpnWWJjY2Fra6vyZHcA8Pb2xuLFi4XlkydPwtnZGcbGxrC3t0dUVBTa2tq6Pc5+/frBxsYGgwYNgoeHB+bNm4fTp08L6xUKBQIDAzF8+HBIpVI4ODhg586dwvrIyEgcPHgQJ0+eFM4uZWdnAwB+/PFH+Pj4wNLSEgMGDIC3tzcqKyu7jYcx1hEXQozpGZFIhF27duHKlSs4ePAgvv32W3z44Ydd9vfz88PgwYNx/vx5XLx4EWFhYTAyMgIAlJeXw8vLC2+++SaKioqQlJSE3NxchISEqBWTVCqFUqlEW1sbdu7ciR07dmD79u0oKiqCp6cnXnvtNXz//fcAgF27diElJQVHjx5FaWkpEhISMGzYsE63e+7cOQBAZmYmqqurcezYsQ595s2bh59//hlnzpwR2m7fvo309HT4+fkBAHJycrBw4UKsXr0axcXF+PzzzxEfH4/Nmzc/9jFWVlYiIyMDYrFYaFMqlRg8eDCSk5NRXFyMjRs3Yt26dTh69CgA4P3334ePjw+8vLxQXV2N6upquLm5obW1FZ6enjAzM0NOTg7y8vLQv39/eHl5oaWl5bFjYowBOvn0ecb0nb+/PxkaGpKpqanwmjt3bqd9k5OT6Xe/+52wHBcXRxYWFsKymZkZxcfHdzo2MDCQli1bptKWk5NDIpGIGhsbOx3z8PavXbtGo0ePpokTJxIRka2tLW3evFllzKRJkygoKIiIiFauXEnTp08npVLZ6fYB0PHjx4mISC6XEwAqKChQ6ePv70/e3t7Csre3Ny1evFhY/vzzz8nW1pYUCgUREb300ku0ZcsWlW0cPnyYZDJZpzEQEUVERJBIJCJTU1MyNjYWnqQdExPT5RgiouDgYHrzzTe7jLV93w4ODirvQXNzM0mlUsrIyOh2+4wxVTxHiDEdNW3aNOzdu1dYNjU1BfDr2ZHo6GhcvXoV9fX1aGtrQ1NTE+7fvw8TE5MO2wkNDcWSJUtw+PBh4fLOiBEjAPx62ayoqAgJCQlCfyKCUqmEXC7Hc88912lsdXV16N+/P5RKJZqamvDiiy/iiy++QH19PX766SdMmTJFpf+UKVNw+fJlAL9e1poxYwYcHBzg5eWFV199FS+//PITvVd+fn5YunQpPvvsM0gkEiQkJOCtt96CSCQSjjMvL0/lDJBCoej2fQMABwcHpKSkoKmpCV999RUKCwuxcuVKlT579uzBgQMHUFVVhcbGRrS0tMDJyanbeC9fvoyysjKYmZmptDc1NaG8vLwH7wBj+osLIcZ0lKmpKUaOHKnSVllZiVdffRUrVqzA5s2bMWDAAOTm5iIwMBAtLS2dfqFHRkZi/vz5SE1NxalTpxAREYHExES8/vrruHfvHpYvX45Vq1Z1GDdkyJAuYzMzM8OlS5cgEokgk8kglUoBAPX19Y88LmdnZ8jlcpw6dQqZmZnw8fGBh4cHvv7660eO7crs2bNBREhNTcWkSZOQk5ODv/71r8L6e/fuISoqCm+88UaHscbGxl1uVywWCznYunUrZs2ahaioKGzatAkAkJiYiPfffx87duyAq6srzMzM8Mknn+A///lPt/Heu3cPEyZMUClA2/WVCfGM/VZwIcSYHrl48SKUSiV27NghnO1on4/SndGjR2P06NFYs2YN3n77bcTFxeH111+Hs7MziouLOxRcjyISiTodY25uDltbW+Tl5cHd3V1oz8vLg4uLi0o/X19f+Pr6Yu7cufDy8sLt27cxYMAAle21z8dRKBTdxmNsbIw33ngDCQkJKCsrg4ODA5ydnYX1zs7OKC0tVfs4HxYeHo7p06djxYoVwnG6ubkhKChI6PPwGR2xWNwhfmdnZyQlJcHa2hrm5uZPFBNj+o4nSzOmR0aOHInW1lbs3r0bFRUVOHz4MPbt29dl/8bGRoSEhCA7Oxs//PAD8vLycP78eeGS19q1a3H27FmEhISgsLAQ33//PU6ePKn2ZOkHffDBB9i2bRuSkpJQWlqKsLAwFBYWYvXq1QCAmJgYHDlyBFevXsW1a9eQnJwMGxubTm8CaW1tDalUivT0dNTW1qKurq7L/fr5+SE1NRUHDhwQJkm327hxIw4dOoSoqChcuXIFJSUlSExMRHh4uFrH5urqCkdHR2zZsgUAMGrUKFy4cAEZGRm4du0aNmzYgPPnz6uMGTZsGIqKilBaWopbt26htbUVfn5+sLKygre3N3JyciCXy5GdnY1Vq1bh+vXrasXEmN7T9iQlxljv62yCbbuYmBiSyWQklUrJ09OTDh06RADozp07RKQ6mbm5uZneeustsrOzI7FYTLa2thQSEqIyEfrcuXM0Y8YM6t+/P5mampKjo2OHyc4Peniy9MMUCgVFRkbSoEGDyMjIiMaPH0+nTp0S1sfGxpKTkxOZmpqSubk5vfTSS3Tp0iVhPR6YLE1EtH//frKzsyORSETu7u5dvj8KhYJkMhkBoPLy8g5xpaenk5ubG0mlUjI3NycXFxeKjY3t8jgiIiJo/PjxHdqPHDlCEomEqqqqqKmpiQICAsjCwoIsLS1pxYoVFBYWpjLuxo0bwvsLgM6cOUNERNXV1bRw4UKysrIiiURC9vb2tHTpUqqrq+syJsZYRwZERNotxRhjjDHGtIMvjTHGGGNMb3EhxBhjjDG9xYUQY4wxxvQWF0KMMcYY01tcCDHGGGNMb3EhxBhjjDG9xYUQY4wxxvQWF0KMMcYY01tcCDHGGGNMb3EhxBhjjDG9xYUQY4wxxvQWF0KMMcYY01v/A4BJeEdGGcO0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "val_scores_lstm = []\n",
    "inputs = Input(shape=(200,))\n",
    "layer = Embedding(input_dim=max_words, output_dim=128, input_length=200)(inputs)\n",
    "layer = Bidirectional(LSTM(32, return_sequences=True, recurrent_dropout=0.28))(layer)\n",
    "layer = GlobalMaxPool1D()(layer)\n",
    "layer = Dropout(0.30)(layer)\n",
    "layer = Dense(32, activation='relu')(layer)\n",
    "layer = Dropout(0.30)(layer)\n",
    "layer = Dense(6, activation='sigmoid')(layer)\n",
    "model = Model(inputs=inputs, outputs=layer)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lstm_val_scores_f1 = []\n",
    "lstm_val_scores_precision = []\n",
    "lstm_val_scores_recall = []\n",
    "lstm_val_scores_accuracy = []\n",
    "lstm_roc_auc = []\n",
    "lstm_fpr = []\n",
    "lstm_tpr = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    print(train_index)\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # Adjust the input data to match max_len\n",
    "    X_train_fold = pad_sequences_custom(X_train_fold, 200)\n",
    "    X_val_fold = pad_sequences_custom(X_val_fold, 200)\n",
    "\n",
    "    checkpoint = ModelCheckpoint('save_best_model_lstm.keras', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=1)\n",
    "\n",
    "    history_lstm = model.fit(X_train_fold, y_train_fold, batch_size=128, epochs=5, validation_split=0.2, callbacks=[checkpoint, early_stop])\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_preds = model.predict(X_val_fold)\n",
    "    val_preds_binary = (val_preds > 0.5).astype(int)\n",
    "    \n",
    "    f1 = f1_score(y_val_fold, val_preds_binary, average='macro')\n",
    "    precision = precision_score(y_val_fold, val_preds_binary, average='macro')\n",
    "    recall = recall_score(y_val_fold, val_preds_binary, average='macro')\n",
    "    accuracy = accuracy_score(y_val_fold, val_preds_binary)\n",
    "\n",
    "    lstm_val_scores_f1.append(f1)\n",
    "    lstm_val_scores_precision.append(precision)\n",
    "    lstm_val_scores_recall.append(recall)\n",
    "    lstm_val_scores_accuracy.append(accuracy)\n",
    "    # Calculate ROC AUC for all classes together\n",
    "    auc = roc_auc_score(y_val_fold, val_preds, average='macro')\n",
    "    fpr, tpr, _ = roc_curve(y_val_fold.ravel(), val_preds.ravel())\n",
    "    lstm_roc_auc.append(auc)\n",
    "    lstm_fpr.append(fpr)\n",
    "    lstm_tpr.append(tpr)\n",
    "\n",
    "\n",
    "# Plot ROC curves for all classes together\n",
    "plt.figure()\n",
    "\n",
    "# Plot each fold's ROC curve\n",
    "for i in range(len(lstm_fpr)):  # Each fold\n",
    "    plt.plot(lstm_fpr[i], lstm_tpr[i], lw=2, label=f'Fold {i+1} ROC curve (area = {lstm_roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for LSTM Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     2     4 ... 12758 12763 12765]\n",
      "Epoch 1/5\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.3706 - loss: 0.3039\n",
      "Epoch 1: val_loss improved from inf to 0.11105, saving model to best_model_cnn.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 153ms/step - accuracy: 0.3727 - loss: 0.3024 - val_accuracy: 0.9948 - val_loss: 0.1110\n",
      "Epoch 2/5\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.6336 - loss: 0.1165\n",
      "Epoch 2: val_loss improved from 0.11105 to 0.09199, saving model to best_model_cnn.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.6340 - loss: 0.1164 - val_accuracy: 0.9948 - val_loss: 0.0920\n",
      "Epoch 3/5\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7723 - loss: 0.0694\n",
      "Epoch 3: val_loss improved from 0.09199 to 0.07232, saving model to best_model_cnn.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - accuracy: 0.7722 - loss: 0.0693 - val_accuracy: 0.9948 - val_loss: 0.0723\n",
      "Epoch 4/5\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7612 - loss: 0.0439\n",
      "Epoch 4: val_loss did not improve from 0.07232\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - accuracy: 0.7614 - loss: 0.0439 - val_accuracy: 0.9906 - val_loss: 0.0816\n",
      "Epoch 5/5\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.6604 - loss: 0.0333\n",
      "Epoch 5: val_loss did not improve from 0.07232\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 172ms/step - accuracy: 0.6612 - loss: 0.0333 - val_accuracy: 0.9948 - val_loss: 0.0736\n",
      "Epoch 5: early stopping\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "[    0     1     2 ... 12762 12763 12764]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  # we assume the user will be removing warnings if zero_division is set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7621 - loss: 0.0524\n",
      "Epoch 1: val_loss improved from inf to 0.03423, saving model to best_model_cnn.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - accuracy: 0.7617 - loss: 0.0524 - val_accuracy: 0.9944 - val_loss: 0.0342\n",
      "Epoch 2/5\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7552 - loss: 0.0310\n",
      "Epoch 2: val_loss improved from 0.03423 to 0.03396, saving model to best_model_cnn.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - accuracy: 0.7550 - loss: 0.0310 - val_accuracy: 0.9944 - val_loss: 0.0340\n",
      "Epoch 3/5\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7460 - loss: 0.0264\n",
      "Epoch 3: val_loss did not improve from 0.03396\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - accuracy: 0.7460 - loss: 0.0264 - val_accuracy: 0.9932 - val_loss: 0.0354\n",
      "Epoch 4/5\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.6760 - loss: 0.0223\n",
      "Epoch 4: val_loss did not improve from 0.03396\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.6755 - loss: 0.0223 - val_accuracy: 0.7490 - val_loss: 0.0343\n",
      "Epoch 4: early stopping\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "[    0     3     8 ... 12762 12764 12765]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  # we assume the user will be removing warnings if zero_division is set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.5466 - loss: 0.0307\n",
      "Epoch 1: val_loss improved from inf to 0.01951, saving model to best_model_cnn.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 160ms/step - accuracy: 0.5463 - loss: 0.0307 - val_accuracy: 0.5208 - val_loss: 0.0195\n",
      "Epoch 2/5\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.5183 - loss: 0.0234\n",
      "Epoch 2: val_loss improved from 0.01951 to 0.01886, saving model to best_model_cnn.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - accuracy: 0.5178 - loss: 0.0234 - val_accuracy: 0.8564 - val_loss: 0.0189\n",
      "Epoch 3/5\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5340 - loss: 0.0198\n",
      "Epoch 3: val_loss did not improve from 0.01886\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 146ms/step - accuracy: 0.5323 - loss: 0.0198 - val_accuracy: 0.4026 - val_loss: 0.0194\n",
      "Epoch 4/5\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.4152 - loss: 0.0168\n",
      "Epoch 4: val_loss did not improve from 0.01886\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - accuracy: 0.4153 - loss: 0.0168 - val_accuracy: 0.5833 - val_loss: 0.0198\n",
      "Epoch 4: early stopping\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  # we assume the user will be removing warnings if zero_division is set\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHHCAYAAABTMjf2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAACZrElEQVR4nOzdeVxN+f8H8NftVrdFJRMVUhHF0CJrGLLVWGOGKJTB4GcZWcve2MYuY2eoKMo6fW2NMfK1hFEipKjsRSEpLbr38/ujb4fbftXtVPf9fDx6TOdzPuec973X1LvPKmCMMRBCCCGEKCAlvgMghBBCCOELJUKEEEIIUViUCBFCCCFEYVEiRAghhBCFRYkQIYQQQhQWJUKEEEIIUViUCBFCCCFEYVEiRAghhBCFRYkQIYQQQhQWJUKEkGpr7dq1aNq0KYRCIaytrfkOh5TC3d0dJiYmX3Vtjx490KNHj0qNh5DyokSIkBL4+vpCIBBwX8rKymjUqBHc3d3x4sWLYq9hjGH//v347rvvULduXWhoaKBNmzb49ddfkZmZWeKzjh8/ju+//x56enpQVVVFw4YNMXz4cPzzzz/lijU7OxsbN25Ex44doaOjAzU1NbRo0QJTp05FXFzcV71+vv3111+YO3cuunTpgn379mHlypVyfZ67uzvq1KlTZr3o6Gj8+OOPMDY2hpqaGho1aoQ+ffrg999/BwAsXbpU6t9NSV8Fv/jd3d0hEAigra2NrKysIs97+PAhd826devKjK+g7vjx44s9v2DBAq5OampqmfcjpLZT5jsAQqq7X3/9FaampsjOzsa1a9fg6+uLy5cv4+7du1BTU+PqicViuLi4IDg4GN26dcPSpUuhoaGBS5cuwdvbG4cPH8bff/8NfX197hrGGH766Sf4+vrCxsYGM2fOhIGBAZKSknD8+HH06tULV65cgZ2dXYnxpaamwtHRERERERgwYABcXFxQp04dxMbG4tChQ9i1axdyc3Pl+h7Jwz///AMlJSX88ccfUFVV5TscAMDVq1dhb2+PJk2aYMKECTAwMMCzZ89w7do1+Pj4YNq0aRg6dCjMzMy4azIyMjB58mQMGTIEQ4cO5cq//HegrKyMjx8/4j//+Q+GDx8u9cyAgACoqakhOzu73HGqqanh6NGj2LZtW5H37uDBgzLfj5BajRFCirVv3z4GgP37779S5fPmzWMAWFBQkFT5ypUrGQA2e/bsIvcKCQlhSkpKzNHRUap87dq1DACbMWMGk0gkRa7z9/dn169fLzXO/v37MyUlJXbkyJEi57Kzs9msWbNKvb68Pn36xHJycirlXuUxduxYpqmpWWn3k0gk7OPHjyWed3NzK/N5/fr1Y/Xr12fv3r0rcu7Vq1fFXpOSksIAsCVLlpT63L59+zInJ6ci55s3b85++OEHBoCtXbu21PgYYwwAc3JyYkpKSuzEiRNS565cucIAcPdLSUkp837l5ebmxoyNjb/q2u7du7Pu3btXWiyEyIK6xgiRUbdu3QAA8fHxXFlWVhbWrl2LFi1aYNWqVUWuGThwINzc3HD27Flcu3aNu2bVqlWwsLDAunXrIBAIilw3evRodOjQocRYrl+/jlOnTmHcuHH44YcfipwXiURS3SkljcUoPL7j8ePHXFfMpk2b0KxZM4hEIty6dQvKysrw9vYuco/Y2FgIBAJs2bKFK0tLS8OMGTNgZGQEkUgEMzMzrF69GhKJpMTXBOR37+zbtw+ZmZlcN46vry8AIC8vD8uWLeNiMjExwfz585GTkyN1DxMTEwwYMAChoaFo164d1NXVsXPnzlKfW5b4+Hh8++23qFu3bpFzDRo0qNC9XVxccObMGaSlpXFl//77Lx4+fAgXFxeZ7tWoUSN89913CAwMlCoPCAhAmzZt0Lp162KvO3z4MGxtbaGurg49PT2MGjWq2G7gEydOoHXr1lBTU0Pr1q1x/PjxYu8nkUiwadMmfPvtt1BTU4O+vj4mTpyId+/eyfR6CJEnSoQIkdHjx48BALq6ulzZ5cuX8e7dO7i4uEBZufge5zFjxgAATp48yV3z9u1buLi4QCgUflUsISEhAPITJnnYt28ffv/9d/z8889Yv349DA0N0b17dwQHBxepGxQUBKFQiGHDhgEAPn78iO7du+PAgQMYM2YMNm/ejC5dusDLywszZ84s9bn79+9Ht27dIBKJsH//fm7cFQCMHz8eixcvRtu2bbFx40Z0794dq1atwogRI4rcJzY2FiNHjkSfPn3g4+NT4QHXxsbGiIiIwN27dyt0n+IMHToUAoEAx44d48oCAwNhYWGBtm3bynw/FxcX/Oc//0FGRgaA/ATy8OHDJSZVvr6+GD58OIRCIVatWoUJEybg2LFj6Nq1q1Ry9tdff+GHH36AQCDAqlWr4OTkhLFjx+LmzZtF7jlx4kTMmTMHXbp0gY+PD8aOHYuAgAA4ODjg06dPMr8mQuSC7yYpQqqrgq6xv//+m6WkpLBnz56xI0eOsPr16zORSMSePXvG1d20aRMDwI4fP17i/d6+fcsAsKFDhzLGGPPx8SnzmrIMGTKEASi2q6Y4JXVBFO7WSExMZACYtrY2e/36tVTdnTt3MgAsOjpaqrxVq1asZ8+e3PGyZcuYpqYmi4uLk6rn6enJhEIhe/r0aamxFtdVFRUVxQCw8ePHS5XPnj2bAWD//PMPV2ZsbMwAsLNnz5b6nNKeV9hff/3FhEIhEwqFrHPnzmzu3LksNDSU5ebmlnhNebvGGGPsxx9/ZL169WKMMSYWi5mBgQHz9vbmPo/ydo1NmTKFvX37lqmqqrL9+/czxhg7deoUEwgE7PHjx2zJkiVSXWO5ubmsQYMGrHXr1iwrK4u718mTJxkAtnjxYq7M2tqaGRoasrS0NKn3BYDUv6FLly4xACwgIEAqvrNnzxYpp64xwidqESKkDL1790b9+vVhZGSEH3/8EZqamggJCUHjxo25Oh8+fAAAaGlplXifgnPp6elS/y3tmrJUxj1K88MPP6B+/fpSZUOHDoWysjKCgoK4srt37+L+/ftwdnbmyg4fPoxu3bpBV1cXqamp3Ffv3r0hFovx3//+V+Z4Tp8+DQBFWpRmzZoFADh16pRUuampKRwcHGR+Tkn69OmD8PBwDBo0CLdv38aaNWvg4OCARo0aca1zFeHi4oKwsDAkJyfjn3/+QXJysszdYgV0dXXh6OiIgwcPAshvXbKzs4OxsXGRujdv3sTr16/xf//3f1ITAPr37w8LCwvufU1KSkJUVBTc3Nygo6PD1evTpw9atWoldc/Dhw9DR0cHffr0kfr8bW1tUadOHVy4cOGrXhchlY0SIULKsHXrVpw7dw5HjhxBv379kJqaCpFIJFWnIBEpSIiKUzhZ0tbWLvOaslTGPUpjampapExPTw+9evWS6h4LCgqCsrKy1Kyohw8f4uzZs6hfv77UV+/evQEAr1+/ljmeJ0+eQElJSWpWFgAYGBigbt26ePLkSZnxV1T79u1x7NgxvHv3Djdu3ICXlxc+fPiAH3/8Effv36/Qvfv16wctLS0EBQUhICAA7du3L/JaZeHi4oJz587h6dOnOHHiRIlJVcH7Zm5uXuSchYUFd77gv82bNy9Sr/C1Dx8+xPv379GgQYMi/wYyMjK+6vMnRB5o+jwhZejQoQPatWsHAHByckLXrl3h4uKC2NhYbt2Zli1bAgDu3LkDJyenYu9z584dAOD+crawsACQvy5NSdeU5ct7FAziLo1AIABjrEi5WCwutr66unqx5SNGjMDYsWMRFRUFa2trBAcHo1evXtDT0+PqSCQS9OnTB3Pnzi32Hi1atCgz3pIUN7C8OCXFXxlUVVXRvn17tG/fHi1atMDYsWNx+PBhLFmy5KvvKRKJMHToUPj5+SEhIQFLly6tUIyDBg2CSCSCm5sbcnJyikzNlyeJRIIGDRogICCg2POFWxoJ4Qu1CBEig4KBpC9fvpSaHdW1a1fUrVsXgYGBJSYV/v7+AIABAwZw1+jq6uLgwYMlXlOWgQMHAgAOHDhQrvq6urpSA18LFG5JKYuTkxNUVVURFBSEqKgoxMXFFRms3KxZM2RkZKB3797FfjVp0kSmZwL5g5UlEgkePnwoVf7q1SukpaUV2+1TFQoS5aSkpArfy8XFBbdu3cKHDx+KHQAuC3V1dTg5OSEsLAx9+vSRSlS/VPC+xcbGFjkXGxvLnS/4b+H3v7hrmzVrhjdv3qBLly7Ffv5WVlYVem2EVBZKhAiRUY8ePdChQwds2rSJW5ROQ0MDs2fPRmxsLBYsWFDkmlOnTsHX1xcODg7o1KkTd828efMQExODefPmFdtSc+DAAdy4caPEWDp37gxHR0fs2bMHJ06cKHI+NzcXs2fP5o6bNWuGBw8eICUlhSu7ffs2rly5Uu7XDwB169aFg4MDgoODcejQIaiqqhZp1Ro+fDjCw8MRGhpa5Pq0tDTk5eXJ9Ewgv+sIADZt2iRVvmHDBgD5Y1rk6cKFC8V+TgVjl4rrWpKVvb09li1bhi1btsDAwKDC95s9ezaWLFmCRYsWlVinXbt2aNCgAXbs2CG1DMGZM2cQExPDva+GhoawtraGn58f3r9/z9U7d+5ckW7B4cOHQywWY9myZUWel5eXV2xCTggfqGuMkK8wZ84cDBs2DL6+vpg0aRIAwNPTE7du3cLq1asRHh6OH374Aerq6rh8+TIOHDiAli1bws/Pr8h97t27h/Xr1+PChQv48ccfYWBggOTkZJw4cQI3btzA1atXS43F398fffv2xdChQzFw4ED06tULmpqaePjwIQ4dOoSkpCRuLaGffvoJGzZsgIODA8aNG4fXr19jx44d+Pbbb7mB1+Xl7OyMUaNGYdu2bXBwcCiyts6cOXMQEhKCAQMGwN3dHba2tsjMzER0dDSOHDmCx48fl9hCURIrKyu4ublh165dSEtLQ/fu3XHjxg34+fnByckJ9vb2Mt2vsE+fPmH58uVFyuvVq4f/+7//w7Rp0/Dx40cMGTIEFhYWyM3NxdWrVxEUFAQTExOMHTu2Qs8HACUlJSxcuLDC9ylgZWVVZuuLiooKVq9ejbFjx6J79+4YOXIkXr16BR8fH5iYmMDDw4Oru2rVKvTv3x9du3bFTz/9hLdv3+L333/Ht99+y03VB4Du3btj4sSJWLVqFaKiotC3b1+oqKjg4cOHOHz4MHx8fPDjjz9W2usk5KvxPGuNkGqrpJWlGcuf2tysWTPWrFkzlpeXJ1W+b98+1qVLF6atrc3U1NTYt99+y7y9vVlGRkaJzzpy5Ajr27cvq1evHlNWVmaGhobM2dmZhYWFlSvWjx8/snXr1rH27duzOnXqMFVVVda8eXM2bdo09ujRI6m6Bw4cYE2bNmWqqqrM2tqahYaGljh9vrTp2unp6UxdXZ0BYAcOHCi2zocPH5iXlxczMzNjqqqqTE9Pj9nZ2bF169aVOuWcsZKns3/69Il5e3szU1NTpqKiwoyMjJiXlxfLzs6WqmdsbMz69+9f6jMKPw9AsV/NmjVjjDF25swZ9tNPPzELCwvufTYzM2PTpk2r8MrSpfma6fOlKTx9vkBQUBCzsbFhIpGI1atXj7m6urLnz58Xuf7o0aOsZcuWTCQSsVatWrFjx46VuLL0rl27mK2tLVNXV2daWlqsTZs2bO7cuezly5dcHZo+T/gkYKyYdl5CCCGEEAVAY4QIIYQQorAoESKEEEKIwqJEiBBCCCEKixIhQgghhCgsSoQIIYQQorAoESKEEEKIwlK4BRUlEglevnwJLS2tcu9XRAghhBB+Mcbw4cMHNGzYEEpKldeOo3CJ0MuXL2FkZMR3GIQQQgj5Cs+ePUPjxo0r7X4KlwhpaWkByH8jtbW1eY6GEEIIIeWRnp4OIyMj7vd4ZVG4RKigO0xbW5sSIUIIIaSGqexhLTRYmhBCCCEKixIhQgghhCgsSoQIIYQQorAoESKEEEKIwqJEiBBCCCEKixIhQgghhCgsSoQIIYQQorAoESKEEEKIwqJEiBBCCCEKixIhQgghhCgsXhOh//73vxg4cCAaNmwIgUCAEydOlHlNWFgY2rZtC5FIBDMzM/j6+so9TkIIIYTUTrwmQpmZmbCyssLWrVvLVT8xMRH9+/eHvb09oqKiMGPGDIwfPx6hoaFyjpQQQgghtRGvm65+//33+P7778tdf8eOHTA1NcX69esBAC1btsTly5exceNGODg4yCtMQgghhNRSNWr3+fDwcPTu3VuqzMHBATNmzKjyWBhjuJ1yG2+y3wAAjj08BpFQVOVxVIm8HOBDMvD+OSBU5TsaQgghCoZJGJLiP8jl3jUqEUpOToa+vr5Umb6+PtLT05GVlQV1dfUi1+Tk5CAnJ4c7Tk9PL/fzMj9lYv3N9ZAwCVf29MNT/Jv871dEXwsIAEg+8h0FIYQQBfIp7RNe7HmBjNgMudy/RiVCX2PVqlXw9vb+qms7BXaq5GgIIYQQUl7pkel4se8FxB/EcntGjUqEDAwM8OrVK6myV69eQVtbu9jWIADw8vLCzJkzueP09HQYGRmV+ayV11eWWUdfQx8aKhoY3GwwAEBXTRedDTtDAABvHwOJF4Cn14FXdwFNPSD1YZn3rFR6LSrvXmlPAcvhgElX4BuzyrsvIaRau/LwDQJuPEHWJ/n9IgKANxm5cr0/+Trf1OFvOERuxgfE7JgPcW7+vz3VOlrIzaj87rEalQh17twZp0+flio7d+4cOnfuXOI1IpEIIpFsY3fupt7FwQcHpcqODTrGfS+AACY6JlBWKubtS3sGbGpdtDwjtewHaxkCgmIm8uXlANlpQOep+ccWAwBVjZLvU8cA0Pym7OcRQmqcU3eSsOFcLDJz5JuYFEhOzwagX2a9ymSgrValzyNFaYqEmNXXHP3aGPIaxx4TbUyYMAFOTk7YsGEDmjZtWunP4DURysjIwKNHj7jjxMREREVFoV69emjSpAm8vLzw4sUL+Pv7AwAmTZqELVu2YO7cufjpp5/wzz//IDg4GKdOnarUuEaeGil1fMP1BtSVi29xknJ+GXBpXcnnVTQBMODTR2CYH6BZP79cSQg0bAso00BkQhRVeROc/MSEH/JOUKrLL1/CD7FYjLy8PKnGi3HjxsHIyAh9+/bFhw+1cLD0zZs3YW9vzx0XdGG5ubnB19cXSUlJePr0KXfe1NQUp06dgoeHB3x8fNC4cWPs2bOnUqfOb4vaJnW8qNOispOg/64D/llW/LmOk4HmfQCTbpToEFIBVd0SUtW+JsGpqpYTSlCIvD179gxjxoxB69at8fvvv3PlAoFA7svjCBhjTK5PqGbS09Oho6OD9+/fQ1tbW+rcx08f0TGwo1RZtFt06TdcqlN8ec9FwHezKxIqIQqlrESHz5aQqlZWgkOJCalNgoODMXHiRKSlpQEATp06hX79+hWpV9rv74qoUWOE5CktOw3dgrpJlZ0Zeqb0i0pKgiZdBgzaVFJkhFQP8m6RkSXRqa1jSCjBIYokPT0d06dPh5+fH1dmZGQELS2tKo2DEqH/KZwEjW09Fo21Gpd8QYRv0TKP+4BOo8oNjBA5kiW5qcoWmZISHUoUCKkdwsPDMWrUKCQkJHBlzs7O2L59O3R1das0FkqEAIS/DJc61lbVxkzbmSXUBpCXC/znF+myuYmARj05REdqM77HvXxtciOvFhlKdAip3fLy8rBixQosW7YMYnH+zz0tLS1s3boVo0aNgkAgqPKYKBECMCtsltTxlZFXSr/g7Dzp4+lRlAQRALInNtVp3Et5khtKVAghX+vNmzcYOHAgwsM/Nz7Y2dnhwIEDMDU15S0uSoQAfPj0eUrelp5byr7g5l7p43r8fYBEvqoyseFr3AslN4SQqlC3bl0oK+enHUKhEIsXL8b8+fO5Mr4ofCJUeNJct8bdSqjJXSB97PW8kiMila0i3U9VkdhQIkIIUQRCoRD79+/H0KFDsXXrVnTqVD22sVL4RCj2XazUsVJxKzsXkEiANSbSZaKqHd1OyufL5Keyup8osSGEkPK7ePEi1NXV0aFDB67M2NgYN2/e5GUsUEkUPhE69+Qc972RVil7kD2/CezpJV1m3l9OUZHyKqm1p6Tk52u6nyixIYSQ8svNzcWSJUuwevVqmJqaIioqSmpKfHVKggBKhLDrzi7u+yFmQ0quWDgJAgDHVXKIiJRHQQIUn5JZZl0DbTVKZgghpArExsbCxcUFkZGRAICEhARs374dc+fO5Tmykil8IvQlRxPH4k9ICo0tEWkDcxMAoYr8gyKcsrq7Crf2UPJDCCFVgzGG3bt3Y8aMGcjKygIAqKioYMWKFZg1a1YZV/NLoROhwgOljbRL6Br7tdDUeK9ncoqIFKes1p9m9TUp4SGEEJ6kpKRgwoQJ+PPPP7kyc3NzBAYGom3btjxGVj4KnQi9zHxZdqXnN6WPW3wvn2AUXGkzu0pq/aEWH0II4VdoaCjc3d2RnJzMlU2aNAnr16+HhoYGj5GVn0InQm+y3nDfN6pTwtYYhccGOe+XY0SK6dSdJEwJjCxXXWr9IYSQ6uHVq1dwcnJCdnb+H6t6enrYu3cvBg4cyHNkslHoRCjy1edfvp0bdi5a4XmE9PFwfxoXVAHlneFV3Mwuav0hhJDqRV9fH7/99htmzJgBBwcH+Pr6wsDAgO+wZKbQiVC2+PMvYGMtY+mT4jxgT0/pMoualeVWF7LM8Nrm2paSHUIIqYYkEgnEYjFUVD43CEybNg2NGzfGkCFDoKRUyjp81ZhCJ0Lvc95z31s1sJI+ectf+tj1KFBDP2S+lJYA0QwvQgipOZKSkuDu7g5ra2usXr2aK1dSUsIPP/zAY2QVp9CJ0MO0h9z3OiId6ZNPrkofN+9dBRHVHiWN+6ExPoQQUrP8+eefGDduHN68eYNz587BwcEBPXv2LPvCGkKhE6HrSde573VUCyVC0Yc/f+96tIoiqnnKO+6HEiBCCKlZMjMzMWvWLOzcuZMr09fX5zEi+VDoROhL9dS+WCso96P0SWO7qg2mGiuc+JRnHy8a90MIITVLREQEXFxcEBcXx5UNHjwYe/bsgZ6eHo+RVT5KhP5Hau+T3wstAKVaM9ZCkKfyDHimcT+EEFKzicVirFu3DgsXLkReXh4AQENDA5s2bcL48eOr3T5hlUFhE6EvB0prKBdKdD4kff6+zbAqiqh6kGUT04LEhxIeQgip+VJTUzFs2DCEhYVxZba2tggMDESLFi34C0zOFDYR+vjpc/eXoeYXv8DvFhoPNGBT1QRUDZR3YUMa70MIIbWPjo4OMjIyAOT3knh6emLp0qVQVVXlOTL5UthEKOp1FPe9xTcWn0+8e/L5e62GgKhO1QXFk5K6vairixBCFIeKigoCAgLg5OSE7du3o3v37nyHVCUUNhFK/5TOfa+EL9YH+nLafJ9fqzAifpTUCkQDnAkhpHYLDw+HhoYGrKw+r6PXokUL3L17t8Yujvg1FDYRik6J5r7vYdTj84lnn6fU45tmVRdQFSupFYi6vQghpHbLy8vDihUrsGzZMrRo0QI3b96U2iBVkZIgQIEToWcfnnHfa6pofj6R87mlCPXNqzCiyifrju7UCkQIIbVbQkICRo0ahfDwcABATEwMtm3bhtmzZ/McGX8UNhHSU9fDo+xHAIBmdf/X8nPvhHQlVU3UZOXd34tagQghpHZjjGH//v2YOnUqPnz4AAAQCoVYsmQJZsyYwW9wPFPYRCgnL4f7XltVO/+buFCeoqm44lp/Xn/Ib/VREgANtGhHd0IIUUTv3r3DpEmTEBwczJU1a9YMBw4cQKdOnXiMrHpQ2ETo5uubEKoLAQCqwv9NDXz6xUDpoXt4iOrrlDXt3VRPE+dn9ai6gAghhFQLYWFhGD16NJ4/f86VjR07Fj4+PtDS0uIxsupDYRMhIy0jvMx7CQBQVvrf2/Du8ecKTav/tMHyTHsvaPUhhBCiWJKSkuDg4IDc3FwAgK6uLnbu3IlhwxRroeCyKGwi9OzDM65FCADw/rl0BY1vqjYgGdG0d0IIIaUxNDTEkiVLsGDBAtjb28Pf3x+NGzfmO6xqR2EToSLOF1ozSElYfD2e0bR3QgghxWGMQSKRQCj8/Ptr3rx5MDIygqurq8JNiy8vhU+EuO017gR9Lvx+DT/BlODLgdA07Z0QQkhhKSkpmDBhAmxsbLBkyRKuXCgUYvTo0TxGVv0pfCJkrG0MiD9JF9pUn380pQ2EplYgQgghoaGhcHd3R3JyMk6ePIm+ffuic+fOfIdVYyh8IhT7NhZIfyFdqKpRfOUqVNpAaJr2TgghJDs7G15eXti0aRNXpqury60TRMpH4RMhJzMn4NX9zwUGlrzFUoAGQhNCCClNdHQ0XF1dER39ebsoBwcH+Pr6wsDAgMfIah6FT4Qa1WkE/PvFmkHGdrzFQgOhCSGElEYikeD333/HvHnzkJOTvzCwSCTCmjVrMHXqVBoQ/RUUPhESMzGQfOdzQdMevMRBrUCEEEJK8+bNG7i6uiI09PMuCG3atEFgYCBat27NY2Q1m8KnjkoCJSAz5XNBC8cqj6G4JKhZfU1KggghhHA0NTXx4sXnMa0eHh64ceMGJUEVpPAtQvVUdaQLBIIqj2HDuVipY0qACCGEFKampobAwEAMHjwYO3bsQN++ffkOqVZQ+ERImJPO6/NP3UmSGhNESRAhhBAAiIiIgKamJiwsLLiyNm3aIC4uDsrKCv/ru9IofNeYSlba54Om9lX23FN3ktBrfZhUl1iz+pqUBBFCiIITi8VYvXo1OnXqhJEjR3KDogtQElS5FD4REj6+8vmgjn6VPLNgTFDh2WG0OSohhCi2Z8+eoVevXvD09EReXh6ioqKwbds2vsOq1RQ+EVLKevf5QL2u3J9HA6MJIYQUJzg4GJaWlrh48SIAQCAQwMvLC1OmTOE5stpN4dvX9N8nfT6wHC7359HAaEIIIV9KT0/H9OnT4efnx5UZGRlh//796N69O4+RKQaFT4S+eZP4+UC7sdyfl5kj5r6nJIgQQhRbeHg4Ro0ahYSEBK7M2dkZ27dvh66uLo+RKQ6FT4S0xHmfD+o0kOuzTt1J4naPN9BWoySIEEIU2IsXL9CjRw/k5uYCALS0tLB161aMGjUKAh6WclFUNEboywM5/cMrboaYpkgol2cRQgipGRo1aoTZs2cDAOzs7HD79m2MHj2akqAqptAtQlrKX+wy36ynXJ5R0tYZNEOMEEIUC2MMAKQSnaVLl6JJkyYYN24cTYvniWK3CDHJ5+9VNEqu95VohhghhBAAePfuHUaMGIH169dLlauoqGDixImUBPFIod/5D+LszwfqlT8ojWaIEUIICQsLw+jRo/H8+XMcP34cvXr1go2NDd9hkf9R6BYhM2GdzweN2lbqvWnrDEIIUWy5ubnw9PREz5498fz5cwBAnTp1kJyczHNk5EsK3SIkVFL54qhyB6d92RpEW2cQQohiiY2NhYuLCyIjPw+PsLe3h7+/Pxo3lv9SLaT8FLpFSAj2+eCbZpV238KtQTQwmhBCFANjDDt37oSNjQ2XBKmoqGDNmjX4+++/KQmqhhS6RShPnPv5QFWzUu5ZeIA0tQYRQohiePv2LcaOHYuQkBCuzNzcHIGBgWjbtnKHX5DKo9AtQnGSj58PKmlV6cIDpKk1iBBCFINIJMKDBw+448mTJyMyMpKSoGpOoROhzllZnw+URZVyT9pCgxBCFJOmpiYCAgLQsGFDhISEYNu2bdDQqPylWUjlUuiuMaUvhghVtGvs1J0kbDgXi9cfaAsNQghRBNHR0dDU1ETTpk25snbt2iEhIQEiUeX8cU3kT6FbhKSyQKFKSdXKZcO5WMSnZELyv+SKttAghJDaSSKRwMfHB+3bt4erqyvy8vKkzlMSVLModCIkZKzsSuVU0CWmJMgfIE1jgwghpPZJSkrC999/jxkzZiAnJwfXrl3D9u3b+Q6LVADvidDWrVthYmICNTU1dOzYETdu3Ci1/qZNm2Bubg51dXUYGRnBw8MD2dnZpV5TEq7NpkGrr7q+OA201HB+Vg/qFiOEkFrmzz//RJs2bfDXX39xZR4eHpgwYQKPUZGK4jURCgoKwsyZM7FkyRJERkbCysoKDg4OeP36dbH1AwMD4enpiSVLliAmJgZ//PEHgoKCMH/+/K96/hvh/15+Q1rqnBBCSPEyMzMxadIkODk54c2bNwAAQ0NDhIaGYsOGDVBTU+M5QlIRvCZCGzZswIQJEzB27Fi0atUKO3bsgIaGBvbu3Vts/atXr6JLly5wcXGBiYkJ+vbti5EjR5bZilQSlYKeMbW6X/cCCCGE1GoRERFo27Ytdu7cyZU5OTnhzp076Nu3L4+RkcrCWyKUm5uLiIgI9O7d+3MwSkro3bs3wsPDi73Gzs4OERERXOKTkJCA06dPo1+/fiU+JycnB+np6VJfBUw+fcr/RrthhV7LqTtJSE7/uu45Qggh1dOzZ89gZ2eHuLg4AICGhgZ2796NY8eOQU9Pj+foSGXhLRFKTU2FWCyGvr6+VLm+vn6JG9K5uLjg119/RdeuXaGiooJmzZqhR48epXaNrVq1Cjo6OtyXkZERd06lYLC0asXWefhyEUWaLUYIIbWDkZER/u///g8AYGtri1u3bmH8+PEQCCp3b0rCL94HS8siLCwMK1euxLZt2xAZGYljx47h1KlTWLZsWYnXeHl54f3799zXs2fPuHOSgo1WhV8/1ZH2FSOEkNqDFZpNvGrVKmzYsAFXr15FixYteIqKyBNvCyrq6elBKBTi1atXUuWvXr2CgYFBsdcsWrQIo0ePxvjx4wEAbdq0QWZmJn7++WcsWLAASkpF8zqRSFTimg45Sv9LhD59LPZ8edAu84QQUvOlp6dj+vTp6NChA9cKBABqamrw8PDgMTIib7y1CKmqqsLW1hbnz5/nyiQSCc6fP4/OnTsXe83Hjx+LJDtCYX5XVOEsvjya5/5v01Udo9IrloBagwghpOYLDw+HtbU1/Pz8MGvWLMTExPAdEqlCvHaNzZw5E7t374afnx9iYmIwefJkZGZmYuzYsQCAMWPGwMvLi6s/cOBAbN++HYcOHUJiYiLOnTuHRYsWYeDAgVxCJIsswf9evsrXTX2k1iBCCKm58vLysHTpUnTr1g2JiYkAABUVFcTHx/McGalKvO415uzsjJSUFCxevBjJycmwtrbG2bNnuQHUT58+lWoBWrhwIQQCARYuXIgXL16gfv36GDhwIFasWPFVz9cV/2+D1K9oTaLWIEIIqbkSEhIwatQoqVnKdnZ2OHDgAExNTXmMjFQ1AfuaPqUaLD09HTo6Omi5vSXWfXiHfpkfgYn/BQytZLpPr/VhXCLUrL4mzs/qIYdoCSGEVCbGGPz9/TF16lRkZGQAyB9isXjxYsyfPx/Kygq9F3m1VvD7+/3799DW1q60+yr0J87tNSZUlek6ag0ihJCaJy0tDRMnTkRwcDBX1rRpUwQEBKBTp048Rkb4VKOmz1c2blSRjIkQjQ0ihJCaRyAQ4Pr169yxu7s7oqKiKAlScJQIAYCSbA1jBTvNA9QaRAghNYWOjg72798PPT09BAcHY9++fdDS0uI7LMIz6hoDAK2va9Ex0Faj1iBCCKmmYmNjoampicaNG3Nl3bp1w+PHj6GpqcljZKQ6UegWIe7FK8vWNUYIIaT6Yoxh586dsLGxwZgxYyCRSKTOUxJEvqTQiZAEAFRk+x+CNlglhJDqKyUlBU5OTpg0aRKysrJw4cIF7Nq1i++wSDWm0F1j2hIJ8ClHpmtog1VCCKmeQkND4e7uLrVx96RJkzBmzBgeoyLVnUK3CCkzAJBtGSUaKE0IIdVLdnY2PDw84OjoyCVBenp6CAkJwfbt26GhocFzhKQ6U+gWIWUwoK5xuet/2S1GA6UJIYR/0dHRcHV1RXR0NFfm4OAAX1/fEjfwJuRLCp0ICRkApfJ3b1G3GCGEVB9PnjxB+/btkZOTP8RBJBJhzZo1mDp1apENugkpiUL/SxEAgKD8CQ11ixFCSPVhbGzMjf9p06YNbt68ienTp1MSRGSi0C1C6kxS7hYh6hYjhJDqZ+PGjTA2NsasWbOgpqbGdzikBlLotFmWFiHqFiOEEP5kZmZi0qRJ8PX1lSrX1NTEggULKAkiX02xEyEGgInLrAdQtxghhPAlIiICtra22LlzJ6ZNm4b4+Hi+QyK1iGInQgCQ8kCma6hbjBBCqoZYLMbq1avRqVMnxMbmt8pLJBLcvXuX58hIbaLQY4QEAGDWu8x6tJo0IYRUrWfPnmH06NG4ePEiV2Zra4vAwEC0aNGCx8hIbaPQLUJKYMCbR2XWo/FBhBBSdYKDg2FpacklQQKBAF5eXrh69SolQaTSUYtQo3Zl1qPxQYQQIn8fPnzAtGnT4Ofnx5UZGRlh//796N69O4+RkdpMoVuEBAyAxjflrk/jgwghRH5ycnLw119/ccfOzs64ffs2JUFErhQ7EQIAoQrfYRBCCEH+/mB+fn7Q1taGv78/Dh48CF1dXb7DIrWcQneNKQHAx7el1qGB0oQQIh8JCQnQ1NSEvr4+V9anTx88efIEdevW5S8wolCoRUikVeL5U3eSMCUwkjumgdKEEFJxjDH4+fnBysoKP/30ExhjUucpCSJVSaETIYABdeqXePbL2WIADZQmhJCKevfuHUaMGAF3d3dkZGTg9OnT2LdvH99hEQWm2F1jDIBSyW/Bl7PFtrm2pYHShBBSAWFhYRg9ejSeP3/Olbm7u2PYsGE8RkUUnUK3CJV3rzGaLUYIIV8vNzcXnp6e6NmzJ5cE6erqIjg4GPv27YOWVslDFAiRN8VuEQJKbREihBBSMQ8ePICrqysiIz+Pt7S3t4e/vz8aN27MY2SE5KMsQKn4FiGaLUYIIRWTkJCAtm3bIisrCwCgoqKCFStWYNasWVBSUugOCVKNKPS/RCUAEBT/FtC2GoQQUjFNmzbF0KFDAQDm5ua4du0a5syZQ0kQqVYUukVIyBjwKavYc7StBiGEVNzWrVthbGyMBQsWQENDg+9wCCmiQml5dnbN7jpSBoB6TUutQwOlCSGkbNnZ2fDw8MDhw4elynV0dLBixQpKgki1JXMiJJFIsGzZMjRq1Ah16tRBQkICAGDRokX4448/Kj1AeREwlj9rjAZLE0JIhURHR6NDhw7YtGkTfv75Zzx79ozvkAgpN5kToeXLl8PX1xdr1qyBqqoqV966dWvs2bOnUoOTJ27Uj7BoIkQDpQkhpGwSiQQ+Pj5o3749oqOjAQBZWVm4efMmz5ERUn4yJ0L+/v7YtWsXXF1dIRR+HkRsZWWFBw8eVGpw8qRUsKJ7MS1CNFCaEEJKl5SUhH79+mHGjBnIyckBALRp0wY3b97EkCFDeI6OkPKTORF68eIFzMzMipRLJBJ8+vSpUoKqCkr4XyZUaI+bU3eSEJ+SyR3TQGlCCJH2559/wtLSEqGhoVyZh4cHbty4gdatW/MYGSGykzkRatWqFS5dulSk/MiRI7CxsamUoKoC98K1G0qVf9ka1Ky+Jg2UJoSQ/8nMzMSkSZPg5OSE1NRUAIChoSFCQ0OxYcMGqKmp8RwhIbKTeaTw4sWL4ebmhhcvXkAikeDYsWOIjY2Fv78/Tp48KY8Y5YLrGiu0jhBNmyeEkOKlp6fj6NGj3LGTkxN2794NPT09HqMipGJkbhEaPHgw/vOf/+Dvv/+GpqYmFi9ejJiYGPznP/9Bnz595BGjXHBdYyUsqEjT5gkhRJqhoSH27NkDDQ0N7N69G8eOHaMkiNR4XzV3vFu3bjh37lxlx1KluPRHIOAzDEIIqbaePXsGTU1N1KtXjysbPHgwEhMT0aBBAx4jI6TyyNwi1LRpU7x586ZIeVpaGpo2LX1xwuokjZvxRokQIYQUFhwcDEtLS0ycOBGs0KQSSoJIbSJzIvT48WOIxeIi5Tk5OXjx4kWlBFWlSugaI4QQRZSeng53d3c4OzsjLS0NR44cQWBgIN9hESI35e4aCwkJ4b4PDQ2Fjo4OdywWi3H+/HmYmJhUanDypJ+Xl//NF7vP00KKhBBFFh4eDldXVyQmJnJlzs7O6NevH49RESJf5U6EnJycAAACgQBubm5S51RUVGBiYoL169dXanBVQuXz/je0kCIhRBHl5eVhxYoVWLZsGdfir6Wlha1bt2LUqFEQ0FhKUouVOxGSSCQAAFNTU/z77781fqYA97+18PM2ITR1nhCiaBISEjBq1CiEh4dzZXZ2djhw4ABMTU15jIyQqiHzrLEvm0xrhS8SoQI0dZ4QoggePXqEtm3b4sOHDwAAoVCIxYsXY/78+VBWpg2piWL4qn/pmZmZuHjxIp4+fYrc3Fypc9OnT6+UwORNUDAJQqjCaxyEEMKXZs2aoVevXjhx4gSaNm2KgIAAdOrUie+wCKlSMidCt27dQr9+/fDx40dkZmaiXr16SE1NhYaGBho0aFBjEiEO9X0TQhSUQCDA7t27YWxsjGXLlkFLS4vvkAipcjLPHffw8MDAgQPx7t07qKur49q1a3jy5AlsbW2xbt06ecQoFwIA0DHiOwxCCKkSubm58PT0xKlTp6TK9fT0sGnTJkqCiMKSORGKiorCrFmzoKSkBKFQiJycHBgZGWHNmjWYP3++PGKUHyXqAyeE1H6xsbHo3LkzVq9ejZ9++gmvXr3iOyRCqg2ZEyEVFRUoKeVf1qBBAzx9+hQAoKOjg2fPnlVudPKWk859S2sIEUJqG8YYdu7cCRsbG0RGRgIA3r17hytXrvAcGSHVh8xNIjY2Nvj333/RvHlzdO/eHYsXL0Zqair279+P1q1byyNGuRCAAR8/bxVCawgRQmqTlJQUjB8/XmoxXHNzcwQGBqJt27Y8RkZI9SJzi9DKlSthaJg/tXzFihXQ1dXF5MmTkZKSgp07d1Z6gHJl0o37ltYQIoTUFqGhobC0tJRKgiZPnozIyEhKgggpROYWoXbt2nHfN2jQAGfPnq3UgKpUMWOEaA0hQkhNlZ2dDS8vL2zatIkr09PTw969ezFw4ED+AiOkGqu0HUcjIyMxYMCAyrpd1XgZyXcEhBBSaV6/fo19+/Zxx46OjoiOjqYkiJBSyJQIhYaGYvbs2Zg/fz4SEhIAAA8ePICTkxPat2/PbcNREwgAwPQ7ADRQmhBSOzRp0gTbt2+HSCTC5s2bcfr0aRgYGPAdFiHVWrm7xv744w9MmDAB9erVw7t377Bnzx5s2LAB06ZNg7OzM+7evYuWLVvKM9ZKJQAAFU0ANFCaEFIzJSUlQVNTE9ra2lzZyJEj0bVrVxgZ0TpphJRHuVuEfHx8sHr1aqSmpiI4OBipqanYtm0boqOjsWPHjhqVBHGE+XkgDZQmhNQ0f/75JywtLYtdzZ+SIELKr9yJUHx8PIYNGwYAGDp0KJSVlbF27Vo0btxYbsHJk4ABeP1AqowGShNCqrvMzExMmjQJTk5OSE1NhZ+fH44ePcp3WITUWOXuGsvKyoKGhgaA/P1pRCIRN42+xjLpwncEhBBSbhEREXBxcUFcXBxX5uTkhO7du/MYFSE1m0zT5/fs2YM6deoAAPLy8uDr6ws9PT2pOjVq01UBjQcihFR/YrEY69atw8KFC5GXlwcA0NDQgI+PD8aNGwcBbR5NyFcrdyLUpEkT7N69mzs2MDDA/v37peoIBAKZE6GtW7di7dq1SE5OhpWVFX7//Xd06NChxPppaWlYsGABjh07hrdv38LY2BibNm1Cv379ZHouAECJEiFCSPX27NkzjB49GhcvXuTKbG1tERgYiBYtWvAYGSG1Q7kTocePH1f6w4OCgjBz5kzs2LEDHTt2xKZNm+Dg4IDY2Fg0aNCgSP3c3Fz06dMHDRo0wJEjR9CoUSM8efIEdevWlfnZAoBahAgh1VpcXBw6duyItLQ0APl/bHp6emLp0qVQVVXlNzhCaglet1/fsGEDJkyYgLFjxwIAduzYgVOnTmHv3r3w9PQsUn/v3r14+/Ytrl69ChUVFQCAiYnJ1wdALUKEkGrMzMwMHTt2RGhoKIyMjLB//34aD0RIJau0laVllZubi4iICPTu3ftzMEpK6N27N8LDw4u9JiQkBJ07d8aUKVOgr6+P1q1bY+XKlRCLxcXWL40AADJTvjJ6QgiRPyUlJezbtw8///wzbt++TUkQIXLAWyKUmpoKsVgMfX19qXJ9fX0kJycXe01CQgKOHDkCsViM06dPY9GiRVi/fj2WL19e4nNycnKQnp4u9QX8b/d5XdPKe0GEEFIBeXl58Pb2xj///CNVbmhoiJ07d0JXV5enyAip3XjtGpOVRCJBgwYNsGvXLgiFQtja2uLFixdYu3YtlixZUuw1q1atgre3d/E3FNWh7TUIIbxLSEjAqFGjEB4ejkaNGuHOnTuoV68e32ERohB4axHS09ODUCjEq1evpMpfvXpV4t44hoaGaNGiBYTCz2N7WrZsieTkZOTm5hZ7jZeXF96/f899PXv2DMDnwdK0vQYhhC+MMfj7+8Pa2pobEpCcnIwLFy7wHBkhiuOrEqH4+HgsXLgQI0eOxOvXrwEAZ86cwb1798p9D1VVVdja2uL8+fNcmUQiwfnz59G5c+dir+nSpQsePXoktblrXFwcDA0NS5xBIRKJoK2tLfXFURLS9hqEEF68e/cOI0aMgJubGz58+AAAaNq0KS5fvowffviB5+gIURwyJ0IXL15EmzZtcP36dRw7dgwZGRkAgNu3b5fYPVWSmTNnYvfu3fDz80NMTAwmT56MzMxMbhbZmDFj4OXlxdWfPHky3r59i19++QVxcXE4deoUVq5ciSlTpsj6MvJ9MX2ettcghFSVsLAwWFpaIjg4mCtzd3dHVFQUOnXqxGNkhCgemccIeXp6Yvny5Zg5cya0tLS48p49e2LLli0y3cvZ2RkpKSlYvHgxkpOTYW1tjbNnz3IDqJ8+fQolpc+5mpGREUJDQ+Hh4QFLS0s0atQIv/zyC+bNmyfry8inxFvPICFEAeXm5mLJkiVYvXo1GGMAgLp162LXrl3cXo6EkKolcyIUHR2NwMDAIuUNGjRAamqqzAFMnToVU6dOLfZcWFhYkbLOnTvj2rVrMj+nMFpQkRBS1Z4/f47ff/+dS4J69OgBf39/2i2eEB7J3CRSt25dJCUlFSm/desWGjVqVClBVQUBA0D78xBCqlDTpk3h4+MDFRUVrFmzBufPn6ckiBCeyZwIjRgxAvPmzUNycjIEAgEkEgmuXLmC2bNnY8yYMfKIUX6YpOw6hBDylVJTU/Hx40epsp9++gn379/HnDlzpLr+CSH8kPn/wpUrV8LCwgJGRkbIyMhAq1at8N1338HOzg4LFy6UR4xyIQAAjW/4DoMQUkuFhoaiTZs2mDNnjlS5QCCAmZkZT1ERQgqTORFSVVXF7t27ER8fj5MnT+LAgQN48OAB9u/fL7W+T41AY4QIIZUsOzsbHh4ecHR0RHJyMrZt24ZTp07xHRYhpAQyD5a+fPkyunbtiiZNmqBJkybyiKlKCADadJUQUqmio6Ph6uqK6OhorszR0RG2trY8RkUIKY3MLUI9e/aEqakp5s+fj/v378sjpqpDLUKEkEogkUjg4+OD9u3bc0mQSCTC5s2bcfr06RJXyyeE8E/mROjly5eYNWsWLl68iNatW8Pa2hpr167F8+fP5RGf3OS3CNFARUJIxSQlJaFfv36YMWMGcnJyAABt2rTBzZs3MW3aNAhodioh1ZrMmYCenh6mTp2KK1euID4+HsOGDYOfnx9MTEzQs2dPecQoP9QiRAipgNjYWFhaWiI0NJQr8/DwwI0bN9C6dWseIyOElFeFmkRMTU3h6emJ3377DW3atMHFixcrK66qQWOECCEVYGZmhlatWgHI3xQ6NDQUGzZsgJqaGs+REULK66sToStXruD//u//YGhoCBcXF7Ru3bpGzYwQgOG/calITs/mOxRCSA0lFAqxf/9+jB49Gnfu3EHfvn35DokQIiOZZ415eXnh0KFDePnyJfr06QMfHx8MHjwYGhoa8ohPrnZfTwaQvxu9pohahwghJROLxVi3bh26desGOzs7rrxJkybw9/fnMTJCSEXInAj997//xZw5czB8+HDo6enJI6YqIQCQmft5ZelZfc35C4YQUq09e/YMo0ePxsWLF2FqaoqoqChoa2vzHRYhpBLInAhduXJFHnHwQvK/nkEDbTX0a2PIczSEkOooODgYEydORFpaGgDg8ePH+Ouvv/Djjz/yGxghpFKUKxEKCQnB999/DxUVFYSEhJRad9CgQZUSmLwxfE6ECCGksPT0dEyfPh1+fn5cmZGREfbv34/u3bvzGBkhpDKVKxFycnJCcnIyGjRoACcnpxLrCQQCiMXiyopNrh6IRGiWQet7EEKKCg8Px6hRo5CQkMCVOTs7Y/v27dDV1eUxMkJIZStXIiSRSIr9viazzM5BOrUIEUK+kJeXhxUrVmDZsmXcH3VaWlrYunUrRo0aRYsjElILyZwJ+Pv7c6unfik3N7fGzZxgoB9qhJDP4uPjsWrVKi4JsrOzw+3btzF69GhKggippWROhMaOHYv3798XKf/w4QPGjh1bKUFVFTFoyjwh5DNzc3OsWbMGQqEQ3t7e3CwxQkjtJfOsMcZYsX8ZPX/+HDo6OpUSVFWhFiFCFNu7d++goaEBkUjElU2bNg09e/akLTIIURDlToRsbGwgEAggEAjQq1cvKCt/vlQsFiMxMRGOjo5yCVJeJJQIEaKwwsLCMHr0aIwYMQJr167lygUCASVBhCiQcidCBbPFoqKi4ODggDp16nDnVFVVYWJigh9++KHSA5SnPCgjfyI9IURR5ObmYsmSJVi9ejUYY1i3bh0cHR3Rq1cvvkMjhPCg3InQkiVLAAAmJiZwdnauFZsK5kEIII/vMAghVSQ2NhYuLi6IjIzkyuzt7WFuTivLE6KoZB4s7ebmViuSIAFoQUVCFAVjDDt37oSNjQ2XBKmoqGDNmjX4+++/0bhxY54jJITwpVwtQvXq1UNcXBz09PSgq6tb6jTSt2/fVlpw8sYElAgRUtulpKRg/PjxUqvim5ubIzAwEG3btuUxMkJIdVCuRGjjxo3Q0tLivqf1NAghNUFsbCx69OiB5ORkrmzy5MlYt24dNDQ0eIyMEFJdlCsRcnNz4753d3eXVyxVjJI5Qmq7pk2bwsjICMnJydDT08PevXsxcOBAvsMihFQjMvcNRUZGIjo6mjv+888/4eTkhPnz5yM3N7dSg5MryoMIqfVUVFQQEBCAoUOHIjo6mpIgQkgRMidCEydORFxcHAAgISEBzs7O0NDQwOHDhzF37txKD1BeGBMgOT2b7zAIIZVEIpFg8+bNuHXrllR58+bNcfToURgYGPAUGSGkOpM5EYqLi4O1tTUA4PDhw+jevTsCAwPh6+uLo0ePVnZ8cvPl6kGaItpqg5CaLCkpCf369cMvv/wCFxcXfPz4ke+QCCE1hMyJEGOM24H+77//Rr9+/QAARkZGSE1NrdzoqsisvrSGCCE11Z9//glLS0uEhoYCAB48eIAzZ87wHBUhpKaQORFq164dli9fjv379+PixYvo378/ACAxMRH6+vqVHqC8KCE/mTPQVkO/NoY8R0MIkVVmZiYmTZoEJycn7o8wQ0NDhIaG1rhV7gkh/JF509VNmzbB1dUVJ06cwIIFC2BmZgYAOHLkCOzs7Co9QHmhxRQJqbkiIiLg4uLCjVcE8rcB2r17N/T09HiMjBBS08icCFlaWkrNGiuwdu1aCIU1Z6wN7TxPSM0jFouxdu1aLFq0CHl5+dvjaGhoYNOmTRg/fjytcUYIkZnMiVCBiIgIxMTEAABatWpV41Zopa1WCal5Hjx4IJUE2draIjAwEC1atOA5MkJITSVz/9Dr169hb2+P9u3bY/r06Zg+fTratWuHXr16ISUlRR4xygn95UhITfPtt99i2bJlEAgE8PLywtWrVykJIoRUiMyJ0LRp05CRkYF79+7h7du3ePv2Le7evYv09HRMnz5dHjESQhTUhw8fuNafAnPmzMGNGzewcuVKqKqq8hQZIaS2kDkROnv2LLZt24aWLVtyZa1atcLWrVtr1JRVAfWNEVKthYeHw9raGsuXL5cqFwqFaNeuHU9REUJqG5kTIYlEAhUVlSLlKioq3PpChBDytfLy8uDt7Y1u3bohISEBy5Ytw9WrV/kOixBSS8mcCPXs2RO//PILXr58yZW9ePECHh4e6NWrV6UGJ0/UIERI9ZOQkIDvvvsOS5cuhVgsBgB06tQJhoa01hchRD5kToS2bNmC9PR0mJiYoFmzZmjWrBlMTU2Rnp6O33//XR4xEkJqOcYY/P39YW1tjfDwcAD5XWDe3t64ePEiTE1NeY6QEFJbyTx93sjICJGRkTh//jw3fb5ly5bo3bt3pQdHCKn93r17h8mTJyMoKIgra9q0KQICAtCpUyceIyOEKAKZEqGgoCCEhIQgNzcXvXr1wrRp0+QVFyFEAcTGxqJPnz549uwZV+bu7o7NmzdDS0uLx8gIIYqi3F1j27dvx8iRI3Hz5k08fPgQU6ZMwZw5c+QZm5zROkKE8M3Y2Bh169YFAOjq6iI4OBj79u2jJIgQUmXKnQht2bIFS5YsQWxsLKKiouDn54dt27bJMzZCSC2npqaGwMBA9OvXD3fu3MGwYcP4DokQomDKnQglJCTAzc2NO3ZxcUFeXh6SkpLkEhghpHZhjGHXrl24f/++VHnr1q1x6tQpNG7cmKfICCGKrNyJUE5ODjQ1NT9fqKQEVVVVZGVlySUwQkjtkZKSAicnJ0ycOBEuLi7IycnhOyRCCAEg42DpRYsWQUNDgzvOzc3FihUroKOjw5Vt2LCh8qIjhNR4oaGhcHd3R3JyMgDg9u3bOHnyJH744QeeIyOEEBkSoe+++w6xsbFSZXZ2dkhISOCOBQIagEwIyZednQ1PT0/4+PhwZXp6eti7dy8GDhzIY2SEEPJZuROhsLAwOYZBCKlNoqOj4eLigrt373JlDg4O8PX1hYGBAY+REUKINJlXliaEkJJIJBL4+Pigffv2XBIkEong4+OD06dPUxJECKl2ZF5ZurZgtI4QIZUuOjoaM2fO5DZgbtOmDQIDA9G6dWueIyOEkOIpbIsQpUGEVD4rKyvMnz8fAODh4YEbN25QEkQIqdYUtkWIEFJxHz9+hJqaGpSUPv9NtXjxYvTt2xfdunXjMTJCCCkfhW0RIoRUTEREBGxsbLB+/XqpchUVFUqCCCE1xlclQpcuXcKoUaPQuXNnvHjxAgCwf/9+XL58uVKDI4RUP2KxGKtXr0anTp0QFxeHBQsWIDIyku+wCCHkq8icCB09ehQODg5QV1fHrVu3uBVi379/j5UrV1Z6gPLC+A6AkBro2bNn6NWrFzw9PZGXlwcAsLS0RJ06dXiOjBBCvo7MidDy5cuxY8cO7N69GyoqKlx5ly5d6K9CQmqx4OBgWFpa4uLFiwDyF1D18vLC1atX0aJFC56jI4SQryPzYOnY2Fh89913Rcp1dHSQlpZWGTFVCWoRIqR80tPTMX36dPj5+XFlRkZG2L9/P7p3785jZIQQUnEytwgZGBjg0aNHRcovX76Mpk2bVkpQVUlTJOQ7BEKqrdjYWNjY2EglQc7Ozrhz5w4lQYSQWkHmRGjChAn45ZdfcP36dQgEArx8+RIBAQGYPXs2Jk+eLI8Y5WpWX3O+QyCk2mrcuDGUlfMbjrW0tODv74+DBw+ibt26/AZGCCGVROZEyNPTEy4uLujVqxcyMjLw3XffYfz48Zg4cSKmTZv2VUFs3boVJiYmUFNTQ8eOHXHjxo1yXXfo0CEIBAI4OTl9xVMFMNBWQ782hl9xLSGKQVNTE4GBgejRowdu376N0aNH0+bKhJBaReZESCAQYMGCBXj79i3u3r2La9euISUlBcuWLfuqAIKCgjBz5kwsWbIEkZGRsLKygoODA16/fl3qdY8fP8bs2bNpvRJCKgljDP7+/oiPj5cqt7W1xT///ANTU1OeIiOEEPn56gUVVVVV0apVK3To0KFCU2c3bNiACRMmYOzYsWjVqhV27NgBDQ0N7N27t8RrxGIxXF1d4e3tXSPHJRFS3bx79w4jRoyAm5sbXF1d8enTJ6nz1ApECKmtZJ41Zm9vX+oPxX/++afc98rNzUVERAS8vLy4MiUlJfTu3Rvh4eElXvfrr7+iQYMGGDduHC5dulTqM3Jycri1joD8GTAAIKB5Y4QAAMLCwjB69Gg8f/4cAHD9+nWcPHkSQ4YM4TkyQgiRP5kTIWtra6njT58+ISoqCnfv3oWbm5tM90pNTYVYLIa+vr5Uub6+Ph48eFDsNZcvX8Yff/yBqKiocj1j1apV8Pb2LlKujlyZYiWktsnNzcXixYuxZs0aMJb/h4Guri527dpFSRAhRGHInAht3Lix2PKlS5ciIyOjwgGV5sOHDxg9ejR2794NPT29cl3j5eWFmTNncsfp6ekwMjLCB6jLK0xCqr3Y2Fi4uLhILYJqb28Pf39/NG7cmMfICCGkalXa7vOjRo1Chw4dsG7dunJfo6enB6FQiFevXkmVv3r1CgYGBkXqx8fH4/Hjxxg4cCBXJpFIAADKysqIjY1Fs2bNpK4RiUQQiURF7iWgnjGigBhj2LVrFzw8PJCVlQUgf5PUFStWYNasWVK7yBNCiCKotJ964eHhUFNTk+kaVVVV2Nra4vz581yZRCLB+fPn0blz5yL1LSwsEB0djaioKO5r0KBBsLe3R1RUFIyMjCr8OgipzW7duoVJkyZxSZC5uTmuXbuGOXPmUBJECFFIMrcIDR06VOqYMYakpCTcvHkTixYtkjmAmTNnws3NDe3atUOHDh2wadMmZGZmYuzYsQCAMWPGoFGjRli1ahXU1NTQunVrqesLFnYrXE4IKapt27aYOXMmNmzYgMmTJ2PdunXQ0NDgOyxCCOGNzImQjo6O1LGSkhLMzc3x66+/om/fvjIH4OzsjJSUFCxevBjJycmwtrbG2bNnuQHUT58+pb9UCflKOTk5UFVVlZrpuXLlSjg6OqJPnz48RkYIIdWDgBVMFykHsViMK1euoE2bNtDV1ZVnXHKTnp4OHR0dDF7/LZKzfXBtfi++QyJELqKjo+Hi4oLJkyfj//7v//gOhxBCKqTg9/f79++hra1dafeVqalFKBSib9++NWqXeUIUjUQigY+PD9q3b4+7d+9i1qxZuH//Pt9hEUJItSRzn1Pr1q2RkJAgj1gIIRWUlJSEfv36YcaMGdxCos2bN+c5KkIIqb5kToSWL1+O2bNn4+TJk0hKSkJ6errUV01BGwaQ2ubPP/+EpaUlQkNDuTIPDw/cuHEDrVq14jEyQgipvso9WPrXX3/FrFmz0K9fPwDAoEGDpAZgMsYgEAggFosrP0pCSIkyMzMxa9Ys7Ny5kyszNDSEr6/vV01gIIQQRVLuRMjb2xuTJk3ChQsX5BkPIUQGcXFxGDhwIOLi4rgyJycnmVZfJ4QQRVbuRKhgcln37t3lFgwhRDb6+vrIzc3fN09DQwM+Pj4YN24c7RZPCCHlJNMYIfrhSkj1oqOjgwMHDqBjx464desWxo8fT/+fEkKIDGRaULFFixZl/pB9+/ZthQIihJTs8OHD6NSpk9R2Ml26dEF4eDglQIQQ8hVkSoS8vb2LrCxNCJG/9PR0TJ8+HX5+fujRowf+/vtvCIVC7jwlQYQQ8nVkSoRGjBiBBg0ayCsWQkgxwsPDMWrUKG79rrCwMJw8eRKDBw/mOTJCCKn5yj1GiP7iJKRq5eXlwdvbG926deOSIC0tLfj7+2PQoEE8R0cIIbWDzLPGCCHyl5CQgFGjRiE8PJwrs7Ozw4EDB2BqaspjZIQQUruUu0VIIpFQtxghcsYYg7+/P6ytrbkkSCgUwtvbGxcvXqQkiBBCKplMY4QIIfJ18+ZNuLm5ccdNmzZFQEAAOnXqxGNUhBBSe8m81xghRH7at2+PiRMnAgDc3d0RFRVFSRAhhMgRtQgRwqNPnz5BWVlZajLC+vXr0a9fPxoQTQghVYBahAjhSWxsLDp16gQ/Pz+pck1NTUqCCCGkiihsIkSLARC+MMawc+dO2NjYIDIyEtOmTcOjR4/4DosQQhQSdY0RUoVSUlIwfvx4hISEcGWNGjVCVlYWj1ERQojiUtgWIUKqWmhoKCwtLaWSoEmTJiEyMhJt2rThMTJCCFFcCpsIMeocI1UkOzsbHh4ecHR0RHJyMgBAT08PISEh2L59OzQ0NHiOkBBCFBd1jREiR48ePcLQoUMRHR3NlTk6OmLfvn0wMDDgMTJCCCGAArcIEVIVdHV18ebNGwCASCTC5s2bcfr0aUqCCCGkmqBEiBA5+uabb+Dr6wsrKyvcvHkT06ZNow2MCSGkGlHYRIh+FRF5+M9//sONAyrQp08fREREoHXr1jxFRQghpCQKmwgRUpkyMzMxadIkDBo0CD/99BMYY1LnhUIhT5ERQggpDSVChFRQREQE2rZti507dwIAzpw5g5MnT/IcFSGEkPKgRIiQryQWi7F69Wp06tQJcXFxAAANDQ3s3r0bAwYM4Dk6Qggh5UHT5wn5Cs+ePcPo0aNx8eJFrszW1haBgYFo0aIFj5ERQgiRBbUIESKjoKAgWFpackmQQCCAl5cXrl69SkkQIYTUMNQiRIgMrl27hhEjRnDHRkZG2L9/P7p3785jVIQQQr4WtQgRIoNOnTph9OjRAABnZ2fcvn2bkiBCCKnBFLdFiJVdhRCJRAIlJem/F7Zs2YL+/ftj+PDhtDgiIYTUcNQiREgJEhIS0LVrVwQHB0uVa2trw9nZmZIgQgipBSgRIqQQxhj8/f1hbW2N8PBwTJw4Ec+ePeM7LEIIIXJAiRAhX3j37h1GjBgBNzc3fPjwAQBQr149buNUQgghtQslQoT8T1hYGCwtLaW6wtzd3REVFQVra2v+AiOEECI3lAgRhZebmwtPT0/07NkTz58/BwDUrVsXwcHB2LdvH7S0tHiOkBBCiLwo7qwxQpA/IHrYsGGIjIzkynr06AF/f38YGRnxGBkhhJCqQC1CRKGpq6vj6dOnAAAVFRWsWbMG58+fpySIEEIUBCVCRKEZGhrijz/+gIWFBa5du4Y5c+YUWTeIEEJI7UU/8YlC+fvvv4vMABs0aBDu3LmDtm3b8hQVIYQQvlAiRBRCdnY2PDw80KdPH0ycOBGMSS8trqKiwlNkhBBC+ESJEKn1oqOj0aFDB2zatAkAcPToUZw9e5bfoAghhFQLlAiRWksikcDHxwft27dHdHQ0AEAkEmHz5s1wdHTkOTpCCCHVAU2fJ7VSUlISxo4di9DQUK6sTZs2CAwMROvWrXmMjBBCSHWisC1CAtCGmbVVSEgILC0tpZIgDw8P3Lhxg5IgQgghUhS6RUhTJOQ7BFLJrly5gsGDB3PHBgYG8PPzQ9++fXmMihBCSHWlsC1CDMCsvuZ8h0EqmZ2dHYYMGQIAGDx4MKKjoykJIoQQUiKFbRFSEgD92hjyHQapIMYYBILP3ZwCgQC7d+/GoEGD4ObmJnWOEEIIKUxhW4RIzffs2TP07NkTJ0+elCr/5ptv4O7uTkkQIYSQMlEiRGqk4OBgWFpaIiwsDD/99BOSk5P5DokQQkgNRIkQqVHS09Ph7u4OZ2dnpKWlAQDU1NTw8uVLfgMjhBBSIylwIkTdJjVNeHg4rK2t4efnx5U5Ozvj9u3btE8YIYSQr6KwiRClQTVHXl4eli5dim7duiExMREAoKWlBX9/fxw8eBC6uro8R0gIIaSmUthZY6RmePz4MVxcXBAeHs6V2dnZ4cCBAzA1NeUxMkIIIbWBwrYIkZpBSUkJ9+/fBwAIhUJ4e3vj4sWLlAQRQgipFJQIkWqtSZMm2LFjB5o2bYrLly9j8eLFUFamhkxCCCGVQ2ETIcZ3AKRYly5dQnp6ulTZiBEjcO/ePXTq1ImnqAghhNRW1eJP661bt2Lt2rVITk6GlZUVfv/9d3To0KHYurt374a/vz/u3r0LALC1tcXKlStLrE9qhtzcXCxevBhr1qzB6NGjpWaGAflT5EntIBaL8enTJ77DIIRUQ6qqqlBSqto2Gt4ToaCgIMycORM7duxAx44dsWnTJjg4OCA2NhYNGjQoUj8sLAwjR46EnZ0d1NTUsHr1avTt2xf37t1Do0aNeHgFpKJiY2Ph4uKCyMhIAIC/vz9cXV1pj7BahjGG5ORkbv0nQggpTElJCaamplBVVa2yZwoYY7z2EnXs2BHt27fHli1bAAASiQRGRkaYNm0aPD09y7xeLBZDV1cXW7ZswZgxY8qsn56eDh0dHfy43hKHZ96ucPzk6zHGsGvXLnh4eCArKwsAoKKighUrVmDWrFlV/lcBka+kpCSkpaWhQYMG0NDQoC1QCCFSJBIJXr58CRUVFTRp0qTIz4iC39/v37+HtrZ2pT2X1xah3NxcREREwMvLiytTUlJC7969paZLl+bjx4/49OkT6tWrV+z5nJwc5OTkcMeFx58QfqSkpGD8+PEICQnhyszNzREYGEiLI9ZCYrGYS4K++eYbvsMhhFRT9evXx8uXL5GXlwcVFZUqeSavf3KnpqZCLBZDX19fqlxfX7/ce0fNmzcPDRs2RO/evYs9v2rVKujo6HBfRkZGFY6bVExoaCgsLS2lkqDJkycjMjKSkqBaqmBMkIaGBs+REEKqs4IuMbFYXGXPrNF9D7/99hsOHTqE48ePlziY1svLC+/fv+e+nj17VsVRki9dunQJjo6OXKKrp6eHkJAQbNu2jX5JKgDqDiOElIaPnxG8JkJ6enoQCoV49eqVVPmrV69gYGBQ6rXr1q3Db7/9hr/++guWlpYl1hOJRNDW1pb6Ivzp2rUrHB0dAQCOjo6Ijo7GwIEDeY6KEEKIouI1EVJVVYWtrS3Onz/PlUkkEpw/fx6dO3cu8bo1a9Zg2bJlOHv2LNq1a1cVoZJKIhAIsG/fPmzbtg2nT58uM+ElpCbr0aMHZsyYUWodExMTbNq0qUriIeXz3XffITAwkO8wah1PT09MmzaN7zCK4L1rbObMmdi9ezf8/PwQExODyZMnIzMzE2PHjgUAjBkzRmow9erVq7Fo0SLs3bsXJiYmSE5ORnJyMjIyMvh6CaQEycnJ6N+/v1SiCwAGBgaYPHkydZOQas/d3R0CgaDI16NHj6oshnv37uGHH36AiYkJBAJBuZKmsLAwqXjr16+Pfv36ITo6ukjdZ8+e4aeffkLDhg2hqqoKY2Nj/PLLL3jz5k2Ruo8ePcLYsWPRuHFjiEQimJqaYuTIkbh582ZlvNRqISQkBK9evcKIESP4DkVu7ty5g27dukFNTQ1GRkZYs2ZNmdecP38ednZ20NLSgoGBAebNm4e8vLxi6z569AhaWlqoW7euVPns2bPh5+eHhISEyngZlYb3RMjZ2Rnr1q3D4sWLYW1tjaioKJw9e5YbQP306VMkJSVx9bdv347c3Fz8+OOPMDQ05L7WrVsn03PpV7B8hYSEoE2bNjh9+jTc3NyK/aFKSE3g6OiIpKQkqa+q3Ovu48ePaNq0KX777TeZW1BjY2ORlJSE0NBQ5OTkoH///sjNzeXOJyQkoF27dnj48CEOHjyIR48eYceOHVyr/Nu3b7m6N2/ehK2tLeLi4rBz507cv38fx48fh4WFBWbNmlVpr7csYrEYEolEbvffvHkzxo4dW6HlO+QdY0Wkp6ejb9++MDY2RkREBNauXYulS5di165dJV5z+/Zt9OvXD46Ojrh16xaCgoIQEhJS7BI3nz59wsiRI9GtW7ci5/T09ODg4IDt27dX6muqMKZg3r9/zwCwH9db8h1KrZSRkcEmTpzIkL+LCQPADA0N2c2bN/kOjfAoKyuL3b9/n2VlZfEdikzc3NzY4MGDSzwfFhbG2rdvz1RVVZmBgQGbN28e+/TpE3e+e/fu7JdffuGOX716xQYMGMDU1NSYiYkJO3DgADM2NmYbN24sVzzlrXvhwgUGgL17944rCwkJYQDY7du3uTJHR0fWuHFj9vHjR6nrk5KSmIaGBps0aRJjjDGJRMK+/fZbZmtry8RicZHnffmcwsRiMVu9ejVr1qwZU1VVZUZGRmz58uUlxnnr1i0GgCUmJjLGGNu3bx/T0dFhf/75J2vZsiUTCoVs586dTCQSFXnu9OnTmb29PXd86dIl1rVrV6ampsYaN27Mpk2bxjIyMkqM9fXr10wgELC7d+9Kla9fv561bt2aaWhosMaNG7PJkyezDx8+cOeLizExMZFlZ2ezWbNmsYYNGzINDQ3WoUMHduHCBe661NRUNmLECNawYUOmrq7OWrduzQIDA0uMrzJs27aN6erqspycHK5s3rx5zNzcvMRrvLy8WLt27aTKQkJCmJqaGktPT5cqnzt3Lhs1ahT3nhTm5+fHGjduXOKzSvtZUfD7+/379yVe/zV4X1ma1B4RERFwdXVFbGwsV+bk5ITdu3dDT0+Px8hIdTTw98tI+ZBTdsVKVl9LhP9M61rh+7x48QL9+vWDu7s7/P398eDBA0yYMAFqampYunRpsde4u7vj5cuXuHDhAlRUVDB9+nS8fv26wrGU5f379zh06BCAz9OT3759i9DQUKxYsQLq6upS9Q0MDODq6oqgoCBs27YNUVFRuHfvHgIDA4ttKSncBfIlLy8v7N69Gxs3bkTXrl2RlJSEBw8eyBT/x48fsXr1auzZswfffPMNGjdujMWLF+Po0aMYN24cgPxWmKCgIKxYsQIAEB8fD0dHRyxfvhx79+5FSkoKpk6diqlTp2Lfvn3FPufy5cvQ0NBAy5YtpcqVlJSwefNmmJqaIiEhAf/3f/+HuXPnYtu2bSXG2KBBA0ydOhX379/HoUOH0LBhQxw/fpybJNK8eXNkZ2fD1tYW8+bNg7a2Nk6dOoXRo0ejWbNmJW4b9fTpU7Rq1arU92v+/PmYP39+sefCw8Px3XffSa3c7ODggNWrV+Pdu3fQ1dUtck1OTk6Rmdnq6urIzs5GREQEevToAQD4559/cPjwYURFReHYsWPFPr9Dhw54/vw5Hj9+DBMTk1JfR1WhRIhUmFgsxrp167Bw4UKuz1hDQwM+Pj4YN24cjQUixUr5kIPk9Gy+wyjTyZMnUadOHe74+++/x+HDh7Ft2zYYGRlhy5YtEAgEsLCwwMuXLzFv3jwsXry4SMIQFxeHM2fO4MaNG2jfvj0A4I8//ijyS7cyNW7cGACQmZkJABg0aBAsLCwAAA8fPgRjrMTnt2zZEu/evUNKSgoePnwIANy15fXhwwf4+Phgy5YtcHNzAwA0a9YMXbvKloh++vQJ27Ztg5WVFVc2YsQIBAYGconQ+fPnkZaWhh9++AFA/hpyrq6u3GD15s2bY/PmzejevTu2b99e7JIrT548gb6+fpHP7ssB7yYmJli+fDkmTZoklQgVjvHp06fYt28fnj59ioYNGwLIHyNz9uxZ7Nu3DytXrkSjRo0we/Zs7h7Tpk1DaGgogoODS0yEGjZsiKioqFLfr5IWGAbyx24W7totGIqSnJxcbCLk4OCATZs24eDBgxg+fDiSk5Px66+/AgA3dOXNmzdwd3fHgQMHSp2dXfBePHnyhBIhUjs8f/4co0ePRlhYGFdma2uLwMBAtGjRgr/ASLVXX0tUI55rb28vNaZBU1MTABATE4POnTtLJfpdunRBRkYGnj9/jiZNmkjdJyYmBsrKyrC1teXKLCwsSm1NqahLly5BQ0MD165dw8qVK7Fjx44idVg5dlkqT53ixMTEICcnB7169fqq6wuoqqoWWSbF1dUVnTp1wsuXL9GwYUMEBASgf//+3Pt5+/Zt3LlzBwEBAdw1jDFIJBIkJiYWmwBmZWUVmyD9/fffWLVqFR48eID09HTk5eUhOzsbHz9+5NY/KxxjdHQ0xGJxkZ+DOTk53OrqYrEYK1euRHBwMF68eIHc3Fzk5OSUuqaasrIyzMzMynjHKlffvn2xdu1aTJo0CaNHj4ZIJMKiRYtw6dIlLmmcMGECXFxc8N1335V6r4LWx48fP8o97vKiRIhUSFZWFv79918A+VPjPT09sXTp0irdMI/UTJXRPVUVNDU1q/wXT2UxNTVF3bp1YW5ujtevX8PZ2Rn//e9/AQBmZmYQCASIiYnBkCFDilwbExMDXV1d1K9fn/tl/uDBA9jY2JT7+YW73Aor+CX6ZaJVsAp54fsUbllu3749mjVrhkOHDmHy5Mk4fvw4fH19ufMZGRmYOHEipk+fXuR+hZPUAnp6enj37p1U2ePHjzFgwABMnjwZK1asQL169XD58mWMGzcOubm5XNJSOMaMjAwIhUJERERAKBRK3bOghXHt2rXw8fHBpk2b0KZNG2hqamLGjBlSA9oLq2jXmIGBQbFr9xWcK8nMmTPh4eGBpKQk6Orq4vHjx/Dy8kLTpk0B5HeLhYSEcBOXCpJOZWVl7Nq1Cz/99BMAcAPw69evX+prqEqUCJEKKWhuXrp0Kfbv34/u3bvzHRIhVaJly5Y4evQoGGPcL8ArV65AS0uL65L6koWFBfLy8hAREcF1jcXGxiItLa1K4p0yZQpWrVqF48ePY8iQIfjmm2/Qp08fbNu2DR4eHlJJS3JyMgICAjBmzBgIBAJYW1ujVatWWL9+PZydnYt0HaWlpRXbstW8eXOoq6vj/PnzGD9+fJHzBb8MC365Aiiz2+dLrq6uCAgIQOPGjaGkpIT+/ftz59q2bYv79+/LlMTa2NggOTlZaqxMREQEJBIJ1q9fz73u4ODgct1LLBbj9evXxc6gAvL/vQwePBijRo0CkL+OXlxcXKmJTkW7xjp37owFCxbg06dP3F5e586dg7m5ebHdYl8SCARc19bBgwdhZGTEbYsUHh4utS3Gn3/+idWrV+Pq1ato1KgRV3737l2oqKjg22+/LfVZVapSh17XADRrrGKuX7/OMjMzpcokEonUDApCCquNs8aeP3/ONDQ02JQpU1hMTAw7ceIE09PTY0uWLOHqFJ415ujoyGxsbNi1a9fYzZs3WdeuXZm6unqpM8FycnLYrVu32K1bt5ihoSGbPXs2u3XrFnv48GGJ1xQ3G4ux/Bk9bdq0YRKJhDHGWFxcHNPT02PdunVjFy9eZE+fPmVnzpxhrVu3Zs2bN2dv3rzhrr1+/TrT0tJidnZ27NSpUyw+Pp7dvn2bLV++nH333XclxrJ06VKmq6vL/Pz82KNHj1h4eDjbs2cPY4yx3NxcZmRkxIYNG8bi4uLYyZMnmbm5ebGzxorz8OFDBoBZWlqycePGSZ27ffs2U1dXZ1OmTGG3bt1icXFx7MSJE2zKlCklxpqXl8fq16/P/vOf/3BlUVFRDADbtGkTi4+PZ/7+/qxRo0ZS729JMbq6ujITExN29OhRlpCQwK5fv85WrlzJTp48yRhjzMPDgxkZGbErV66w+/fvs/HjxzNtbe1SZypWVFpaGtPX12ejR49md+/eZYcOHWIaGhps586dXJ1jx44VmUW2Zs0adufOHXb37l3266+/MhUVFXb8+PESn1PSe7JkyRLWs2fPEq/jY9aYwiZCw9Zb8R1KjfLp0ye2dOlSJhQK2eTJk/kOh9QwtTERYkz26fNJSUmsf//+TCQSsSZNmjB/f/8yp8QnJiZKLUdR8NW9e/cSrykpEXr69ClTVlZmQUFBXNnjx4+Zm5sb09fXZyoqKszIyIhNmzaNpaamFrlvbGwsGzNmDGvYsCFTVVVlxsbGbOTIkSwyMrLEWMRiMVu+fDkzNjZmKioqrEmTJmzlypXc+cuXL7M2bdowNTU11q1bN3b48OFyJ0KMMdahQwcGgP3zzz9Fzt24cYP16dOH1alTh2lqajJLS0u2YsWKEu/FWH6yOGLECKmyDRs2MENDQ6aurs4cHByYv79/uRKh3NxctnjxYmZiYsJUVFSYoaEhGzJkCLtz5w5jjLE3b96wwYMHszp16rAGDRqwhQsXsjFjxsg1EWIsP0ns2rUrE4lErFGjRuy3336TOr9v3z5WuJ3E3t6e6ejoMDU1NdaxY0d2+vTpUp9R0ntibm7ODh48WOJ1fCRCAsa+chRcDZWeng4dHR0MW2+F4JlRfIdTIyQkJGDUqFEIDw/nyv755x/Y29vzGBWpSbKzs5GYmAhTU9MSN0gmpDpITk7Gt99+i8jISBgbG/MdTq1y5swZzJo1C3fu3IGycvEjc0r7WVHw+/v9+/eVum8o7ytLk+qLMQZ/f39YW1tzSZBQKIS3t3eJfd6EEFKTGRgY4I8//sDTp0/5DqXWyczMxL59+0pMgvhSvaIh1ca7d+8wefJkBAUFcWVNmzZFQEAAOnXqxGNkhBAiX05OTnyHUCv9+OOPfIdQLIVtEVKo/kAZXbx4EVZWVlJJkLu7O6KioigJIoQQUqtQixCRcvHiRdjb23Preujq6mLnzp0YNmwYz5ERQgghlU9hW4RI8bp27cqtDGpvb487d+5QEkQIIaTWUtgWIdr9qnhCoRD79+/H4cOHMWPGjGI3WCSEEEJqC/otp8BSUlLwww8/4MqVK1LlRkZGmDlzJiVBhBBCaj2FbRFSdKGhoXB3d0dycjIiIyNx+/btSl2XgRBCCKkJ6E9+BZOdnY0ZM2bA0dERycnJAPI3B4yLi+M5MkIIIaTqUSKkQKKjo9G+fXv4+PhwZY6OjoiOjka7du14jIyQ2qlHjx6YMWNGqXVMTEywadOmKomHlC03NxdmZma4evUq36HUOp6enpg2bRrfYRRBiZACkEgk8PHxQfv27XH37l0AgEgkwubNm3H69GkYGBjwHCEh1ZO7uzsEAkGRr0ePHlVZDLt370a3bt2gq6sLXV1d9O7dGzdu3Cj1Gl9fXy5WJSUlGBoawtnZudjVku/du4fhw4ejfv36EIlEaNGiBRYvXoyPHz8WqXvr1i0MGzYM+vr6UFNTQ/PmzTFhwoRa1aK8Y8cOmJqaws7Oju9Q5CYsLAxt27aFSCSCmZkZfH19y7wmODgY1tbW0NDQgLGxMdauXVukztatW9GyZUuoq6vD3Nwc/v7+Uudnz54NPz8/JCQkVNZLqRSUCNVySUlJ6NevH2bMmIGcnBwAQJs2bXDz5k1MmzYNAgHNnyOkNI6OjkhKSpL6MjU1rbLnh4WFYeTIkbhw4QLCw8NhZGSEvn374sWLF6Vep62tjaSkJLx48QJHjx5FbGxskaUwrl27ho4dOyI3NxenTp1CXFwcVqxYAV9fX/Tp0we5ublc3ZMnT6JTp07IyclBQEAAYmJicODAAejo6GDRokVyee3F+TKmysYYw5YtWzBu3LgK3UeeMVZUYmIi+vfvD3t7e0RFRWHGjBkYP348QkNDS7zmzJkzcHV1xaRJk3D37l1s27YNGzduxJYtW7g627dvh5eXF5YuXYp79+7B29sbU6ZMwX/+8x+ujp6eHhwcHLB9+3a5vkaZVeoWrjVAwe61wxVk9/m7d+8ykUjE7Vjt4eFR43YAJzUf7T6f79WrV2zAgAFMTU2NmZiYsAMHDpS5+3xheXl5TEtLi/n5+ZVYp7idvzdv3iy1c7dEImGtWrVi7dq1Y2KxWKpuVFQUEwgE3K7kmZmZTE9Pjzk5ORX7vMK73H8pOzubzZ07lzVu3JipqqqyZs2asT179pQY5/Hjx6V2Pl+yZAmzsrJiu3fvZiYmJkwgELCdO3cyQ0PDInEPGjSIjR07ljs+ceIEs7GxYSKRiJmamrKlS5dKfT6F/fvvv0xJSYmlp6dLlc+dO5c1b96cqaurM1NTU7Zw4UKWm5tbaowF78u4ceOYnp4e09LSYvb29iwqKoq77tGjR2zQoEGsQYMGTFNTk7Vr146dO3euxPgqw9y5c9m3334rVebs7MwcHBxKvGbkyJHsxx9/lCrbvHkza9y4MZNIJIwxxjp37sxmz54tVWfmzJmsS5cuUmV+fn6scePGJT6Lj93nFXbWmKJssfHtt99i7dq1WLlyJfz8/NC3b1++QyIk387uQMbrqn9unQbAxIsVvs2LFy/Qr18/uLu7w9/fHw8ePMCECROgpqaGpUuXFnuNu7s7Xr58iQsXLkBFRQXTp0/H69eyvQcfP37Ep0+fUK9evXJf8/r1axw/fhxCoRBCoRAAEBUVhfv37yMwMLDIUhlWVlbo3bs3Dh48iHnz5iE0NBSpqamYO3dusfevW7duic8eM2YMwsPDsXnzZlhZWSExMRGpqanljh0AHj16hKNHj+LYsWMQCoUwMjLCtGnTcOHCBfTq1QsA8PbtW5w9exanT58GAFy6dAljxozB5s2b0a1bN8THx+Pnn38GACxZsqTY51y6dAktWrSAlpaWVLmWlhZ8fX3RsGFDREdHY8KECdDS0pJ6PwrHCADDhg2Duro6zpw5Ax0dHezcuRO9evVCXFwc6tWrh4yMDPTr1w8rVqyASCSCv78/Bg4ciNjYWDRp0qTEGL///vtS36+dO3fC1dW12HPh4eHo3bu3VJmDg0OpY9lycnKgoaEhVaauro7nz5/jyZMnMDExQU5OTpHd4tXV1XHjxg18+vQJKioqAIAOHTrg+fPnePz4MUxMTEp9HVVFYROh2ur27duwsLCASCTiyqZOnYpRo0ZBV1eXx8gIKSTjNfDhJd9RlOnkyZOoU6cOd/z999/j8OHD2LZtG4yMjLBlyxYIBAJYWFjg5cuXmDdvHhYvXlwkuYiLi8OZM2dw48YNtG/fHgDwxx9/oGXLljLFM2/ePDRs2LDIL7PC3r9/jzp16oAxxo33mT59OjQ1Nbl4AJT4/JYtW+Ly5csAgIcPHwIALCwsZIo1Li4OwcHBOHfuHBdv06ZNZboHkN/V5O/vj/r163Nl33//PQIDA7lE6MiRI9DT04O9vT0AwNvbG56ennBzc+Oeu2zZMsydO7fEROjJkydo2LBhkfKFCxdy35uYmGD27Nk4dOiQVCJUOMbLly/jxo0beP36NffzeN26dThx4gSOHDmCn3/+GVZWVrCysuLusWzZMhw/fhwhISGYOnVqsTG2a9cOUVFRpb5f+vr6JZ5LTk4ucl5fXx/p6enIysqCurp6kWscHBzg4eEBd3d32Nvb49GjR1i/fj2A/OEXJiYmcHBwwJ49e+Dk5IS2bdsiIiICe/bswadPn5CamgpDQ0MA4N7fggSqOqBEqJYQi8VYt24dFi5ciF9++QXr1q3jzgkEAkqCSPVTp0GNeK69vb3UmIaCRCImJgadO3eWGmfXpUsXZGRk4Pnz50X+oo+JiYGysjJsbW25MgsLi1JbUwr77bffcOjQIYSFhRX567swLS0tREZG4tOnTzhz5gwCAgKwYsWKIvUYK7t9vDx1ihMVFQWhUIju3bt/1fUFjI2NpZIgAHB1dcWECROwbds2iEQiBAQEYMSIEVwCevv2bVy5ckXqNYvFYmRnZ+Pjx49FWjgAICsrq9j3NSgoCJs3b0Z8fDwyMjKQl5dXZN21wjHevn0bGRkZ+Oabb4o8Iz4+HkD+0iVLly7FqVOnkJSUhLy8PGRlZRU7qL2Auro6zMzMSjwvDxMmTEB8fDwGDBiAT58+QVtbG7/88guWLl3Kvd+LFi1CcnIyOnXqBMYY9PX14ebmhjVr1kj9UVCQaBU3GJ8vlAjVAs+ePcPo0aNx8WJ+c//69evh5OSErl278hwZIaWohO6pqqCpqVnlv3iKs27dOvz222/4+++/YWlpWWZ9JSUlLu6WLVsiPj4ekydPxv79+wEALVq0AJCfoNnY2BS5PiYmhqtT8N8HDx6gc+fO5Y65uNaFwjEWTrI+ffpUpF5B8vmlgQMHgjGGU6dOoX379rh06RI2btzInc/IyIC3tzeGDh1a5NqSkkg9PT1ER0dLlYWHh8PV1RXe3t5wcHCAjo4ODh06xLWIlBRjRkYGDA0NERYWVuQ5Bcnv7Nmzce7cOaxbtw5mZmZQV1fHjz/+WOpg64p2jRkYGODVq1dSZa9evYK2tnaJn5dAIMDq1auxcuVKJCcno379+jh//jyAzy186urq2Lt3L3bu3IlXr17B0NAQu3btgpaWllSC+PbtWwAoktjyiRKhGi44OBgTJ05EWloagPx/sJ6enujQoQO/gRFSy7Vs2RJHjx4FY4xrFbpy5Qq0tLTQuHHjIvUtLCyQl5eHiIgIrmssNjaW+3+3NGvWrMGKFSsQGhr61Wt+eXp6olmzZvDw8EDbtm1hbW0NCwsLbNy4UaolBchvzfj777+xatUqAEDfvn2hp6eHNWvW4Pjx40XunZaWVmzLVps2bSCRSHDx4sViu/Lq16+PDx8+IDMzk0skyur2KaCmpoahQ4ciICAAjx49grm5Odq2bcudb9u2LWJjY2VKYm1sbLB9+3apz/Tq1aswNjbGggULuHpPnjwp815t27ZFcnIylJWVS+wCunLlCtzd3TFkyBAA+cnT48ePS71vRbvGOnfuzI2jKnDu3LlyJbhCoRCNGjUCABw8eBCdO3cuktCoqKhw//4PHTqEAQMGSP3bunv3LlRUVPDtt9+W+bwqU6lDr2uAglHnw9Zb8x1Khbx//565ublxs8EAMCMjIxYWFsZ3aIQUURtnjT1//pxpaGiwKVOmsJiYGHbixAmmp6fHlixZwtUpPGvM0dGR2djYsGvXrrGbN2+yrl27MnV19VJnjf32229MVVWVHTlyhCUlJXFfHz58KPGa4mZjMcbY8OHDWf/+/bnjK1euMA0NDebk5MSuX7/Onjx5woKDg5mRkRGzs7Nj2dnZXN0TJ04wFRUVNnDgQHbu3DmWmJjI/v33XzZnzhzm7OxcYizu7u7MyMiIHT9+nCUkJLALFy6woKAgxhhjb968YZqammz69Ons0aNHLCAggDVs2LDYWWPFOXfuHBOJRMzc3JwtW7ZM6tzZs2eZsrIyW7p0Kbt79y67f/8+O3jwIFuwYEGJsaampjIVFRUWHR3Nlf35559MWVmZHTx4kD169Ij5+PiwevXqSb2/xcUokUhY165dmZWVFQsNDWWJiYnsypUrbP78+ezff/9ljDE2ZMgQZm1tzW7dusWioqLYwIEDmZaWltS/mcqWkJDANDQ02Jw5c1hMTAzbunUrEwqF7OzZs1yd33//nfXs2ZM7TklJYdu3b2cxMTHs1q1bbPr06UxNTY1dv36dqxMbG8v279/P4uLi2PXr15mzszOrV68eS0xMlHr+kiVLpO5dGB+zxigRqoGuXr3KmjZtKpUEOTs7s7dv3/IdGiHFqo2JEGOyT59PSkpi/fv3ZyKRiDVp0oT5+/uXOX3e2NhY6v/1gq8vE67CSkqEwsPDGQCpX2B37txhP/zwA6tXrx5TUVFhzZo1YwsXLmSZmZlFrv/333/Z0KFDWf369ZlIJGJmZmbs559/Zg8fPiwxlqysLObh4cEMDQ2ZqqoqMzMzY3v37uXOHz9+nJmZmTF1dXU2YMAAtmvXrnInQmKxmBkaGjIALD4+vsj5s2fPMjs7O6aurs60tbVZhw4d2K5du0qMlbH8ZNHT01OqbM6cOeybb75hderUYc7Ozmzjxo1lJkKMMZaens6mTZvGGjZsyFRUVJiRkRFzdXVlT58+ZYwxlpiYyOzt7Zm6ujozMjJiW7ZsKfJvRh4uXLjArK2tmaqqKmvatCnbt2+f1PklS5YwY2Nj7jglJYV16tSJaWpqMg0NDdarVy927do1qWvu37/PrK2tufd68ODB7MGDB0WebW5uzg4ePFhibHwkQgLGvnIUXA2Vnp4OHR0dDF9njaBZt/gOR2ZhYWHo3bs3xGIxgPwBkVu3bsWoUaNocURSbWVnZyMxMRGmpqZlDvIlhE937txBnz59EB8fLzVbkFTcmTNnMGvWLNy5cwfKysWPzCntZ0XB7+/3799X6ibhtLJ0DdOlSxdu1omdnR1u376N0aNHUxJECCGVwNLSEqtXr0ZiYiLfodQ6mZmZ2LdvX4lJEF+qVzSkTCoqKggICEBQUBDmzZtX7f5BEUJITefu7s53CLXSjz/+yHcIxaIWoWrs3bt3cHV1RUREhFS5mZkZFixYQEkQIYQQUkEK+5u0ug+MCgsLw+jRo/H8+XNEREQgMjKy2AXACCGEEPL1qEWomsnNzYWnpyd69uyJ58+fA8jfJ+jevXs8R0YIIYTUPgrbIlQdxcbGwsXFBZGRkVyZvb09/P39i12gjRBCCCEVo7AtQtVpjhVjDDt37oSNjQ2XBKmoqGDNmjX4+++/KQkihBBC5IRahHiWkpKC8ePHIyQkhCszNzdHYGCg1HLxhBBCCKl8CtsiVF0GSz979kxq35fJkycjMjKSkiBCCCGkCihsIlRdtG3bFsuXL4eenh5CQkKwbds2mh1GSC3Ro0cPzJgxo9Q6JiYm2LRpU5XEQ8qWm5sLMzMzXL16le9Qap0RI0Zg/fr1fIdRBCVCVezBgwf49OmTVNns2bNx7949DBw4kKeoCCHFcXd3h0AgKPL16NGjKovh2LFjaNeuHerWrQtNTU1YW1tj//79pV7j6+vLxaqkpARDQ0M4Ozvj6dOnRereu3cPw4cPR/369SESidCiRQssXrwYHz9+LFL31q1bGDZsGPT19aGmpobmzZtjwoQJiIuLq7TXy7cdO3bA1NQUdnZ2fIciF0lJSXBxcUGLFi2gpKRUZqJe4OnTp+jfvz80NDTQoEEDzJkzB3l5eVJ1wsLC0LZtW4hEIpiZmcHX11fq/MKFC7FixQq8f/++kl5N5aBEqIpIJBL4+PjA2toay5cvlzonFArRoEEDniIjhJTG0dERSUlJUl+mpqZV9vx69ephwYIFCA8Px507dzB27FiMHTsWoaGhpV6nra2NpKQkvHjxAkePHkVsbCyGDRsmVefatWvo2LEjcnNzcerUKcTFxWHFihXw9fVFnz59kJuby9U9efIkOnXqhJycHAQEBCAmJgYHDhyAjo4OFi1aJJfXXpwvY6psjDFs2bIF48aNq9B95BljReXk5KB+/fpYuHAhrKysynWNWCxG//79kZubi6tXr8LPzw++vr5YvHgxVycxMRH9+/eHvb09oqKiMGPGDIwfP17q32nr1q3RrFkzHDhwoNJfV4VU6hauNQC3+/y6qtt9/uXLl8zBwYHbNVpJSUlq92dCajvafT7fq1ev2IABA5iamhozMTFhBw4cKHP3+eLY2NiwhQsXlni+uN3nN2/eLLVzt0QiYa1atWLt2rVjYrFYqm5UVBQTCATst99+Y4wxlpmZyfT09JiTk1Oxz3v37l2JsWRnZ7O5c+eyxo0bM1VVVdasWTO2Z8+eEuM8fvx4sbvP7969m5mYmDCBQMB27tzJDA0Ni8Q9aNAgNnbsWO74xIkTzMbGholEImZqasqWLl0q9fkU9u+//zIlJSWWnp4uVT537lzWvHlzpq6uzkxNTdnChQtZbm5uqTEWvC/jxo1jenp6TEtLi9nb27OoqCjuukePHrFBgwaxBg0aME1NTdauXTt27ty5EuOrbOXd6f706dNMSUmJJScnc2Xbt29n2traLCcnhzGW/x59++23Utc5OzszBwcHqTJvb2/WtWvXEp/Fx+7zCjtrrKqmz//5558YP348UlNTubLp06fD0tKyiiIgpHpyPumM1KzUsitWMj11PQQNCKrwfV68eIF+/frB3d0d/v7+ePDgASZMmAA1NTUsXbq02Gvc3d3x8uVLXLhwASoqKpg+fTpev35d7mcyxvDPP/8gNjYWq1evLvd1r1+/xvHjxyEUCiEUCgEAUVFRuH//PgIDA6GkJN05YGVlhd69e+PgwYOYN28eQkNDkZqairlz5xZ7/7p165b47DFjxiA8PBybN2+GlZUVEhMTpX4elsejR49w9OhRHDt2DEKhEEZGRpg2bRouXLiAXr16AQDevn2Ls2fPcpNPLl26hDFjxmDz5s3o1q0b4uPj8fPPPwMAlixZUuxzLl26hBYtWkBLS0uqXEtLC76+vmjYsCGio6MxYcIEaGlpSb0fhWMEgGHDhkFdXR1nzpyBjo4Odu7ciV69eiEuLg716tVDRkYG+vXrhxUrVkAkEsHf3x8DBw5EbGwsmjRpUmKM33//fanv186dO+Hq6lqOd7Z8wsPD0aZNG+jr63NlDg4OmDx5Mu7duwcbGxuEh4ejd+/eUtc5ODgU6Xrr0KEDVqxYgZycHIhEokqLsSIUNhGSdyqUmZmJWbNmYefOnVyZgYEB/Pz80LdvX7k+m5CaIDUrFa8/lj8J4MvJkydRp04d7vj777/H4cOHsW3bNhgZGWHLli0QCASwsLDAy5cvMW/ePCxevLhIchEXF4czZ87gxo0baN++PQDgjz/+QMuWLcuM4f3792jUqBFycnIgFAqxbds29OnTp8xr6tSpA8YYN95n+vTp0NTU5OIBUOLzW7ZsicuXLwMAHj58CACwsLAoM9YvxcXFITg4GOfOneN+STZt2lSmewD5XU3+/v6oX78+V/b9998jMDCQS4SOHDkCPT092NvbAwC8vb3h6ekJNzc37rnLli3D3LlzS0yEnjx5goYNGxYpX7hwIfe9iYkJZs+ejUOHDkklQoVjvHz5Mm7cuIHXr19zv/DXrVuHEydO4MiRI/j5559hZWUl1T21bNkyHD9+HCEhIZg6dWqxMbZr1w5RUVGlvl9fJiyVITk5ucg9C46Tk5NLrZOeno6srCyoq6sDABo2bIjc3FwkJyfD2Ni4UuP8WgqcCMlPREQEXFxcpAYQDh48GHv27IGenh6PkRFSfeip8/P/gqzPtbe3x/bt27njgkQiJiYGnTt3hkDw+Y+qLl26ICMjA8+fPy/yF31MTAyUlZVha2vLlVlYWJTamlJAS0sLUVFRyMjIwPnz5zFz5kw0bdoUPXr0KPWayMhIfPr0CWfOnEFAQABWrFhRpB5jZS8mUp46xYmKioJQKET37t2/6voCxsbGUkkQALi6umLChAnYtm0bRCIRAgICMGLECC4BvX37Nq5cuSL1msViMbKzs/Hx48diZ+dmZWVBTU2tSHlQUBA2b96M+Ph4ZGRkIC8vD9ra2qXGePv2bWRkZOCbb74p8oz4+HgAQEZGBpYuXYpTp04hKSkJeXl5yMrKKnZQewF1dXWYmZmVeL66K0iIihuMzxdKhCrZP//8AwcHB240vYaGBjZt2oTx48dL/cAkRNFVRvdUVdDU1OT9F4+SkhIXg7W1NWJiYrBq1apSE6Evr2nZsiXi4+MxefJkbsZZixYtAOQnaDY2NkWuj4mJ4eoU/PfBgwfo3LlzueMu+KVXWoyFk6zCs2qBz8nnlwYOHAjGGE6dOoX27dvj0qVL2LhxI3c+IyMD3t7eGDp0aJFri0t2AEBPTw/R0dFSZeHh4XB1dYW3tzccHBygo6ODQ4cOFZkGXjjGjIwMGBoaIiwsrMhzCpLf2bNn49y5c1i3bh3MzMygrq6OH3/8sdTB1nx0jRkYGODGjRtSZa9eveLOFfy3oOzLOtra2lL/Dt6+fQsARRJbPlEiVMm6dOmCVq1a4c6dO7C1tUVgYCD3Q4QQUnu0bNkSR48eBWOM+yPnypUr0NLSKnZbHAsLC+Tl5SEiIoLrGouNjUVaWprMz5ZIJMjJyZHpGk9PTzRr1gweHh5o27YtrK2tYWFhgY0bN0q1pAD5rRl///03Vq1aBQDo27cv9PT0sGbNGhw/frzIvdPS0opt2WrTpg0kEgkuXrxYZPwIkP/L8MOHD8jMzOQSibK6fQqoqalh6NChCAgIwKNHj2Bubi61EG3btm0RGxsrUxJrY2OD7du3S32mV69ehbGxMRYsWMDVe/LkSZn3atu2LZKTk6GsrAwTE5Ni61y5cgXu7u4YMmQIgPzk6fHjx6Xel4+usc6dO2PFihV4/fo1N8P53Llz0NbWRqtWrbg6Xy4OXFCncOJ89+5dNG7cuHr1jlTq0OsaoGDU+fB1NnJ7xt27d9mCBQu40fSEKLraOGvs+fPnTENDg02ZMoXFxMSwEydOMD09PbZkyRKuTuFZOY6OjszGxoZdu3aN3bx5k3Xt2pWpq6uXOmts5cqV7K+//mLx8fHs/v37bN26dUxZWZnt3r27xGuKm43FGGPDhw9n/fv3546vXLnCNDQ0mJOTE7t+/Tp78uQJCw4OZkZGRszOzo5lZ2dzdU+cOMFUVFTYwIED2blz51hiYiL7999/2Zw5c5izs3OJsbi7uzMjIyN2/PhxlpCQwC5cuMCCgoIYY4y9efOGaWpqsunTp7NHjx6xgIAA1rBhw2JnjRXn3LlzTCQSMXNzc7Zs2TKpc2fPnmXKysps6dKl7O7du+z+/fvs4MGDbMGCBSXGmpqaylRUVFh0dDRX9ueffzJlZWV28OBB9ujRI+bj48Pq1asn9f4WF6NEImFdu3ZlVlZWLDQ0lCUmJrIrV66w+fPns3///ZcxxtiQIUOYtbU1u3XrFouKimIDBw5kWlpa5ZrJVRG3bt1it27dYra2tszFxYXdunWL3bt3jzt/7NgxZm5uzh3n5eWx1q1bs759+7KoqCh29uxZVr9+febl5cXVSUhIYBoaGmzOnDksJiaGbd26lQmFQnb27FmpZ7u5ubGffvqpxNj4mDVGiVAF7zV+/Hh29+7dSoiMkNqrNiZCjMk+fT4pKYn179+fiUQi1qRJE+bv71/m9PkFCxYwMzMzpqamxnR1dVnnzp3ZoUOHSo27pEQoPDycAZBavuPOnTvshx9+YPXq1WMqKiqsWbNmbOHChSwzM7PI9f/++y8bOnQoq1+/PhOJRMzMzIz9/PPP7OHDhyXGkpWVxTw8PJihoSFTVVVlZmZmbO/evdz548ePMzMzM6aurs4GDBjAdu3aVe5ESCwWM0NDQwaAxcfHFzl/9uxZZmdnx9TV1Zm2tjbr0KED27VrV4mxMpafLHp6ekqVzZkzh33zzTesTp06zNnZmW3cuLHMRIgxxtLT09m0adNYw4YNmYqKCjMyMmKurq7s6dOnjDHGEhMTmb29PVNXV2dGRkZsy5Yt5Z7SXhH431IuX34ZGxtz5/ft28cKt5M8fvyYff/990xdXZ3p6emxWbNmFVmK4MKFC8za2pqpqqqypk2bsn379kmdz8rKYjo6Oiw8PLzE2PhIhASMfeUouBoqPT0dOjo6GL7OBkGzIr/6PuHh4Rg1ahQSEhJgaWmJGzduVJupgIRUN9nZ2UhMTISpqWmJ4zMIqQ7u3LmDPn36ID4+Xmq2IKm47du34/jx4/jrr79KrFPaz4qC39/v378vMli9ImhlaRnl5eXB29sb3bp1Q0JCAoD8FTXv3LnDc2SEEEIqytLSEqtXr0ZiYiLfodQ6Kioq+P333/kOowgaLC2DhIQEjBo1CuHh4VyZnZ0dDhw4UKVL7hNCCJEfd3d3vkOolcaPH893CMWiFqFyYIzB398f1tbWXBIkFArh7e2NixcvUhJECCGE1FDUIlSGd+/eYfLkyQgK+rzmSdOmTREQEIBOnTrxGBkhhBBCKopahMoQExODw4cPc8fu7u6IioqiJIiQr6BgczMIITLi42cEJUJlsLOzw4IFC1C3bl0EBwdj3759RTbkI4SUTkVFBUD1WlafEFL9FKyqXbBxbVWgrrFCEhMT0aRJE6kPYdGiRZg4cSIaNWrEY2SE1FxCoRB169bldlrX0NCgLWcIIVIkEglSUlKgoaEBZeWqS08oEfofxhh27doFDw8PLFmyBPPmzePOqaioUBJESAUV7ElUkAwRQkhhSkpKaNKkSZX+oUSJEICUlBSMHz8eISEhAICFCxeib9++xW5ESAj5OgKBAIaGhmjQoEGxG2sSQoiqqqrUvndVoVokQlu3bsXatWuRnJwMKysr/P777+jQoUOJ9Q8fPoxFixbh8ePHaN68OVavXo1+/fp91bNDQ0Ph7u6O5ORkrmz8+PEwNzf/qvsRQkonFAqrtP+fEEJKw/tg6aCgIMycORNLlixBZGQkrKys4ODgUGLz+dWrVzFy5EiMGzcOt27dgpOTE5ycnHD37l2ZnivOk2DGjBlwdHTkkiA9PT2EhIRg+/bt0NDQqPBrI4QQQkj1xvteYx07dkT79u2xZcsWAPmDpYyMjDBt2jR4enoWqe/s7IzMzEycPHmSK+vUqROsra2xY8eOMp9XsFeJtoEa0pOzuXJHR0fs27ePG8dACCGEkOqjVu41lpubi4iICPTu3ZsrU1JSQu/evaW2sfhSeHi4VH0AcHBwKLF+SQqSIJFIhM2bN+P06dOUBBFCCCEKhtcxQqmpqRCLxdDX15cq19fXx4MHD4q9Jjk5udj6X47x+VJOTg5ycnK44/fv33Pft2rVCn/88QdatWqFDx8+fO3LIIQQQoicpaenA6j8RRerxWBpeVq1ahW8vb2LPXf//n107ty5iiMihBBCyNd68+YNdHR0Ku1+vCZCenp6EAqFePXqlVT5q1evSuymMjAwkKm+l5cXZs6cyR2npaXB2NgYT58+rdQ3ksguPT0dRkZGePbsWaX295KvQ59H9UGfRfVBn0X18f79ezRp0gT16tWr1PvymgipqqrC1tYW58+fh5OTE4D8wdLnz5/H1KlTi72mc+fOOH/+PGbMmMGVnTt3rsSWHZFIBJFIVKRcR0eH/lFXE9ra2vRZVCP0eVQf9FlUH/RZVB+Vvc4Q711jM2fOhJubG9q1a4cOHTpg06ZNyMzMxNixYwEAY8aMQaNGjbBq1SoAwC+//ILu3btj/fr16N+/Pw4dOoSbN29i165dfL4MQgghhNRAvCdCzs7OSElJweLFi5GcnAxra2ucPXuWGxD99OlTqezPzs4OgYGBWLhwIebPn4/mzZvjxIkTaN26NV8vgRBCCCE1FO+JEABMnTq1xK6wsLCwImXDhg3DsGHDvupZIpEIS5YsKba7jFQt+iyqF/o8qg/6LKoP+iyqD3l9FrwvqEgIIYQQwhfet9gghBBCCOELJUKEEEIIUViUCBFCCCFEYVEiRAghhBCFVSsToa1bt8LExARqamro2LEjbty4UWr9w4cPw8LCAmpqamjTpg1Onz5dRZHWfrJ8Frt370a3bt2gq6sLXV1d9O7du8zPjshG1v83Chw6dAgCgYBb+JRUnKyfRVpaGqZMmQJDQ0OIRCK0aNGCflZVElk/i02bNsHc3Bzq6uowMjKCh4cHsrOzqyja2uu///0vBg4ciIYNG0IgEODEiRNlXhMWFoa2bdtCJBLBzMwMvr6+sj+Y1TKHDh1iqqqqbO/evezevXtswoQJrG7duuzVq1fF1r9y5QoTCoVszZo17P79+2zhwoVMRUWFRUdHV3HktY+sn4WLiwvbunUru3XrFouJiWHu7u5MR0eHPX/+vIojr51k/TwKJCYmskaNGrFu3bqxwYMHV02wtZysn0VOTg5r164d69evH7t8+TJLTExkYWFhLCoqqoojr31k/SwCAgKYSCRiAQEBLDExkYWGhjJDQ0Pm4eFRxZHXPqdPn2YLFixgx44dYwDY8ePHS62fkJDANDQ02MyZM9n9+/fZ77//zoRCITt79qxMz611iVCHDh3YlClTuGOxWMwaNmzIVq1aVWz94cOHs/79+0uVdezYkU2cOFGucSoCWT+LwvLy8piWlhbz8/OTV4gK5Ws+j7y8PGZnZ8f27NnD3NzcKBGqJLJ+Ftu3b2dNmzZlubm5VRWiwpD1s5gyZQrr2bOnVNnMmTNZly5d5BqnoilPIjR37lz27bffSpU5OzszB4f/b+/uY5q6/j+Avynah9VW4hjSSn0ABzNOZaAuoAtTceCmMp/QSRAVZRMRs0Un8amgA9mmLGp0ipugjghqdJqhMFFJAN1UpLAIFnnSLYLGaUAUBNrP74+F+7UCzqLCfu3nldw/eu45537uPTT3k3NPuX5mHcuiHo01NTUhPz8fvr6+QplIJIKvry8uXLjQbpsLFy6Y1AcAPz+/Duuz59OZsXjao0eP0Nzc/NJfsGeNOjseGzZsgIODA0JDQ7siTKvQmbE4ceIEvLy8sHTpUvTt2xdvv/024uLiYDAYuipsi9SZsfD29kZ+fr7w+KyiogInT57Ehx9+2CUxs/95Wffv/8R/ln5Z7t69C4PBILyeo1Xfvn1x7dq1dtvU1NS0W7+mpuaVxWkNOjMWT1u1ahXUanWbP3Rmvs6MR25uLn788UfodLouiNB6dGYsKioqcPbsWQQFBeHkyZMoKytDeHg4mpubodVquyJsi9SZsZg7dy7u3r2LsWPHgojQ0tKCzz77DKtXr+6KkNkTOrp/19XVoaGhATKZ7Ln6sagZIWY54uPjkZqaimPHjkEqlXZ3OFbnwYMHCA4Oxp49e2Bvb9/d4Vg9o9EIBwcHJCYmwtPTE7Nnz8aaNWuwa9eu7g7N6mRnZyMuLg47d+7ElStXcPToUaSnp2Pjxo3dHRrrJIuaEbK3t4etrS1u375tUn779m04Ojq228bR0dGs+uz5dGYsWm3evBnx8fHIysrC8OHDX2WYVsPc8SgvL0dVVRWmTJkilBmNRgBAjx49oNfr4eLi8mqDtlCd+W6oVCr07NkTtra2QtmQIUNQU1ODpqYmiMXiVxqzperMWKxbtw7BwcFYtGgRAGDYsGF4+PAhwsLCsGbNGpOXhLNXq6P7t1KpfO7ZIMDCZoTEYjE8PT1x5swZocxoNOLMmTPw8vJqt42Xl5dJfQA4ffp0h/XZ8+nMWADAN998g40bNyIjIwMjR47silCtgrnj8dZbb+GPP/6ATqcTtqlTp2LcuHHQ6XTQaDRdGb5F6cx3Y8yYMSgrKxOSUQAoLS2FSqXiJOgFdGYsHj161CbZaU1QiV/d2aVe2v3bvHXc/32pqakkkUgoOTmZiouLKSwsjOzs7KimpoaIiIKDgykqKkqon5eXRz169KDNmzdTSUkJabVa/vn8S2LuWMTHx5NYLKYjR45QdXW1sD148KC7TsGimDseT+Nfjb085o7FzZs3SaFQUEREBOn1evrll1/IwcGBvvrqq+46BYth7lhotVpSKBR08OBBqqiooF9//ZVcXFwoMDCwu07BYjx48IAKCgqooKCAAFBCQgIVFBTQjRs3iIgoKiqKgoODhfqtP59fuXIllZSU0I4dO/jn8622b99O/fv3J7FYTKNHj6bffvtN2Ofj40MhISEm9Q8dOkSurq4kFotp6NChlJ6e3sURWy5zxmLAgAEEoM2m1Wq7PnALZe5340mcCL1c5o7F+fPn6d133yWJRELOzs4UGxtLLS0tXRy1ZTJnLJqbmyk6OppcXFxIKpWSRqOh8PBwun//ftcHbmHOnTvX7j2g9fqHhISQj49Pmzbu7u4kFovJ2dmZkpKSzD6uDRHP5THGGGPMOlnUGiHGGGOMMXNwIsQYY4wxq8WJEGOMMcasFidCjDHGGLNanAgxxhhjzGpxIsQYY4wxq8WJEGOMMcasFidCjDETycnJsLOz6+4wOs3GxgY///zzM+vMnz8fH3/8cZfEwxj7b+NEiDELNH/+fNjY2LTZysrKujs0JCcnC/GIRCI4OTlhwYIFuHPnzkvpv7q6GpMmTQIAVFVVwcbGBjqdzqTO1q1bkZyc/FKO15Ho6GjhPG1tbaHRaBAWFoZ79+6Z1Q8nbYy9Whb19nnG2P/4+/sjKSnJpOyNN97opmhMKZVK6PV6GI1GFBYWYsGCBbh16xYyMzNfuO+O3hr+pN69e7/wcZ7H0KFDkZWVBYPBgJKSEixcuBC1tbVIS0vrkuMzxv4dzwgxZqEkEgkcHR1NNltbWyQkJGDYsGGQy+XQaDQIDw9HfX19h/0UFhZi3LhxUCgUUCqV8PT0xOXLl4X9ubm5eO+99yCTyaDRaBAZGYmHDx8+MzYbGxs4OjpCrVZj0qRJiIyMRFZWFhoaGmA0GrFhwwY4OTlBIpHA3d0dGRkZQtumpiZERERApVJBKpViwIAB2LRpk0nfrY/GBg0aBAB45513YGNjg/fffx+A6SxLYmIi1Gq1yZvdASAgIAALFy4UPh8/fhweHh6QSqVwdnZGTEwMWlpannmePXr0gKOjI/r16wdfX1/MmjULp0+fFvYbDAaEhoZi0KBBkMlkcHNzw9atW4X90dHR2LdvH44fPy7MLmVnZwMA/vzzTwQGBsLOzg59+vRBQEAAqqqqnhkPY6wtToQYszIikQjbtm3D1atXsW/fPpw9exZffvllh/WDgoLg5OSES5cuIT8/H1FRUejZsycAoLy8HP7+/pgxYwaKioqQlpaG3NxcREREmBWTTCaD0WhES0sLtm7dii1btmDz5s0oKiqCn58fpk6diuvXrwMAtm3bhhMnTuDQoUPQ6/VISUnBwIED2+334sWLAICsrCxUV1fj6NGjberMmjULf//9N86dOyeU3bt3DxkZGQgKCgIA5OTkYN68eVi+fDmKi4uxe/duJCcnIzY29rnPsaqqCpmZmRCLxUKZ0WiEk5MTDh8+jOLiYqxfvx6rV6/GoUOHAAArVqxAYGAg/P39UV1djerqanh7e6O5uRl+fn5QKBTIyclBXl4eevXqBX9/fzQ1NT13TIwxwCLfPs+YtQsJCSFbW1uSy+XCNnPmzHbrHj58mF5//XXhc1JSEvXu3Vv4rFAoKDk5ud22oaGhFBYWZlKWk5NDIpGIGhoa2m3zdP+lpaXk6upKI0eOJCIitVpNsbGxJm1GjRpF4eHhRES0bNkyGj9+PBmNxnb7B0DHjh0jIqLKykoCQAUFBSZ1QkJCKCAgQPgcEBBACxcuFD7v3r2b1Go1GQwGIiKaMGECxcXFmfRx4MABUqlU7cZARKTVakkkEpFcLiepVCq8STshIaHDNkRES5cupRkzZnQYa+ux3dzcTK7B48ePSSaTUWZm5jP7Z4yZ4jVCjFmocePG4fvvvxc+y+VyAP/MjmzatAnXrl1DXV0dWlpa0NjYiEePHuG1115r088XX3yBRYsW4cCBA8LjHRcXFwD/PDYrKipCSkqKUJ+IYDQaUVlZiSFDhrQbW21tLXr16gWj0YjGxkaMHTsWP/zwA+rq6nDr1i2MGTPGpP6YMWNQWFgI4J/HWhMnToSbmxv8/f0xefJkfPDBBy90rYKCgrB48WLs3LkTEokEKSkpmDNnDkQikXCeeXl5JjNABoPhmdcNANzc3HDixAk0Njbip59+gk6nw7Jly0zq7NixA3v37sXNmzfR0NCApqYmuLu7PzPewsJClJWVQaFQmJQ3NjaivLy8E1eAMevFiRBjFkoul2Pw4MEmZVVVVZg8eTKWLFmC2NhY9OnTB7m5uQgNDUVTU1O7N/To6GjMnTsX6enpOHXqFLRaLVJTUzFt2jTU19fj008/RWRkZJt2/fv37zA2hUKBK1euQCQSQaVSQSaTAQDq6ur+9bw8PDxQWVmJU6dOISsrC4GBgfD19cWRI0f+tW1HpkyZAiJCeno6Ro0ahZycHHz33XfC/vr6esTExGD69Olt2kql0g77FYvFwhjEx8fjo48+QkxMDDZu3AgASE1NxYoVK7BlyxZ4eXlBoVDg22+/xe+///7MeOvr6+Hp6WmSgLb6ryyIZ+z/C06EGLMi+fn5MBqN2LJlizDb0boe5VlcXV3h6uqKzz//HJ988gmSkpIwbdo0eHh4oLi4uE3C9W9EIlG7bZRKJdRqNfLy8uDj4yOU5+XlYfTo0Sb1Zs+ejdmzZ2PmzJnw9/fHvXv30KdPH5P+WtfjGAyGZ8YjlUoxffp0pKSkoKysDG5ubvDw8BD2e3h4QK/Xm32eT1u7di3Gjx+PJUuWCOfp7e2N8PBwoc7TMzpisbhN/B4eHkhLS4ODgwOUSuULxcSYtePF0oxZkcGDB6O5uRnbt29HRUUFDhw4gF27dnVYv6GhAREREcjOzsaNGzeQl5eHS5cuCY+8Vq1ahfPnzyMiIgI6nQ7Xr1/H8ePHzV4s/aSVK1fi66+/RlpaGvR6PaKioqDT6bB8+XIAQEJCAg4ePIhr166htLQUhw8fhqOjY7v/BNLBwQEymQwZGRm4ffs2amtrOzxuUFAQ0tPTsXfvXmGRdKv169dj//79iImJwdWrV1FSUoLU1FSsXbvWrHPz8vLC8OHDERcXBwB48803cfnyZWRmZqK0tBTr1q3DpUuXTNoMHDgQRUVF0Ov1uHv3LpqbmxEUFAR7e3sEBAQgJycHlZWVyM7ORmRkJP766y+zYmLM6nX3IiXG2MvX3gLbVgkJCaRSqUgmk5Gfnx/t37+fAND9+/eJyHQx8+PHj2nOnDmk0WhILBaTWq2miIgIk4XQFy9epIkTJ1KvXr1ILpfT8OHD2yx2ftLTi6WfZjAYKDo6mvr160c9e/akESNG0KlTp4T9iYmJ5O7uTnK5nJRKJU2YMIGuXLki7McTi6WJiPbs2UMajYZEIhH5+Ph0eH0MBgOpVCoCQOXl5W3iysjIIG9vb5LJZKRUKmn06NGUmJjY4XlotVoaMWJEm/KDBw+SRCKhmzdvUmNjI82fP5969+5NdnZ2tGTJEoqKijJpd+fOHeH6AqBz584REVF1dTXNmzeP7O3tSSKRkLOzMy1evJhqa2s7jIkx1pYNEVH3pmKMMcYYY92DH40xxhhjzGpxIsQYY4wxq8WJEGOMMcasFidCjDHGGLNanAgxxhhjzGpxIsQYY4wxq8WJEGOMMcasFidCjDHGGLNanAgxxhhjzGpxIsQYY4wxq8WJEGOMMcasFidCjDHGGLNa/wdUlyQgUXXtegAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "val_scores_cnn = []\n",
    "\n",
    "# Define the CNN model\n",
    "inputs = Input(shape=(200,))\n",
    "embedding = Embedding(input_dim=max_words, output_dim=256, input_length=200)(inputs)\n",
    "conv1 = Conv1D(filters=256, kernel_size=3, activation='relu')(embedding)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv2 = Conv1D(filters=256, kernel_size=3, activation='relu')(pool1)\n",
    "pool2 = GlobalMaxPooling1D()(conv2)\n",
    "dense1 = Dense(64, activation='relu')(pool2)\n",
    "dropout = Dropout(0.20)(dense1)\n",
    "outputs = Dense(6, activation='sigmoid')(dropout)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_val_scores_f1 = []\n",
    "cnn_val_scores_precision = []\n",
    "cnn_val_scores_recall = []\n",
    "cnn_val_scores_accuracy = []\n",
    "cnn_roc_auc = []\n",
    "cnn_fpr = []\n",
    "cnn_tpr = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    print(train_index)\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # Adjust the input data to match max_len\n",
    "    X_train_fold = pad_sequences_custom(X_train_fold, 200)\n",
    "    X_val_fold = pad_sequences_custom(X_val_fold, 200)\n",
    "    \n",
    "    # Define callbacks\n",
    "    checkpoint = ModelCheckpoint('best_model_cnn.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=2, mode='min', verbose=1)\n",
    "\n",
    "    # Train the model\n",
    "    history_cnn = model.fit(X_train_fold, y_train_fold, epochs=5, batch_size=128, validation_data=(X_val_fold, y_val_fold), callbacks=[checkpoint, early_stop])\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_preds = model.predict(X_val_fold)\n",
    "    val_preds_binary = (val_preds > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val_fold, val_preds_binary, average='macro')\n",
    "    precision = precision_score(y_val_fold, val_preds_binary, average='macro')\n",
    "    recall = recall_score(y_val_fold, val_preds_binary, average='macro')\n",
    "    accuracy = accuracy_score(y_val_fold, val_preds_binary)\n",
    "\n",
    "    cnn_val_scores_f1.append(f1)\n",
    "    cnn_val_scores_precision.append(precision)\n",
    "    cnn_val_scores_recall.append(recall)\n",
    "    cnn_val_scores_accuracy.append(accuracy)\n",
    "    # Calculate ROC AUC for all classes together\n",
    "    auc = roc_auc_score(y_val_fold, val_preds, average='macro')\n",
    "    fpr, tpr, _ = roc_curve(y_val_fold.ravel(), val_preds.ravel())\n",
    "    cnn_roc_auc.append(auc)\n",
    "    cnn_fpr.append(fpr)\n",
    "    cnn_tpr.append(tpr)\n",
    "\n",
    "# Plot ROC curves for all classes together\n",
    "plt.figure()\n",
    "\n",
    "# Plot each fold's ROC curve\n",
    "for i in range(len(cnn_fpr)):  # Each fold\n",
    "    plt.plot(cnn_fpr[i], cnn_tpr[i], lw=2, label=f'Fold {i+1} ROC curve (area = {cnn_roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for LSTM Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "Average F1 Score: 0.3725667195578997\n",
      "Average Precision: 0.40185090453052835\n",
      "Average Recall: 0.35539936328539995\n",
      "Average Accuracy: 0.921902380068856\n",
      "CNN\n",
      "Average F1 Score: 0.5087247180668936\n",
      "Average Precision: 0.5912102117206407\n",
      "Average Recall: 0.4754613857103857\n",
      "Average Accuracy: 0.9350639193459559\n"
     ]
    }
   ],
   "source": [
    "avg_f1_lstm = np.mean(lstm_val_scores_f1)\n",
    "avg_precision_lstm = np.mean(lstm_val_scores_precision)\n",
    "avg_recall_lstm = np.mean(lstm_val_scores_recall)\n",
    "avg_accuracy_lstm = np.mean(lstm_val_scores_accuracy)\n",
    "\n",
    "print(\"LSTM\")\n",
    "print('Average F1 Score:', avg_f1_lstm)\n",
    "print('Average Precision:', avg_precision_lstm)\n",
    "print('Average Recall:', avg_recall_lstm)\n",
    "print('Average Accuracy:', avg_accuracy_lstm)\n",
    "\n",
    "avg_f1_cnn = np.mean(cnn_val_scores_f1)\n",
    "avg_precision_cnn = np.mean(cnn_val_scores_precision)\n",
    "avg_recall_cnn = np.mean(cnn_val_scores_recall)\n",
    "avg_accuracy_cnn = np.mean(cnn_val_scores_accuracy)\n",
    "\n",
    "print(\"CNN\")\n",
    "print('Average F1 Score:', avg_f1_cnn)\n",
    "print('Average Precision:', avg_precision_cnn)\n",
    "print('Average Recall:', avg_recall_cnn)\n",
    "print('Average Accuracy:', avg_accuracy_cnn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Regresja_Liniowa': {'accuracy': [], 'precision': [], 'recall': [], 'f1_score': []}, 'Naive_Bayes': {'accuracy': [], 'precision': [], 'recall': [], 'f1_score': []}, 'CNN': {'accuracy': [0.9090695488721805, 0.9339600470035253, 0.9621621621621622], 'precision': [0.5282858388057433, 0.505025956228482, 0.7403188401276964], 'recall': [0.2915568753440226, 0.5374607126739689, 0.5973665691131654], 'f1_score': [0.3621482228928256, 0.5205841610303548, 0.6434417702775003]}, 'LSTM': {'accuracy': [0.9161184210526315, 0.9163337250293772, 0.9332549941245594], 'precision': [0.39604136712788174, 0.38226240328559663, 0.42724894317810685], 'recall': [0.257470168536678, 0.39139807112157343, 0.4173298501979484], 'f1_score': [0.3118518788841789, 0.38421632969902264, 0.42163195009049764]}}\n"
     ]
    }
   ],
   "source": [
    "results_metrics = {\n",
    "    'Regresja_Liniowa': {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1_score': []\n",
    "    },\n",
    "    'Naive_Bayes': {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1_score': []\n",
    "    },\n",
    "    'CNN': {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1_score': []\n",
    "    },\n",
    "    'LSTM': {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1_score': []\n",
    "    }\n",
    "}\n",
    "\n",
    "results_metrics['LSTM']['accuracy']=lstm_val_scores_accuracy\n",
    "results_metrics['LSTM']['precision']=lstm_val_scores_precision\n",
    "results_metrics['LSTM']['recall']=lstm_val_scores_recall\n",
    "results_metrics['LSTM']['f1_score']=lstm_val_scores_f1\n",
    "\n",
    "results_metrics['CNN']['accuracy']=cnn_val_scores_accuracy\n",
    "results_metrics['CNN']['precision']=cnn_val_scores_precision\n",
    "results_metrics['CNN']['recall']=cnn_val_scores_recall\n",
    "results_metrics['CNN']['f1_score']=cnn_val_scores_f1\n",
    "\n",
    "print(results_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-test dla f1_score (LSTM vs CNN): t-stat = -2.750011801476057, p-value = 0.11070191000890009\n",
      "t-test dla accuracy (LSTM vs CNN): t-stat = -1.23967043894027, p-value = 0.3408229925958176\n",
      "t-test dla precision (LSTM vs CNN): t-stat = -3.058335046748232, p-value = 0.09234283896924816\n",
      "t-test dla recall (LSTM vs CNN): t-stat = -2.722974271282715, p-value = 0.11255211675563152\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_value = ttest_rel(results_metrics['LSTM']['f1_score'], results_metrics['CNN']['f1_score'])\n",
    "print(f't-test dla f1_score (LSTM vs CNN): t-stat = {t_stat}, p-value = {p_value}')\n",
    "\n",
    "t_stat, p_value = ttest_rel(results_metrics['LSTM']['accuracy'], results_metrics['CNN']['accuracy'])\n",
    "print(f't-test dla accuracy (LSTM vs CNN): t-stat = {t_stat}, p-value = {p_value}')\n",
    "\n",
    "t_stat, p_value = ttest_rel(results_metrics['LSTM']['precision'], results_metrics['CNN']['precision'])\n",
    "print(f't-test dla precision (LSTM vs CNN): t-stat = {t_stat}, p-value = {p_value}')\n",
    "\n",
    "t_stat, p_value = ttest_rel(results_metrics['LSTM']['recall'], results_metrics['CNN']['recall'])\n",
    "print(f't-test dla recall (LSTM vs CNN): t-stat = {t_stat}, p-value = {p_value}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
