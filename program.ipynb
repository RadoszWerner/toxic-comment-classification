{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T18:32:04.376421Z",
     "start_time": "2024-05-23T18:32:03.009793Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.core.framework.types_pb2' has no attribute 'SerializedDType'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_26540\\2331349026.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcallbacks\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModelCheckpoint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mEarlyStopping\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocessing\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mTokenizer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpad_sequences\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\keras\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \"\"\"\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdistribute\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmodels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minput_layer\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mInput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msequential\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSequential\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\keras\\models\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunctional\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mFunctional\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msequential\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSequential\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtraining\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\keras\\engine\\functional.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mwarnings\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mv2\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mbackend\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_sys\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 41\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtools\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmodule_util\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_module_util\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     42\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlazy_loader\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLazyLoader\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_LazyLoader\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;31m# Bring in subpackages.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 42\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     43\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdistribute\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[1;31m# from tensorflow.python import keras\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;31m# pylint: disable=unused-import\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mexperimental\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset_ops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mAUTOTUNE\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset_ops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[1;31m# pylint: disable=unused-import\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 96\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mservice\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     97\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatching\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdense_to_ragged_batch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatching\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdense_to_sparse_batch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    417\u001B[0m \"\"\"\n\u001B[0;32m    418\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 419\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_service_ops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdistribute\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    420\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_service_ops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mfrom_dataset_id\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    421\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_service_ops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mregister_dataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprotobuf\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdata_service_pb2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtf2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcompression_ops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mservice\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_pywrap_server_lib\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mservice\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_pywrap_utils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;31m# ==============================================================================\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;34m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mstructure\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mgen_experimental_dataset_ops\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mged_ops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mwrapt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcomposite_tensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     32\u001B[0m \"\"\"\n\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msparse_tensor\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_sparse_tensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_pywrap_utils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtf2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcomposite_tensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mconstant_op\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtypes_pb2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meager\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meager\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mexecute\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mop_callbacks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpywrap_tfe\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meager\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtensor_shape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     44\u001B[0m     \u001B[0mtrace\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTraceType\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m     \u001B[0mtrace_type\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSerializable\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 46\u001B[1;33m     metaclass=DTypeMeta):\n\u001B[0m\u001B[0;32m     47\u001B[0m   \"\"\"Represents the type of the elements in a `Tensor`.\n\u001B[0;32m     48\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\u001B[0m in \u001B[0;36mDType\u001B[1;34m()\u001B[0m\n\u001B[0;32m    200\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    201\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 202\u001B[1;33m   \u001B[1;32mdef\u001B[0m \u001B[0mexperimental_type_proto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mType\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtypes_pb2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSerializedDType\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    203\u001B[0m     \u001B[1;34m\"\"\"Returns the type of proto associated with DType serialization.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    204\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtypes_pb2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSerializedDType\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'tensorflow.core.framework.types_pb2' has no attribute 'SerializedDType'"
     ]
    }
   ],
   "source": [
    "from keras import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, Bidirectional, GlobalMaxPool1D, LSTM\n",
    "\n",
    "from prepare_data import DataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:40:46.270598Z",
     "start_time": "2024-05-23T16:38:21.674570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id                                       comment_text  \\\n",
      "0       0000997932d777bf  explanation\\nwhy the edits made under my usern...   \n",
      "1       000103f0d9cfb60f  d'aww! he matches this background colour i'm s...   \n",
      "2       000113f07ec002fd  hey man, i'm really not trying to edit war. it...   \n",
      "3       0001b41b1c6bb37e  \"\\nmore\\ni can't make any real suggestions on ...   \n",
      "4       0001d958c54c6e35  you, sir, are my hero. any chance you remember...   \n",
      "...                  ...                                                ...   \n",
      "159566  ffe987279560d7ff  \":::::and for the second time of asking, when ...   \n",
      "159567  ffea4adeee384e90  you should be ashamed of yourself \\n\\nthat is ...   \n",
      "159568  ffee36eab5c267c9  spitzer \\n\\numm, theres no actual article for ...   \n",
      "159569  fff125370e4aaaf3  and it looks like it was actually you who put ...   \n",
      "159570  fff46fc426af1f9a  \"\\nand ... i really don't think you understand...   \n",
      "\n",
      "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0           0             0        0       0       0              0  \n",
      "1           0             0        0       0       0              0  \n",
      "2           0             0        0       0       0              0  \n",
      "3           0             0        0       0       0              0  \n",
      "4           0             0        0       0       0              0  \n",
      "...       ...           ...      ...     ...     ...            ...  \n",
      "159566      0             0        0       0       0              0  \n",
      "159567      0             0        0       0       0              0  \n",
      "159568      0             0        0       0       0              0  \n",
      "159569      0             0        0       0       0              0  \n",
      "159570      0             0        0       0       0              0  \n",
      "\n",
      "[159571 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "prepData = DataPreprocessor(\"jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "\n",
    "prepData.load_data()\n",
    "prepData.preprocess_data()\n",
    "X, y = prepData.get_XY()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:41:12.528766Z",
     "start_time": "2024-05-23T16:41:01.476696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (127656, 150)\n",
      "X_test (31915, 150)\n",
      "y_train (127656, 6)\n",
      "y_test (31915, 6)\n"
     ]
    }
   ],
   "source": [
    "# Zmniana wartości klas w binarne\n",
    "\n",
    "mlb = LabelBinarizer()\n",
    "y_binary = mlb.fit_transform(y)\n",
    "\n",
    "X_notoken = X\n",
    "\n",
    "# Tokenizacja danych tekstowych\n",
    "max_words = 20000\n",
    "max_len = 150\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_seq, maxlen=max_len)\n",
    "\n",
    "# Podział metodą train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"y_test\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# LR preparation\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions = {\n",
    "    'C': uniform(loc=0.01, scale=10),  # Search C values between 0.01 and 10\n",
    "    'penalty': ['l2']  # Search over l1 and l2 regularization\n",
    "}\n",
    "\n",
    "random_search_LR = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(solver='lbfgs', max_iter=1000, verbose=True),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=4,  # Number of random parameter settings to try\n",
    "    cv=3,  # Number of cross-validation folds\n",
    "    random_state=42,\n",
    "    scoring='f1'  # Optimize for F1 score\n",
    ")\n",
    "\n",
    "def LR_Training(y_label):\n",
    "    X_train_LR, X_test_LR, y_train_LR, y_test_LR = train_test_split(X_padded, y_label, test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train_LR = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_train_LR]\n",
    "    X_test_LR = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_test_LR]\n",
    "    \n",
    "    tfidf_vec = TfidfVectorizer(max_df=0.7)\n",
    "    X_train_LR_vec = tfidf_vec.fit_transform(X_train_LR)\n",
    "    X_test_LR_vec = tfidf_vec.transform(X_test_LR)\n",
    "    \n",
    "    random_search_LR.fit(X_train_LR_vec, y_train_LR.values.ravel())\n",
    "    \n",
    "    best_estimator = random_search_LR.best_estimator_\n",
    "    print('Best parameters:', best_estimator.get_params())\n",
    "    \n",
    "    predictions = best_estimator.predict(X_test_LR_vec)\n",
    "    print(confusion_matrix(y_test_LR, predictions))\n",
    "    print(classification_report(y_test_LR, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:05:45.467908Z",
     "start_time": "2024-05-23T15:05:45.449914Z"
    }
   },
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training\n",
      "Toxic comments:\n",
      "Best parameters: {'C': 9.51714306409916, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': True, 'warm_start': False}\n",
      "[[28528   331]\n",
      " [  962  2094]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     28859\n",
      "           1       0.86      0.69      0.76      3056\n",
      "\n",
      "    accuracy                           0.96     31915\n",
      "   macro avg       0.92      0.84      0.87     31915\n",
      "weighted avg       0.96      0.96      0.96     31915\n",
      "\n",
      "Severe toxic comments:\n",
      "Best parameters: {'C': 9.51714306409916, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': True, 'warm_start': False}\n",
      "[[31510    84]\n",
      " [  226    95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     31594\n",
      "           1       0.53      0.30      0.38       321\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.76      0.65      0.69     31915\n",
      "weighted avg       0.99      0.99      0.99     31915\n",
      "\n",
      "Obscene comments:\n",
      "Best parameters: {'C': 9.51714306409916, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': True, 'warm_start': False}\n",
      "[[30051   149]\n",
      " [  554  1161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     30200\n",
      "           1       0.89      0.68      0.77      1715\n",
      "\n",
      "    accuracy                           0.98     31915\n",
      "   macro avg       0.93      0.84      0.88     31915\n",
      "weighted avg       0.98      0.98      0.98     31915\n",
      "\n",
      "Threat comments:\n",
      "Best parameters: {'C': 9.51714306409916, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': True, 'warm_start': False}\n",
      "[[31826    15]\n",
      " [   60    14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31841\n",
      "           1       0.48      0.19      0.27        74\n",
      "\n",
      "    accuracy                           1.00     31915\n",
      "   macro avg       0.74      0.59      0.64     31915\n",
      "weighted avg       1.00      1.00      1.00     31915\n",
      "\n",
      "Insult comments:\n",
      "Best parameters: {'C': 7.3299394181140505, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': True, 'warm_start': False}\n",
      "[[30064   237]\n",
      " [  707   907]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     30301\n",
      "           1       0.79      0.56      0.66      1614\n",
      "\n",
      "    accuracy                           0.97     31915\n",
      "   macro avg       0.88      0.78      0.82     31915\n",
      "weighted avg       0.97      0.97      0.97     31915\n",
      "\n",
      "Identity hate comments:\n",
      "Best parameters: {'C': 9.51714306409916, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': True, 'warm_start': False}\n",
      "[[31586    35]\n",
      " [  215    79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     31621\n",
      "           1       0.69      0.27      0.39       294\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.84      0.63      0.69     31915\n",
      "weighted avg       0.99      0.99      0.99     31915\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "\n",
    "print(\"Logistic Regression Training\")\n",
    "print(\"Toxic comments:\")\n",
    "LR_Training(y[[\"toxic\"]])\n",
    "print(\"Severe toxic comments:\")\n",
    "LR_Training(y[[\"severe_toxic\"]])\n",
    "print(\"Obscene comments:\")\n",
    "LR_Training(y[[\"obscene\"]])\n",
    "print(\"Threat comments:\")\n",
    "LR_Training(y[[\"threat\"]])\n",
    "print(\"Insult comments:\")\n",
    "LR_Training(y[[\"insult\"]])\n",
    "print(\"Identity hate comments:\")\n",
    "LR_Training(y[[\"identity_hate\"]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:14:20.509158Z",
     "start_time": "2024-05-23T15:09:49.073041Z"
    }
   },
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# NB Preparation\n",
    "\n",
    "param_distributions = {\n",
    "    'alpha': uniform(loc=0, scale=1),  # Search alpha values between 0 and 1\n",
    "    'fit_prior': [True, False]  # Whether to learn class prior probabilities or not\n",
    "}\n",
    "\n",
    "random_search_NB = RandomizedSearchCV(\n",
    "    estimator=MultinomialNB(),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=4,  # Number of random parameter settings to try\n",
    "    cv=3,  # Number of cross-validation folds\n",
    "    random_state=42,\n",
    "    scoring='f1'  # Optimize for F1 score\n",
    ")\n",
    "\n",
    "def NB_Training(y_label):\n",
    "    X_train_NB, X_test_NB, y_train_NB, y_test_NB = train_test_split(X_padded, y_label, test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train_NB = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_train_NB]\n",
    "    X_test_NB = [' '.join(tokenizer.sequences_to_texts([comment])[0].split()) for comment in X_test_NB]\n",
    "    \n",
    "    tfidf_vec = TfidfVectorizer(max_df=0.7)\n",
    "    X_train_NB_vec = tfidf_vec.fit_transform(X_train_NB)\n",
    "    X_test_NB_vec = tfidf_vec.transform(X_test_NB)\n",
    "    \n",
    "    random_search_NB.fit(X_train_NB_vec, y_train_NB.values.ravel())\n",
    "    \n",
    "    best_estimator = random_search_NB.best_estimator_\n",
    "    print('Best parameters:', best_estimator.get_params())\n",
    "    \n",
    "    predictions = best_estimator.predict(X_test_NB_vec)\n",
    "    print(confusion_matrix(y_test_NB, predictions))\n",
    "    print(classification_report(y_test_NB, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:19:47.517059Z",
     "start_time": "2024-05-23T15:19:47.490025Z"
    }
   },
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Training\n",
      "Toxic comments:\n",
      "Best parameters: {'C': 9.51714306409916, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': True, 'warm_start': False}\n",
      "[[28854     5]\n",
      " [ 2947   109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     28859\n",
      "           1       0.96      0.04      0.07      3056\n",
      "\n",
      "    accuracy                           0.91     31915\n",
      "   macro avg       0.93      0.52      0.51     31915\n",
      "weighted avg       0.91      0.91      0.87     31915\n",
      "\n",
      "Severe toxic comments:\n",
      "Best parameters: {'C': 9.51714306409916, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': True, 'warm_start': False}\n",
      "[[31516    78]\n",
      " [  285    36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     31594\n",
      "           1       0.32      0.11      0.17       321\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.65      0.55      0.58     31915\n",
      "weighted avg       0.98      0.99      0.99     31915\n",
      "\n",
      "Obscene comments:\n",
      "Best parameters: {'C': 9.51714306409916, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': True, 'warm_start': False}\n",
      "[[30170    30]\n",
      " [ 1631    84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     30200\n",
      "           1       0.74      0.05      0.09      1715\n",
      "\n",
      "    accuracy                           0.95     31915\n",
      "   macro avg       0.84      0.52      0.53     31915\n",
      "weighted avg       0.94      0.95      0.93     31915\n",
      "\n",
      "Threat comments:\n",
      "Best parameters: {'C': 9.51714306409916, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': True, 'warm_start': False}\n",
      "[[31733   108]\n",
      " [   68     6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31841\n",
      "           1       0.05      0.08      0.06        74\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.53      0.54      0.53     31915\n",
      "weighted avg       1.00      0.99      1.00     31915\n",
      "\n",
      "Insult comments:\n",
      "Best parameters: {'C': 9.51714306409916, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': True, 'warm_start': False}\n",
      "[[30272    29]\n",
      " [ 1529    85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     30301\n",
      "           1       0.75      0.05      0.10      1614\n",
      "\n",
      "    accuracy                           0.95     31915\n",
      "   macro avg       0.85      0.53      0.54     31915\n",
      "weighted avg       0.94      0.95      0.93     31915\n",
      "\n",
      "Identity hate comments:\n",
      "Best parameters: {'C': 9.51714306409916, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': True, 'warm_start': False}\n",
      "[[31586    35]\n",
      " [  215    79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     31621\n",
      "           1       0.69      0.27      0.39       294\n",
      "\n",
      "    accuracy                           0.99     31915\n",
      "   macro avg       0.84      0.63      0.69     31915\n",
      "weighted avg       0.99      0.99      0.99     31915\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "print(\"Naive Bayes Training\")\n",
    "print(\"Toxic comments:\")\n",
    "NB_Training(y[[\"toxic\"]])\n",
    "print(\"Severe toxic comments:\")\n",
    "NB_Training(y[[\"severe_toxic\"]])\n",
    "print(\"Obscene comments:\")\n",
    "NB_Training(y[[\"obscene\"]])\n",
    "print(\"Threat comments:\")\n",
    "NB_Training(y[[\"threat\"]])\n",
    "print(\"Insult comments:\")\n",
    "NB_Training(y[[\"insult\"]])\n",
    "print(\"Identity hate comments:\")\n",
    "NB_Training(y[[\"identity_hate\"]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:20:58.583490Z",
     "start_time": "2024-05-23T15:19:50.671817Z"
    }
   },
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.core.framework.types_pb2' has no attribute 'SerializedDType'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_26540\\2940760974.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mbackend\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mK\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mf1_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[1;31m# Calculate the true positives, false positives, and false negatives\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mtrue_positives\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mK\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mK\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mround\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mK\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\keras\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \"\"\"\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdistribute\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmodels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minput_layer\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mInput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msequential\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSequential\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\keras\\models\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunctional\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mFunctional\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msequential\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSequential\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtraining\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\keras\\engine\\functional.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mwarnings\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mv2\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mbackend\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_sys\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 41\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtools\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmodule_util\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_module_util\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     42\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlazy_loader\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLazyLoader\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_LazyLoader\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;31m# Bring in subpackages.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 42\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     43\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdistribute\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[1;31m# from tensorflow.python import keras\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;31m# pylint: disable=unused-import\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mexperimental\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset_ops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mAUTOTUNE\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset_ops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[1;31m# pylint: disable=unused-import\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 96\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mservice\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     97\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatching\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdense_to_ragged_batch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatching\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdense_to_sparse_batch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    417\u001B[0m \"\"\"\n\u001B[0;32m    418\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 419\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_service_ops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdistribute\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    420\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_service_ops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mfrom_dataset_id\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    421\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_service_ops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mregister_dataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprotobuf\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdata_service_pb2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtf2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcompression_ops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mservice\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_pywrap_server_lib\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mservice\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_pywrap_utils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;31m# ==============================================================================\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;34m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mstructure\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mgen_experimental_dataset_ops\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mged_ops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mwrapt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcomposite_tensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     32\u001B[0m \"\"\"\n\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msparse_tensor\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_sparse_tensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_pywrap_utils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtf2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcomposite_tensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mconstant_op\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtypes_pb2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meager\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meager\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mexecute\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mop_callbacks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpywrap_tfe\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0meager\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtensor_shape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     44\u001B[0m     \u001B[0mtrace\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTraceType\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m     \u001B[0mtrace_type\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSerializable\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 46\u001B[1;33m     metaclass=DTypeMeta):\n\u001B[0m\u001B[0;32m     47\u001B[0m   \"\"\"Represents the type of the elements in a `Tensor`.\n\u001B[0;32m     48\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\u001B[0m in \u001B[0;36mDType\u001B[1;34m()\u001B[0m\n\u001B[0;32m    200\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    201\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 202\u001B[1;33m   \u001B[1;32mdef\u001B[0m \u001B[0mexperimental_type_proto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mType\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtypes_pb2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSerializedDType\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    203\u001B[0m     \u001B[1;34m\"\"\"Returns the type of proto associated with DType serialization.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    204\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtypes_pb2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSerializedDType\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'tensorflow.core.framework.types_pb2' has no attribute 'SerializedDType'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    # Calculate the true positives, false positives, and false negatives\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    false_positives = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "\n",
    "    # Calculate the precision and recall\n",
    "    precision = true_positives / (true_positives + false_positives + K.epsilon())\n",
    "    recall = true_positives / (true_positives + false_negatives + K.epsilon())\n",
    "\n",
    "    # Calculate the F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "    return f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T19:30:21.022643Z",
     "start_time": "2024-05-23T19:30:20.610480Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_15468\\4249949116.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m space = {\n\u001B[1;32m----> 4\u001B[1;33m     \u001B[1;34m'max_len'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mhp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchoice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'max_len'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m200\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m300\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m     \u001B[1;34m'embed_dim'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mhp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchoice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'embed_dim'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m128\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m256\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[1;34m'filters'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mhp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchoice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'filters'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m128\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m256\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'hp' is not defined"
     ]
    }
   ],
   "source": [
    "# CNN Parameter Optimization\n",
    "\n",
    "space = {\n",
    "    'max_len': hp.choice('max_len', [100, 200, 300]),\n",
    "    'embed_dim': hp.choice('embed_dim', [64, 128, 256]),\n",
    "    'filters': hp.choice('filters', [64, 128, 256]),\n",
    "    'kernel_size': hp.choice('kernel_size', [3, 5, 7]),\n",
    "    'dense_units': hp.choice('dense_units', [64, 128, 256]),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.2, 0.5),\n",
    "    'batch_size': hp.choice('batch_size', [32, 64, 128]),\n",
    "    'epochs': hp.choice('epochs', [10, 15, 20]),\n",
    "}\n",
    "\n",
    "# Define the objective function to be minimized\n",
    "def objective(params):\n",
    "    # Create the model\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    embedding = Embedding(input_dim=max_words, output_dim=params['embed_dim'], input_length=params['max_len'])(inputs)\n",
    "    conv1 = Conv1D(filters=params['filters'], kernel_size=params['kernel_size'], activation='relu')(embedding)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "    conv2 = Conv1D(filters=params['filters'], kernel_size=params['kernel_size'], activation='relu')(pool1)\n",
    "    pool2 = GlobalMaxPooling1D()(conv2)\n",
    "    dense1 = Dense(params['dense_units'], activation='relu')(pool2)\n",
    "    dropout = Dropout(params['dropout_rate'])(dense1)\n",
    "    outputs = Dense(6, activation='sigmoid')(dropout)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[lambda y_true, y_pred: f1_score(y_true, y_pred, average='micro', pos_label=1)])\n",
    "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Define callbacks\n",
    "    checkpoint = ModelCheckpoint('best_model_cnn.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=2, mode='min', verbose=1)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], validation_split=0.2, callbacks=[checkpoint, early_stop])\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "    # Return the validation loss as the objective to be minimized\n",
    "    return {'loss': val_loss, 'status': STATUS_OK}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "# Perform random search\n",
    "best = fmin(objective, space, algo=tpe.rand.suggest, max_evals=3, trials=trials)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:', best)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T18:04:43.802088Z",
     "start_time": "2024-05-23T18:04:43.734067Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m797/798\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.6754 - loss: 0.1451\n",
      "Epoch 1: val_loss improved from inf to 0.05243, saving model to best_model_cnn.keras\n",
      "\u001B[1m798/798\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 34ms/step - accuracy: 0.6758 - loss: 0.1450 - val_accuracy: 0.9943 - val_loss: 0.0524\n",
      "Epoch 2/10\n",
      "\u001B[1m798/798\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9891 - loss: 0.0504\n",
      "Epoch 2: val_loss improved from 0.05243 to 0.05160, saving model to best_model_cnn.keras\n",
      "\u001B[1m798/798\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 33ms/step - accuracy: 0.9891 - loss: 0.0504 - val_accuracy: 0.9943 - val_loss: 0.0516\n",
      "Epoch 3/10\n",
      "\u001B[1m797/798\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9867 - loss: 0.0409\n",
      "Epoch 3: val_loss did not improve from 0.05160\n",
      "\u001B[1m798/798\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 32ms/step - accuracy: 0.9867 - loss: 0.0409 - val_accuracy: 0.9943 - val_loss: 0.0537\n",
      "Epoch 4/10\n",
      "\u001B[1m798/798\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9620 - loss: 0.0354\n",
      "Epoch 4: val_loss did not improve from 0.05160\n",
      "\u001B[1m798/798\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 33ms/step - accuracy: 0.9620 - loss: 0.0354 - val_accuracy: 0.9943 - val_loss: 0.0568\n",
      "Epoch 4: early stopping\n",
      "\u001B[1m998/998\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.9943 - loss: 0.0545\n",
      "Test Accuracy: 0.9941093325614929\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "inputs = Input(shape=(max_len,))\n",
    "embedding = Embedding(input_dim=max_words, output_dim=128, input_length=max_len)(inputs)\n",
    "conv1 = Conv1D(filters=128, kernel_size=3, activation='relu')(embedding)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv2 = Conv1D(filters=128, kernel_size=3, activation='relu')(pool1)\n",
    "pool2 = GlobalMaxPooling1D()(conv2)\n",
    "dense1 = Dense(128, activation='relu')(pool2)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "outputs = Dense(6, activation='sigmoid')(dropout)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint('best_model_cnn.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, mode='min', verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history_cnn = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.2, callbacks=[checkpoint, early_stop])\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "evaluation_cnn = model.evaluate(X_test, y_test)\n",
    "test_accuracy_cnn = evaluation_cnn[1]\n",
    "print(\"Test Accuracy:\", test_accuracy_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\toxic-comment-classification\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1mModel: \"functional_5\"\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">71,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">306</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m150\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_2 (\u001B[38;5;33mEmbedding\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │     \u001B[38;5;34m2,560,000\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001B[38;5;33mBidirectional\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m150\u001B[0m, \u001B[38;5;34m100\u001B[0m)       │        \u001B[38;5;34m71,600\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_2          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalMaxPooling1D\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │         \u001B[38;5;34m5,050\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m)              │           \u001B[38;5;34m306\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,636,956</span> (10.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m2,636,956\u001B[0m (10.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,636,956</span> (10.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m2,636,956\u001B[0m (10.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m200/200\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 254ms/step - accuracy: 0.4203 - loss: 0.2584\n",
      "Epoch 1: val_loss improved from inf to 0.05852, saving model to save_best_model_lstm.keras\n",
      "\u001B[1m200/200\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m57s\u001B[0m 273ms/step - accuracy: 0.4212 - loss: 0.2578 - val_accuracy: 0.9943 - val_loss: 0.0585\n",
      "Epoch 2/10\n",
      "\u001B[1m200/200\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 249ms/step - accuracy: 0.8603 - loss: 0.0590\n",
      "Epoch 2: val_loss improved from 0.05852 to 0.04991, saving model to save_best_model_lstm.keras\n",
      "\u001B[1m200/200\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m53s\u001B[0m 267ms/step - accuracy: 0.8604 - loss: 0.0590 - val_accuracy: 0.9943 - val_loss: 0.0499\n",
      "Epoch 3/10\n",
      "\u001B[1m200/200\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 249ms/step - accuracy: 0.9052 - loss: 0.0485\n",
      "Epoch 3: val_loss improved from 0.04991 to 0.04937, saving model to save_best_model_lstm.keras\n",
      "\u001B[1m200/200\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m53s\u001B[0m 267ms/step - accuracy: 0.9053 - loss: 0.0485 - val_accuracy: 0.9943 - val_loss: 0.0494\n",
      "Epoch 4/10\n",
      "\u001B[1m200/200\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 255ms/step - accuracy: 0.9364 - loss: 0.0446\n",
      "Epoch 4: val_loss did not improve from 0.04937\n",
      "\u001B[1m200/200\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m55s\u001B[0m 273ms/step - accuracy: 0.9364 - loss: 0.0446 - val_accuracy: 0.9942 - val_loss: 0.0503\n",
      "\u001B[1m998/998\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 8ms/step - accuracy: 0.9941 - loss: 0.0481\n",
      "Test Accuracy: 0.9941093325614929\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape = (max_len, ))\n",
    "layer = Embedding(input_dim=max_words, output_dim=128, input_length=max_len)(inp)\n",
    "layer = Bidirectional(LSTM(50, return_sequences = True, recurrent_dropout = 0.15))(layer)\n",
    "layer = GlobalMaxPool1D()(layer)\n",
    "layer = Dropout(0.2)(layer)\n",
    "layer = Dense(50, activation = 'relu')(layer)\n",
    "layer = Dropout(0.2)(layer)\n",
    "layer = Dense(6, activation = 'sigmoid')(layer)\n",
    "model = Model(inputs = inp, outputs = layer)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "#model.summary()\n",
    "\n",
    "file_path = 'save_best_model_lstm.keras'\n",
    "checkpoint = ModelCheckpoint(file_path, monitor = 'val_loss', verbose = 1, save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 1)\n",
    "\n",
    "history_lstm = model.fit(X_train, y_train, batch_size = 512, epochs = 10, validation_split = 0.2, callbacks = [checkpoint, early_stop])\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "evaluation_lstm = model.evaluate(X_test, y_test)\n",
    "test_accuracy_lstm = evaluation_cnn[1]\n",
    "print(\"Test Accuracy:\", test_accuracy_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20                                           \n",
      "\n",
      "  1/399 [..............................] - ETA: 45:46 - loss: 0.6953 - accuracy: 0.0039\n",
      "  2/399 [..............................] - ETA: 9:48 - loss: 0.6912 - accuracy: 0.0020 \n",
      "  3/399 [..............................] - ETA: 9:42 - loss: 0.6871 - accuracy: 0.0013\n",
      "  4/399 [..............................] - ETA: 9:35 - loss: 0.6834 - accuracy: 9.7656e-04\n",
      "  5/399 [..............................] - ETA: 9:26 - loss: 0.6791 - accuracy: 7.8125e-04\n",
      "  6/399 [..............................] - ETA: 9:19 - loss: 0.6749 - accuracy: 0.0013    \n",
      "  7/399 [..............................] - ETA: 9:16 - loss: 0.6707 - accuracy: 0.0017\n",
      "  8/399 [..............................] - ETA: 9:13 - loss: 0.6661 - accuracy: 0.0015\n",
      "  9/399 [..............................] - ETA: 9:07 - loss: 0.6609 - accuracy: 0.0013\n",
      " 10/399 [..............................] - ETA: 9:02 - loss: 0.6548 - accuracy: 0.0012\n",
      " 11/399 [..............................] - ETA: 9:03 - loss: 0.6487 - accuracy: 0.0014\n",
      " 12/399 [..............................] - ETA: 9:01 - loss: 0.6417 - accuracy: 0.0013\n",
      " 13/399 [..............................] - ETA: 9:00 - loss: 0.6348 - accuracy: 0.0015\n",
      " 14/399 [>.............................] - ETA: 8:56 - loss: 0.6271 - accuracy: 0.0017\n",
      " 15/399 [>.............................] - ETA: 8:54 - loss: 0.6186 - accuracy: 0.0018\n",
      " 16/399 [>.............................] - ETA: 8:52 - loss: 0.6112 - accuracy: 0.0017\n",
      " 17/399 [>.............................] - ETA: 8:49 - loss: 0.6032 - accuracy: 0.0016\n",
      " 18/399 [>.............................] - ETA: 8:47 - loss: 0.5944 - accuracy: 0.0015\n",
      " 19/399 [>.............................] - ETA: 8:47 - loss: 0.5862 - accuracy: 0.0014\n",
      " 20/399 [>.............................] - ETA: 8:45 - loss: 0.5795 - accuracy: 0.0014\n",
      " 21/399 [>.............................] - ETA: 8:43 - loss: 0.5716 - accuracy: 0.0013\n",
      " 22/399 [>.............................] - ETA: 8:42 - loss: 0.5637 - accuracy: 0.0014\n",
      " 23/399 [>.............................] - ETA: 8:40 - loss: 0.5552 - accuracy: 0.0014\n",
      " 24/399 [>.............................] - ETA: 8:38 - loss: 0.5466 - accuracy: 0.0015\n",
      " 25/399 [>.............................] - ETA: 8:37 - loss: 0.5378 - accuracy: 0.0016\n",
      " 26/399 [>.............................] - ETA: 8:35 - loss: 0.5296 - accuracy: 0.0017\n",
      " 27/399 [=>............................] - ETA: 8:34 - loss: 0.5214 - accuracy: 0.0016\n",
      " 28/399 [=>............................] - ETA: 8:32 - loss: 0.5138 - accuracy: 0.0017\n",
      " 29/399 [=>............................] - ETA: 8:31 - loss: 0.5066 - accuracy: 0.0018\n",
      " 30/399 [=>............................] - ETA: 8:30 - loss: 0.4992 - accuracy: 0.0017\n",
      " 31/399 [=>............................] - ETA: 8:29 - loss: 0.4923 - accuracy: 0.0016\n",
      " 32/399 [=>............................] - ETA: 8:28 - loss: 0.4859 - accuracy: 0.0016\n",
      " 33/399 [=>............................] - ETA: 8:26 - loss: 0.4795 - accuracy: 0.0015\n",
      " 34/399 [=>............................] - ETA: 8:26 - loss: 0.4725 - accuracy: 0.0015\n",
      " 35/399 [=>............................] - ETA: 8:24 - loss: 0.4656 - accuracy: 0.0020\n",
      " 36/399 [=>............................] - ETA: 8:23 - loss: 0.4593 - accuracy: 0.0020\n",
      " 37/399 [=>............................] - ETA: 8:22 - loss: 0.4523 - accuracy: 0.0025\n",
      " 38/399 [=>............................] - ETA: 8:21 - loss: 0.4463 - accuracy: 0.0032\n",
      " 39/399 [=>............................] - ETA: 8:19 - loss: 0.4402 - accuracy: 0.0044\n",
      " 40/399 [==>...........................] - ETA: 8:18 - loss: 0.4348 - accuracy: 0.0059\n",
      " 41/399 [==>...........................] - ETA: 8:16 - loss: 0.4296 - accuracy: 0.0071\n",
      " 42/399 [==>...........................] - ETA: 8:15 - loss: 0.4236 - accuracy: 0.0087\n",
      " 43/399 [==>...........................] - ETA: 8:14 - loss: 0.4176 - accuracy: 0.0114\n",
      " 44/399 [==>...........................] - ETA: 8:13 - loss: 0.4128 - accuracy: 0.0149\n",
      " 45/399 [==>...........................] - ETA: 8:12 - loss: 0.4082 - accuracy: 0.0188\n",
      " 46/399 [==>...........................] - ETA: 8:11 - loss: 0.4028 - accuracy: 0.0237\n",
      " 47/399 [==>...........................] - ETA: 8:09 - loss: 0.3989 - accuracy: 0.0289\n",
      " 48/399 [==>...........................] - ETA: 8:07 - loss: 0.3946 - accuracy: 0.0347\n",
      " 49/399 [==>...........................] - ETA: 8:06 - loss: 0.3905 - accuracy: 0.0400\n",
      " 50/399 [==>...........................] - ETA: 8:05 - loss: 0.3859 - accuracy: 0.0465\n",
      " 51/399 [==>...........................] - ETA: 8:04 - loss: 0.3821 - accuracy: 0.0535\n",
      " 52/399 [==>...........................] - ETA: 8:03 - loss: 0.3788 - accuracy: 0.0603\n",
      " 53/399 [==>...........................] - ETA: 8:02 - loss: 0.3753 - accuracy: 0.0674\n",
      " 54/399 [===>..........................] - ETA: 8:01 - loss: 0.3719 - accuracy: 0.0752\n",
      " 55/399 [===>..........................] - ETA: 7:59 - loss: 0.3692 - accuracy: 0.0828\n",
      " 56/399 [===>..........................] - ETA: 7:57 - loss: 0.3661 - accuracy: 0.0905\n",
      " 57/399 [===>..........................] - ETA: 7:55 - loss: 0.3628 - accuracy: 0.0975\n",
      " 58/399 [===>..........................] - ETA: 7:53 - loss: 0.3594 - accuracy: 0.1061\n",
      " 59/399 [===>..........................] - ETA: 7:52 - loss: 0.3567 - accuracy: 0.1135\n",
      " 60/399 [===>..........................] - ETA: 7:51 - loss: 0.3533 - accuracy: 0.1205\n",
      " 61/399 [===>..........................] - ETA: 7:50 - loss: 0.3498 - accuracy: 0.1283\n",
      " 62/399 [===>..........................] - ETA: 7:49 - loss: 0.3468 - accuracy: 0.1354\n",
      " 63/399 [===>..........................] - ETA: 7:47 - loss: 0.3444 - accuracy: 0.1412\n",
      " 64/399 [===>..........................] - ETA: 7:45 - loss: 0.3418 - accuracy: 0.1478\n",
      " 65/399 [===>..........................] - ETA: 7:44 - loss: 0.3398 - accuracy: 0.1539\n",
      " 66/399 [===>..........................] - ETA: 7:42 - loss: 0.3378 - accuracy: 0.1595\n",
      " 67/399 [====>.........................] - ETA: 7:41 - loss: 0.3352 - accuracy: 0.1639\n",
      " 68/399 [====>.........................] - ETA: 7:39 - loss: 0.3330 - accuracy: 0.1693\n",
      " 69/399 [====>.........................] - ETA: 7:37 - loss: 0.3304 - accuracy: 0.1746\n",
      " 70/399 [====>.........................] - ETA: 7:36 - loss: 0.3288 - accuracy: 0.1799\n",
      " 71/399 [====>.........................] - ETA: 7:34 - loss: 0.3273 - accuracy: 0.1844\n",
      " 72/399 [====>.........................] - ETA: 7:33 - loss: 0.3260 - accuracy: 0.1888\n",
      " 73/399 [====>.........................] - ETA: 7:31 - loss: 0.3232 - accuracy: 0.1938\n",
      " 74/399 [====>.........................] - ETA: 7:29 - loss: 0.3215 - accuracy: 0.1976\n",
      " 75/399 [====>.........................] - ETA: 7:28 - loss: 0.3195 - accuracy: 0.2020\n",
      " 76/399 [====>.........................] - ETA: 7:26 - loss: 0.3170 - accuracy: 0.2063\n",
      " 77/399 [====>.........................] - ETA: 7:25 - loss: 0.3151 - accuracy: 0.2110\n",
      " 78/399 [====>.........................] - ETA: 7:24 - loss: 0.3135 - accuracy: 0.2136\n",
      " 79/399 [====>.........................] - ETA: 7:23 - loss: 0.3119 - accuracy: 0.2175\n",
      " 80/399 [=====>........................] - ETA: 7:22 - loss: 0.3103 - accuracy: 0.2206\n",
      " 81/399 [=====>........................] - ETA: 7:20 - loss: 0.3087 - accuracy: 0.2240\n",
      " 82/399 [=====>........................] - ETA: 7:19 - loss: 0.3077 - accuracy: 0.2269\n",
      " 83/399 [=====>........................] - ETA: 7:17 - loss: 0.3060 - accuracy: 0.2306\n",
      " 84/399 [=====>........................] - ETA: 7:16 - loss: 0.3050 - accuracy: 0.2333\n",
      " 85/399 [=====>........................] - ETA: 7:14 - loss: 0.3035 - accuracy: 0.2364\n",
      " 86/399 [=====>........................] - ETA: 7:13 - loss: 0.3027 - accuracy: 0.2396\n",
      " 87/399 [=====>........................] - ETA: 7:12 - loss: 0.3012 - accuracy: 0.2430\n",
      " 88/399 [=====>........................] - ETA: 7:10 - loss: 0.3006 - accuracy: 0.2463\n",
      " 89/399 [=====>........................] - ETA: 7:09 - loss: 0.2990 - accuracy: 0.2496\n",
      " 90/399 [=====>........................] - ETA: 7:08 - loss: 0.2975 - accuracy: 0.2531\n",
      " 91/399 [=====>........................] - ETA: 7:07 - loss: 0.2963 - accuracy: 0.2564\n",
      " 92/399 [=====>........................] - ETA: 7:05 - loss: 0.2945 - accuracy: 0.2596\n",
      " 93/399 [=====>........................] - ETA: 7:04 - loss: 0.2933 - accuracy: 0.2629\n",
      " 94/399 [======>.......................] - ETA: 7:03 - loss: 0.2923 - accuracy: 0.2659\n",
      " 95/399 [======>.......................] - ETA: 7:01 - loss: 0.2912 - accuracy: 0.2691\n",
      " 96/399 [======>.......................] - ETA: 7:00 - loss: 0.2899 - accuracy: 0.2721\n",
      " 97/399 [======>.......................] - ETA: 6:58 - loss: 0.2887 - accuracy: 0.2749\n",
      " 98/399 [======>.......................] - ETA: 6:57 - loss: 0.2875 - accuracy: 0.2776\n",
      " 99/399 [======>.......................] - ETA: 6:55 - loss: 0.2859 - accuracy: 0.2802\n",
      "100/399 [======>.......................] - ETA: 6:54 - loss: 0.2843 - accuracy: 0.2824\n",
      "101/399 [======>.......................] - ETA: 6:52 - loss: 0.2831 - accuracy: 0.2843\n",
      "102/399 [======>.......................] - ETA: 6:51 - loss: 0.2818 - accuracy: 0.2857\n",
      "103/399 [======>.......................] - ETA: 6:50 - loss: 0.2806 - accuracy: 0.2866\n",
      "104/399 [======>.......................] - ETA: 6:48 - loss: 0.2793 - accuracy: 0.2878\n",
      "105/399 [======>.......................] - ETA: 6:47 - loss: 0.2781 - accuracy: 0.2884\n",
      "106/399 [======>.......................] - ETA: 6:45 - loss: 0.2765 - accuracy: 0.2893\n",
      "107/399 [=======>......................] - ETA: 6:44 - loss: 0.2756 - accuracy: 0.2903\n",
      "108/399 [=======>......................] - ETA: 6:42 - loss: 0.2749 - accuracy: 0.2911\n",
      "109/399 [=======>......................] - ETA: 6:41 - loss: 0.2742 - accuracy: 0.2919\n",
      "110/399 [=======>......................] - ETA: 6:40 - loss: 0.2735 - accuracy: 0.2922\n",
      "111/399 [=======>......................] - ETA: 6:38 - loss: 0.2725 - accuracy: 0.2937\n",
      "112/399 [=======>......................] - ETA: 6:37 - loss: 0.2714 - accuracy: 0.2947\n",
      "113/399 [=======>......................] - ETA: 6:35 - loss: 0.2706 - accuracy: 0.2964\n",
      "114/399 [=======>......................] - ETA: 6:34 - loss: 0.2696 - accuracy: 0.2977\n",
      "115/399 [=======>......................] - ETA: 6:33 - loss: 0.2689 - accuracy: 0.2995\n",
      "116/399 [=======>......................] - ETA: 6:31 - loss: 0.2679 - accuracy: 0.3016\n",
      "117/399 [=======>......................] - ETA: 6:30 - loss: 0.2674 - accuracy: 0.3031\n",
      "118/399 [=======>......................] - ETA: 6:28 - loss: 0.2664 - accuracy: 0.3047\n",
      "119/399 [=======>......................] - ETA: 6:27 - loss: 0.2657 - accuracy: 0.3060\n",
      "120/399 [========>.....................] - ETA: 6:25 - loss: 0.2647 - accuracy: 0.3076\n",
      "121/399 [========>.....................] - ETA: 6:24 - loss: 0.2639 - accuracy: 0.3097\n",
      "122/399 [========>.....................] - ETA: 6:22 - loss: 0.2630 - accuracy: 0.3114\n",
      "123/399 [========>.....................] - ETA: 6:21 - loss: 0.2621 - accuracy: 0.3139\n",
      "124/399 [========>.....................] - ETA: 6:19 - loss: 0.2610 - accuracy: 0.3159\n",
      "125/399 [========>.....................] - ETA: 6:18 - loss: 0.2607 - accuracy: 0.3176\n",
      "126/399 [========>.....................] - ETA: 6:17 - loss: 0.2604 - accuracy: 0.3196\n",
      "127/399 [========>.....................] - ETA: 6:15 - loss: 0.2597 - accuracy: 0.3210\n",
      "128/399 [========>.....................] - ETA: 6:14 - loss: 0.2592 - accuracy: 0.3227\n",
      "129/399 [========>.....................] - ETA: 6:12 - loss: 0.2586 - accuracy: 0.3242\n",
      "130/399 [========>.....................] - ETA: 6:11 - loss: 0.2578 - accuracy: 0.3255\n",
      "131/399 [========>.....................] - ETA: 6:10 - loss: 0.2570 - accuracy: 0.3269\n",
      "132/399 [========>.....................] - ETA: 6:08 - loss: 0.2562 - accuracy: 0.3284\n",
      "133/399 [=========>....................] - ETA: 6:07 - loss: 0.2555 - accuracy: 0.3300\n",
      "134/399 [=========>....................] - ETA: 6:05 - loss: 0.2547 - accuracy: 0.3312\n",
      "135/399 [=========>....................] - ETA: 6:04 - loss: 0.2538 - accuracy: 0.3329\n",
      "136/399 [=========>....................] - ETA: 6:03 - loss: 0.2531 - accuracy: 0.3344\n",
      "137/399 [=========>....................] - ETA: 6:01 - loss: 0.2525 - accuracy: 0.3359\n",
      "138/399 [=========>....................] - ETA: 6:00 - loss: 0.2518 - accuracy: 0.3373\n",
      "139/399 [=========>....................] - ETA: 5:59 - loss: 0.2509 - accuracy: 0.3386\n",
      "140/399 [=========>....................] - ETA: 5:57 - loss: 0.2500 - accuracy: 0.3396\n",
      "141/399 [=========>....................] - ETA: 5:56 - loss: 0.2493 - accuracy: 0.3410\n",
      "142/399 [=========>....................] - ETA: 5:54 - loss: 0.2487 - accuracy: 0.3419\n",
      "143/399 [=========>....................] - ETA: 5:53 - loss: 0.2480 - accuracy: 0.3427\n",
      "144/399 [=========>....................] - ETA: 5:52 - loss: 0.2470 - accuracy: 0.3440\n",
      "145/399 [=========>....................] - ETA: 5:51 - loss: 0.2464 - accuracy: 0.3449\n",
      "146/399 [=========>....................] - ETA: 5:49 - loss: 0.2455 - accuracy: 0.3454\n",
      "147/399 [==========>...................] - ETA: 5:48 - loss: 0.2450 - accuracy: 0.3468\n",
      "148/399 [==========>...................] - ETA: 5:47 - loss: 0.2444 - accuracy: 0.3478\n",
      "149/399 [==========>...................] - ETA: 5:46 - loss: 0.2436 - accuracy: 0.3491\n",
      "150/399 [==========>...................] - ETA: 5:45 - loss: 0.2430 - accuracy: 0.3503\n",
      "151/399 [==========>...................] - ETA: 5:44 - loss: 0.2425 - accuracy: 0.3514\n",
      "152/399 [==========>...................] - ETA: 5:43 - loss: 0.2417 - accuracy: 0.3527\n",
      "153/399 [==========>...................] - ETA: 5:42 - loss: 0.2408 - accuracy: 0.3539\n",
      "154/399 [==========>...................] - ETA: 5:41 - loss: 0.2399 - accuracy: 0.3547\n",
      "155/399 [==========>...................] - ETA: 5:40 - loss: 0.2392 - accuracy: 0.3550\n",
      "156/399 [==========>...................] - ETA: 5:39 - loss: 0.2384 - accuracy: 0.3552\n",
      "157/399 [==========>...................] - ETA: 5:37 - loss: 0.2375 - accuracy: 0.3559\n",
      "158/399 [==========>...................] - ETA: 5:37 - loss: 0.2366 - accuracy: 0.3565\n",
      "159/399 [==========>...................] - ETA: 5:36 - loss: 0.2359 - accuracy: 0.3570\n",
      "160/399 [===========>..................] - ETA: 5:34 - loss: 0.2353 - accuracy: 0.3576\n",
      "161/399 [===========>..................] - ETA: 5:33 - loss: 0.2347 - accuracy: 0.3582\n",
      "162/399 [===========>..................] - ETA: 5:31 - loss: 0.2339 - accuracy: 0.3593\n",
      "163/399 [===========>..................] - ETA: 5:30 - loss: 0.2331 - accuracy: 0.3603\n",
      "164/399 [===========>..................] - ETA: 5:29 - loss: 0.2324 - accuracy: 0.3616\n",
      "165/399 [===========>..................] - ETA: 5:28 - loss: 0.2318 - accuracy: 0.3626\n",
      "166/399 [===========>..................] - ETA: 5:27 - loss: 0.2310 - accuracy: 0.3638\n",
      "167/399 [===========>..................] - ETA: 5:26 - loss: 0.2303 - accuracy: 0.3645\n",
      "168/399 [===========>..................] - ETA: 5:24 - loss: 0.2298 - accuracy: 0.3650\n",
      "169/399 [===========>..................] - ETA: 5:23 - loss: 0.2291 - accuracy: 0.3651\n",
      "170/399 [===========>..................] - ETA: 5:21 - loss: 0.2283 - accuracy: 0.3654\n",
      "171/399 [===========>..................] - ETA: 5:20 - loss: 0.2277 - accuracy: 0.3652\n",
      "172/399 [===========>..................] - ETA: 5:19 - loss: 0.2270 - accuracy: 0.3654\n",
      "173/399 [============>.................] - ETA: 5:17 - loss: 0.2263 - accuracy: 0.3658\n",
      "174/399 [============>.................] - ETA: 5:16 - loss: 0.2257 - accuracy: 0.3662\n",
      "175/399 [============>.................] - ETA: 5:15 - loss: 0.2252 - accuracy: 0.3668\n",
      "176/399 [============>.................] - ETA: 5:13 - loss: 0.2246 - accuracy: 0.3675\n",
      "177/399 [============>.................] - ETA: 5:12 - loss: 0.2239 - accuracy: 0.3681\n",
      "178/399 [============>.................] - ETA: 5:10 - loss: 0.2233 - accuracy: 0.3688\n",
      "179/399 [============>.................] - ETA: 5:09 - loss: 0.2227 - accuracy: 0.3693\n",
      "180/399 [============>.................] - ETA: 5:08 - loss: 0.2219 - accuracy: 0.3702\n",
      "181/399 [============>.................] - ETA: 5:06 - loss: 0.2212 - accuracy: 0.3713\n",
      "182/399 [============>.................] - ETA: 5:05 - loss: 0.2204 - accuracy: 0.3720\n",
      "183/399 [============>.................] - ETA: 5:04 - loss: 0.2197 - accuracy: 0.3726\n",
      "184/399 [============>.................] - ETA: 5:02 - loss: 0.2192 - accuracy: 0.3737\n",
      "185/399 [============>.................] - ETA: 5:01 - loss: 0.2188 - accuracy: 0.3745\n",
      "186/399 [============>.................] - ETA: 4:59 - loss: 0.2182 - accuracy: 0.3755\n",
      "187/399 [=============>................] - ETA: 4:58 - loss: 0.2175 - accuracy: 0.3763\n",
      "188/399 [=============>................] - ETA: 4:57 - loss: 0.2170 - accuracy: 0.3770\n",
      "189/399 [=============>................] - ETA: 4:56 - loss: 0.2165 - accuracy: 0.3781\n",
      "190/399 [=============>................] - ETA: 4:54 - loss: 0.2160 - accuracy: 0.3790\n",
      "191/399 [=============>................] - ETA: 4:53 - loss: 0.2152 - accuracy: 0.3799\n",
      "192/399 [=============>................] - ETA: 4:52 - loss: 0.2146 - accuracy: 0.3809\n",
      "193/399 [=============>................] - ETA: 4:51 - loss: 0.2139 - accuracy: 0.3821\n",
      "194/399 [=============>................] - ETA: 4:49 - loss: 0.2133 - accuracy: 0.3831\n",
      "195/399 [=============>................] - ETA: 4:48 - loss: 0.2126 - accuracy: 0.3844\n",
      "196/399 [=============>................] - ETA: 4:46 - loss: 0.2121 - accuracy: 0.3853\n",
      "197/399 [=============>................] - ETA: 4:45 - loss: 0.2114 - accuracy: 0.3861\n",
      "198/399 [=============>................] - ETA: 4:43 - loss: 0.2108 - accuracy: 0.3871\n",
      "199/399 [=============>................] - ETA: 4:42 - loss: 0.2103 - accuracy: 0.3879\n",
      "200/399 [==============>...............] - ETA: 4:40 - loss: 0.2096 - accuracy: 0.3887\n",
      "201/399 [==============>...............] - ETA: 4:39 - loss: 0.2089 - accuracy: 0.3898\n",
      "202/399 [==============>...............] - ETA: 4:37 - loss: 0.2083 - accuracy: 0.3910\n",
      "203/399 [==============>...............] - ETA: 4:36 - loss: 0.2079 - accuracy: 0.3921\n",
      "204/399 [==============>...............] - ETA: 4:35 - loss: 0.2074 - accuracy: 0.3932\n",
      "205/399 [==============>...............] - ETA: 4:33 - loss: 0.2070 - accuracy: 0.3942\n",
      "206/399 [==============>...............] - ETA: 4:32 - loss: 0.2065 - accuracy: 0.3955\n",
      "207/399 [==============>...............] - ETA: 4:30 - loss: 0.2060 - accuracy: 0.3968\n",
      "208/399 [==============>...............] - ETA: 4:29 - loss: 0.2055 - accuracy: 0.3983\n",
      "209/399 [==============>...............] - ETA: 4:27 - loss: 0.2051 - accuracy: 0.3995\n",
      "210/399 [==============>...............] - ETA: 4:26 - loss: 0.2047 - accuracy: 0.4010\n",
      "211/399 [==============>...............] - ETA: 4:25 - loss: 0.2043 - accuracy: 0.4023\n",
      "212/399 [==============>...............] - ETA: 4:24 - loss: 0.2036 - accuracy: 0.4036\n",
      "213/399 [===============>..............] - ETA: 4:22 - loss: 0.2030 - accuracy: 0.4047\n",
      "214/399 [===============>..............] - ETA: 4:21 - loss: 0.2025 - accuracy: 0.4056\n",
      "215/399 [===============>..............] - ETA: 4:19 - loss: 0.2020 - accuracy: 0.4063\n",
      "216/399 [===============>..............] - ETA: 4:18 - loss: 0.2016 - accuracy: 0.4074\n",
      "217/399 [===============>..............] - ETA: 4:16 - loss: 0.2011 - accuracy: 0.4082\n",
      "218/399 [===============>..............] - ETA: 4:15 - loss: 0.2007 - accuracy: 0.4089\n",
      "219/399 [===============>..............] - ETA: 4:13 - loss: 0.2002 - accuracy: 0.4095\n",
      "220/399 [===============>..............] - ETA: 4:12 - loss: 0.1998 - accuracy: 0.4101\n",
      "221/399 [===============>..............] - ETA: 4:10 - loss: 0.1994 - accuracy: 0.4105\n",
      "222/399 [===============>..............] - ETA: 4:09 - loss: 0.1989 - accuracy: 0.4111\n",
      "223/399 [===============>..............] - ETA: 4:08 - loss: 0.1983 - accuracy: 0.4120\n",
      "224/399 [===============>..............] - ETA: 4:06 - loss: 0.1979 - accuracy: 0.4126\n",
      "225/399 [===============>..............] - ETA: 4:05 - loss: 0.1974 - accuracy: 0.4130\n",
      "226/399 [===============>..............] - ETA: 4:03 - loss: 0.1970 - accuracy: 0.4135\n",
      "227/399 [================>.............] - ETA: 4:02 - loss: 0.1965 - accuracy: 0.4139\n",
      "228/399 [================>.............] - ETA: 4:00 - loss: 0.1960 - accuracy: 0.4145\n",
      "229/399 [================>.............] - ETA: 3:59 - loss: 0.1956 - accuracy: 0.4147\n",
      "230/399 [================>.............] - ETA: 3:58 - loss: 0.1952 - accuracy: 0.4153\n",
      "231/399 [================>.............] - ETA: 3:56 - loss: 0.1949 - accuracy: 0.4157\n",
      "232/399 [================>.............] - ETA: 3:55 - loss: 0.1944 - accuracy: 0.4162\n",
      "233/399 [================>.............] - ETA: 3:53 - loss: 0.1940 - accuracy: 0.4167\n",
      "234/399 [================>.............] - ETA: 3:52 - loss: 0.1936 - accuracy: 0.4171\n",
      "235/399 [================>.............] - ETA: 3:50 - loss: 0.1931 - accuracy: 0.4176\n",
      "236/399 [================>.............] - ETA: 3:49 - loss: 0.1927 - accuracy: 0.4180\n",
      "237/399 [================>.............] - ETA: 3:48 - loss: 0.1924 - accuracy: 0.4185\n",
      "238/399 [================>.............] - ETA: 3:46 - loss: 0.1920 - accuracy: 0.4188\n",
      "239/399 [================>.............] - ETA: 3:45 - loss: 0.1915 - accuracy: 0.4193\n",
      "240/399 [=================>............] - ETA: 3:43 - loss: 0.1910 - accuracy: 0.4198\n",
      "241/399 [=================>............] - ETA: 3:42 - loss: 0.1905 - accuracy: 0.4204\n",
      "242/399 [=================>............] - ETA: 3:40 - loss: 0.1900 - accuracy: 0.4211\n",
      "243/399 [=================>............] - ETA: 3:39 - loss: 0.1897 - accuracy: 0.4215\n",
      "244/399 [=================>............] - ETA: 3:38 - loss: 0.1894 - accuracy: 0.4222\n",
      "245/399 [=================>............] - ETA: 3:36 - loss: 0.1890 - accuracy: 0.4228\n",
      "246/399 [=================>............] - ETA: 3:35 - loss: 0.1886 - accuracy: 0.4235\n",
      "247/399 [=================>............] - ETA: 3:33 - loss: 0.1882 - accuracy: 0.4243\n",
      "248/399 [=================>............] - ETA: 3:32 - loss: 0.1879 - accuracy: 0.4251\n",
      "249/399 [=================>............] - ETA: 3:31 - loss: 0.1876 - accuracy: 0.4260\n",
      "250/399 [=================>............] - ETA: 3:29 - loss: 0.1872 - accuracy: 0.4270\n",
      "251/399 [=================>............] - ETA: 3:28 - loss: 0.1868 - accuracy: 0.4280\n",
      "252/399 [=================>............] - ETA: 3:26 - loss: 0.1864 - accuracy: 0.4292\n",
      "253/399 [==================>...........] - ETA: 3:25 - loss: 0.1860 - accuracy: 0.4301\n",
      "254/399 [==================>...........] - ETA: 3:23 - loss: 0.1856 - accuracy: 0.4313\n",
      "255/399 [==================>...........] - ETA: 3:22 - loss: 0.1851 - accuracy: 0.4325\n",
      "256/399 [==================>...........] - ETA: 3:20 - loss: 0.1847 - accuracy: 0.4339\n",
      "257/399 [==================>...........] - ETA: 3:19 - loss: 0.1843 - accuracy: 0.4351\n",
      "258/399 [==================>...........] - ETA: 3:18 - loss: 0.1840 - accuracy: 0.4364\n",
      "259/399 [==================>...........] - ETA: 3:16 - loss: 0.1836 - accuracy: 0.4376\n",
      "260/399 [==================>...........] - ETA: 3:15 - loss: 0.1832 - accuracy: 0.4388\n",
      "261/399 [==================>...........] - ETA: 3:13 - loss: 0.1829 - accuracy: 0.4401\n",
      "262/399 [==================>...........] - ETA: 3:12 - loss: 0.1825 - accuracy: 0.4414\n",
      "263/399 [==================>...........] - ETA: 3:11 - loss: 0.1821 - accuracy: 0.4426\n",
      "264/399 [==================>...........] - ETA: 3:09 - loss: 0.1817 - accuracy: 0.4438\n",
      "265/399 [==================>...........] - ETA: 3:08 - loss: 0.1814 - accuracy: 0.4448\n",
      "266/399 [===================>..........] - ETA: 3:06 - loss: 0.1810 - accuracy: 0.4458\n",
      "267/399 [===================>..........] - ETA: 3:05 - loss: 0.1806 - accuracy: 0.4467\n",
      "268/399 [===================>..........] - ETA: 3:03 - loss: 0.1802 - accuracy: 0.4477\n",
      "269/399 [===================>..........] - ETA: 3:02 - loss: 0.1799 - accuracy: 0.4488\n",
      "270/399 [===================>..........] - ETA: 3:01 - loss: 0.1796 - accuracy: 0.4496\n",
      "271/399 [===================>..........] - ETA: 2:59 - loss: 0.1792 - accuracy: 0.4503\n",
      "272/399 [===================>..........] - ETA: 2:58 - loss: 0.1788 - accuracy: 0.4512\n",
      "273/399 [===================>..........] - ETA: 2:56 - loss: 0.1784 - accuracy: 0.4522\n",
      "274/399 [===================>..........] - ETA: 2:55 - loss: 0.1781 - accuracy: 0.4527\n",
      "275/399 [===================>..........] - ETA: 2:54 - loss: 0.1777 - accuracy: 0.4535\n",
      "276/399 [===================>..........] - ETA: 2:52 - loss: 0.1774 - accuracy: 0.4541\n",
      "277/399 [===================>..........] - ETA: 2:51 - loss: 0.1770 - accuracy: 0.4550\n",
      "278/399 [===================>..........] - ETA: 2:49 - loss: 0.1767 - accuracy: 0.4558\n",
      "279/399 [===================>..........] - ETA: 2:48 - loss: 0.1763 - accuracy: 0.4565\n",
      "280/399 [====================>.........] - ETA: 2:47 - loss: 0.1760 - accuracy: 0.4572\n",
      "281/399 [====================>.........] - ETA: 2:45 - loss: 0.1755 - accuracy: 0.4578\n",
      "282/399 [====================>.........] - ETA: 2:44 - loss: 0.1752 - accuracy: 0.4585\n",
      "283/399 [====================>.........] - ETA: 2:42 - loss: 0.1748 - accuracy: 0.4592\n",
      "284/399 [====================>.........] - ETA: 2:41 - loss: 0.1745 - accuracy: 0.4598\n",
      "285/399 [====================>.........] - ETA: 2:40 - loss: 0.1741 - accuracy: 0.4606\n",
      "286/399 [====================>.........] - ETA: 2:38 - loss: 0.1737 - accuracy: 0.4612\n",
      "287/399 [====================>.........] - ETA: 2:37 - loss: 0.1733 - accuracy: 0.4620\n",
      "288/399 [====================>.........] - ETA: 2:36 - loss: 0.1730 - accuracy: 0.4628\n",
      "289/399 [====================>.........] - ETA: 2:35 - loss: 0.1726 - accuracy: 0.4635\n",
      "290/399 [====================>.........] - ETA: 2:33 - loss: 0.1723 - accuracy: 0.4642\n",
      "291/399 [====================>.........] - ETA: 2:32 - loss: 0.1720 - accuracy: 0.4649\n",
      "292/399 [====================>.........] - ETA: 2:30 - loss: 0.1716 - accuracy: 0.4657\n",
      "293/399 [=====================>........] - ETA: 2:29 - loss: 0.1713 - accuracy: 0.4665\n",
      "294/399 [=====================>........] - ETA: 2:28 - loss: 0.1710 - accuracy: 0.4673\n",
      "295/399 [=====================>........] - ETA: 2:26 - loss: 0.1707 - accuracy: 0.4678\n",
      "296/399 [=====================>........] - ETA: 2:25 - loss: 0.1703 - accuracy: 0.4685\n",
      "297/399 [=====================>........] - ETA: 2:24 - loss: 0.1700 - accuracy: 0.4692\n",
      "298/399 [=====================>........] - ETA: 2:22 - loss: 0.1696 - accuracy: 0.4701\n",
      "299/399 [=====================>........] - ETA: 2:21 - loss: 0.1694 - accuracy: 0.4709\n",
      "300/399 [=====================>........] - ETA: 2:19 - loss: 0.1691 - accuracy: 0.4714\n",
      "301/399 [=====================>........] - ETA: 2:18 - loss: 0.1687 - accuracy: 0.4719\n",
      "302/399 [=====================>........] - ETA: 2:17 - loss: 0.1683 - accuracy: 0.4726\n",
      "303/399 [=====================>........] - ETA: 2:15 - loss: 0.1680 - accuracy: 0.4731\n",
      "304/399 [=====================>........] - ETA: 2:14 - loss: 0.1677 - accuracy: 0.4738\n",
      "305/399 [=====================>........] - ETA: 2:12 - loss: 0.1674 - accuracy: 0.4745\n",
      "306/399 [======================>.......] - ETA: 2:11 - loss: 0.1671 - accuracy: 0.4753\n",
      "307/399 [======================>.......] - ETA: 2:10 - loss: 0.1667 - accuracy: 0.4761\n",
      "308/399 [======================>.......] - ETA: 2:08 - loss: 0.1664 - accuracy: 0.4767\n",
      "309/399 [======================>.......] - ETA: 2:07 - loss: 0.1661 - accuracy: 0.4774\n",
      "310/399 [======================>.......] - ETA: 2:05 - loss: 0.1657 - accuracy: 0.4781\n",
      "311/399 [======================>.......] - ETA: 2:04 - loss: 0.1655 - accuracy: 0.4788\n",
      "312/399 [======================>.......] - ETA: 2:03 - loss: 0.1652 - accuracy: 0.4795\n",
      "313/399 [======================>.......] - ETA: 2:01 - loss: 0.1649 - accuracy: 0.4803\n",
      "314/399 [======================>.......] - ETA: 2:00 - loss: 0.1646 - accuracy: 0.4811\n",
      "315/399 [======================>.......] - ETA: 1:58 - loss: 0.1644 - accuracy: 0.4822\n",
      "316/399 [======================>.......] - ETA: 1:57 - loss: 0.1642 - accuracy: 0.4832\n",
      "317/399 [======================>.......] - ETA: 1:56 - loss: 0.1639 - accuracy: 0.4840\n",
      "318/399 [======================>.......] - ETA: 1:54 - loss: 0.1637 - accuracy: 0.4850\n",
      "319/399 [======================>.......] - ETA: 1:53 - loss: 0.1635 - accuracy: 0.4857\n",
      "320/399 [=======================>......] - ETA: 1:51 - loss: 0.1632 - accuracy: 0.4864\n",
      "321/399 [=======================>......] - ETA: 1:50 - loss: 0.1629 - accuracy: 0.4870\n",
      "322/399 [=======================>......] - ETA: 1:48 - loss: 0.1627 - accuracy: 0.4875\n",
      "323/399 [=======================>......] - ETA: 1:47 - loss: 0.1624 - accuracy: 0.4879\n",
      "324/399 [=======================>......] - ETA: 1:45 - loss: 0.1622 - accuracy: 0.4885\n",
      "325/399 [=======================>......] - ETA: 1:44 - loss: 0.1620 - accuracy: 0.4890\n",
      "326/399 [=======================>......] - ETA: 1:43 - loss: 0.1618 - accuracy: 0.4895\n",
      "327/399 [=======================>......] - ETA: 1:41 - loss: 0.1615 - accuracy: 0.4900\n",
      "328/399 [=======================>......] - ETA: 1:40 - loss: 0.1614 - accuracy: 0.4905\n",
      "329/399 [=======================>......] - ETA: 1:38 - loss: 0.1611 - accuracy: 0.4911\n",
      "330/399 [=======================>......] - ETA: 1:37 - loss: 0.1608 - accuracy: 0.4915\n",
      "331/399 [=======================>......] - ETA: 1:35 - loss: 0.1606 - accuracy: 0.4921\n",
      "332/399 [=======================>......] - ETA: 1:34 - loss: 0.1603 - accuracy: 0.4925\n",
      "333/399 [========================>.....] - ETA: 1:33 - loss: 0.1601 - accuracy: 0.4931\n",
      "334/399 [========================>.....] - ETA: 1:31 - loss: 0.1598 - accuracy: 0.4936\n",
      "335/399 [========================>.....] - ETA: 1:30 - loss: 0.1596 - accuracy: 0.4942\n",
      "336/399 [========================>.....] - ETA: 1:28 - loss: 0.1592 - accuracy: 0.4948\n",
      "337/399 [========================>.....] - ETA: 1:27 - loss: 0.1590 - accuracy: 0.4955\n",
      "338/399 [========================>.....] - ETA: 1:26 - loss: 0.1588 - accuracy: 0.4961\n",
      "339/399 [========================>.....] - ETA: 1:24 - loss: 0.1585 - accuracy: 0.4968\n",
      "340/399 [========================>.....] - ETA: 1:23 - loss: 0.1582 - accuracy: 0.4974\n",
      "341/399 [========================>.....] - ETA: 1:21 - loss: 0.1579 - accuracy: 0.4981\n",
      "342/399 [========================>.....] - ETA: 1:20 - loss: 0.1577 - accuracy: 0.4987\n",
      "343/399 [========================>.....] - ETA: 1:18 - loss: 0.1574 - accuracy: 0.4992\n",
      "344/399 [========================>.....] - ETA: 1:17 - loss: 0.1572 - accuracy: 0.4998\n",
      "345/399 [========================>.....] - ETA: 1:16 - loss: 0.1569 - accuracy: 0.5003\n",
      "346/399 [=========================>....] - ETA: 1:14 - loss: 0.1567 - accuracy: 0.5008\n",
      "347/399 [=========================>....] - ETA: 1:13 - loss: 0.1564 - accuracy: 0.5012\n",
      "348/399 [=========================>....] - ETA: 1:11 - loss: 0.1561 - accuracy: 0.5017\n",
      "349/399 [=========================>....] - ETA: 1:10 - loss: 0.1558 - accuracy: 0.5022\n",
      "350/399 [=========================>....] - ETA: 1:08 - loss: 0.1555 - accuracy: 0.5027\n",
      "351/399 [=========================>....] - ETA: 1:07 - loss: 0.1552 - accuracy: 0.5032\n",
      "352/399 [=========================>....] - ETA: 1:06 - loss: 0.1549 - accuracy: 0.5036\n",
      "353/399 [=========================>....] - ETA: 1:04 - loss: 0.1546 - accuracy: 0.5042\n",
      "354/399 [=========================>....] - ETA: 1:03 - loss: 0.1543 - accuracy: 0.5047\n",
      "355/399 [=========================>....] - ETA: 1:01 - loss: 0.1541 - accuracy: 0.5051\n",
      "356/399 [=========================>....] - ETA: 1:00 - loss: 0.1538 - accuracy: 0.5057\n",
      "357/399 [=========================>....] - ETA: 59s - loss: 0.1537 - accuracy: 0.5061 \n",
      "358/399 [=========================>....] - ETA: 57s - loss: 0.1534 - accuracy: 0.5068\n",
      "359/399 [=========================>....] - ETA: 56s - loss: 0.1532 - accuracy: 0.5075\n",
      "360/399 [==========================>...] - ETA: 54s - loss: 0.1529 - accuracy: 0.5081\n",
      "361/399 [==========================>...] - ETA: 53s - loss: 0.1527 - accuracy: 0.5088\n",
      "362/399 [==========================>...] - ETA: 52s - loss: 0.1525 - accuracy: 0.5097\n",
      "363/399 [==========================>...] - ETA: 50s - loss: 0.1522 - accuracy: 0.5105\n",
      "364/399 [==========================>...] - ETA: 49s - loss: 0.1520 - accuracy: 0.5113\n",
      "365/399 [==========================>...] - ETA: 47s - loss: 0.1518 - accuracy: 0.5122\n",
      "366/399 [==========================>...] - ETA: 46s - loss: 0.1516 - accuracy: 0.5130\n",
      "367/399 [==========================>...] - ETA: 44s - loss: 0.1513 - accuracy: 0.5138\n",
      "368/399 [==========================>...] - ETA: 43s - loss: 0.1511 - accuracy: 0.5147\n",
      "369/399 [==========================>...] - ETA: 42s - loss: 0.1509 - accuracy: 0.5154\n",
      "370/399 [==========================>...] - ETA: 40s - loss: 0.1506 - accuracy: 0.5161\n",
      "371/399 [==========================>...] - ETA: 39s - loss: 0.1504 - accuracy: 0.5168\n",
      "372/399 [==========================>...] - ETA: 37s - loss: 0.1502 - accuracy: 0.5175\n",
      "373/399 [===========================>..] - ETA: 36s - loss: 0.1499 - accuracy: 0.5181\n",
      "374/399 [===========================>..] - ETA: 35s - loss: 0.1497 - accuracy: 0.5186\n",
      "375/399 [===========================>..] - ETA: 33s - loss: 0.1494 - accuracy: 0.5193\n",
      "376/399 [===========================>..] - ETA: 32s - loss: 0.1492 - accuracy: 0.5200\n",
      "377/399 [===========================>..] - ETA: 30s - loss: 0.1490 - accuracy: 0.5206\n",
      "378/399 [===========================>..] - ETA: 29s - loss: 0.1488 - accuracy: 0.5212\n",
      "379/399 [===========================>..] - ETA: 28s - loss: 0.1486 - accuracy: 0.5218\n",
      "380/399 [===========================>..] - ETA: 26s - loss: 0.1484 - accuracy: 0.5224\n",
      "381/399 [===========================>..] - ETA: 25s - loss: 0.1482 - accuracy: 0.5230\n",
      "382/399 [===========================>..] - ETA: 23s - loss: 0.1481 - accuracy: 0.5236\n",
      "383/399 [===========================>..] - ETA: 22s - loss: 0.1478 - accuracy: 0.5244\n",
      "384/399 [===========================>..] - ETA: 21s - loss: 0.1476 - accuracy: 0.5251\n",
      "385/399 [===========================>..] - ETA: 19s - loss: 0.1474 - accuracy: 0.5256\n",
      "  0%|          | 0/3 [09:07<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1568\\840628203.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[1;31m# Perform random search\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 45\u001B[1;33m \u001B[0mbest\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfmin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobjective\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mspace\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malgo\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtpe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrand\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msuggest\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_evals\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrials\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrials\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     46\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[1;31m# Print the best hyperparameters\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\hyperopt\\fmin.py\u001B[0m in \u001B[0;36mfmin\u001B[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[0;32m    553\u001B[0m             \u001B[0mshow_progressbar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshow_progressbar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    554\u001B[0m             \u001B[0mearly_stop_fn\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mearly_stop_fn\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 555\u001B[1;33m             \u001B[0mtrials_save_file\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrials_save_file\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    556\u001B[0m         )\n\u001B[0;32m    557\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\hyperopt\\base.py\u001B[0m in \u001B[0;36mfmin\u001B[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[0;32m    686\u001B[0m             \u001B[0mshow_progressbar\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshow_progressbar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    687\u001B[0m             \u001B[0mearly_stop_fn\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mearly_stop_fn\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 688\u001B[1;33m             \u001B[0mtrials_save_file\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrials_save_file\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    689\u001B[0m         )\n\u001B[0;32m    690\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\hyperopt\\fmin.py\u001B[0m in \u001B[0;36mfmin\u001B[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[0;32m    584\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m     \u001B[1;31m# next line is where the fmin is actually executed\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[0mrval\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexhaust\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mreturn_argmin\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\hyperopt\\fmin.py\u001B[0m in \u001B[0;36mexhaust\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    362\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mexhaust\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    363\u001B[0m         \u001B[0mn_done\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 364\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_evals\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mn_done\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mblock_until_done\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masynchronous\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    365\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrefresh\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    366\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\hyperopt\\fmin.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self, N, block_until_done)\u001B[0m\n\u001B[0;32m    298\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    299\u001B[0m                     \u001B[1;31m# -- loop over trials and do the jobs directly\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 300\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mserial_evaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    301\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    302\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrefresh\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\hyperopt\\fmin.py\u001B[0m in \u001B[0;36mserial_evaluate\u001B[1;34m(self, N)\u001B[0m\n\u001B[0;32m    176\u001B[0m                 \u001B[0mctrl\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbase\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCtrl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcurrent_trial\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    177\u001B[0m                 \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 178\u001B[1;33m                     \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdomain\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mctrl\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    179\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    180\u001B[0m                     \u001B[0mlogger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"job exception: %s\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\hyperopt\\base.py\u001B[0m in \u001B[0;36mevaluate\u001B[1;34m(self, config, ctrl, attach_attachments)\u001B[0m\n\u001B[0;32m    890\u001B[0m                 \u001B[0mprint_node_on_error\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrec_eval_print_node_on_error\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    891\u001B[0m             )\n\u001B[1;32m--> 892\u001B[1;33m             \u001B[0mrval\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpyll_rval\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    893\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    894\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrval\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumber\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1568\\840628203.py\u001B[0m in \u001B[0;36mobjective\u001B[1;34m(params)\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[0mearly_stop\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mEarlyStopping\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmonitor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'val_loss'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpatience\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 35\u001B[1;33m     \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'batch_size'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'epochs'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_split\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcheckpoint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mearly_stop\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[0mval_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 65\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     66\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1648\u001B[0m                         ):\n\u001B[0;32m   1649\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1650\u001B[1;33m                             \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1651\u001B[0m                             \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1652\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    878\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    879\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 880\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    881\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    882\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    910\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    911\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 912\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_no_variable_creation_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    913\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_variable_creation_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    133\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m    134\u001B[0m     return concrete_function._call_flat(\n\u001B[1;32m--> 135\u001B[1;33m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m    136\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    137\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1744\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1745\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[1;32m-> 1746\u001B[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[0;32m   1747\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[0;32m   1748\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    381\u001B[0m               \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    382\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 383\u001B[1;33m               ctx=ctx)\n\u001B[0m\u001B[0;32m    384\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    385\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[1;32m~\\PycharmProjects\\ProjektNW\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[1;32m---> 53\u001B[1;33m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[0;32m     54\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# LSTM Parameter Optimization\n",
    "\n",
    "space = {\n",
    "    'max_len': hp.choice('max_len', [100, 200, 300]),\n",
    "    'embed_dim': hp.choice('embed_dim', [64, 128, 256]),\n",
    "    'lstm_units': hp.choice('lstm_units', [32, 64, 128]),\n",
    "    'recurrent_dropout': hp.uniform('recurrent_dropout', 0.1, 0.3),\n",
    "    'dense_units': hp.choice('dense_units', [32, 64, 128]),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.4),\n",
    "    'batch_size': hp.choice('batch_size', [64, 128, 256]),\n",
    "    'epochs': hp.choice('epochs', [10, 15, 20]),\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    layer = Embedding(input_dim=max_words, output_dim=params['embed_dim'], input_length=params['max_len'])(inputs)\n",
    "    layer = Bidirectional(LSTM(params['lstm_units'], return_sequences=True, recurrent_dropout=params['recurrent_dropout']))(layer)\n",
    "    layer = GlobalMaxPool1D()(layer)\n",
    "    layer = Dropout(params['dropout_rate'])(layer)\n",
    "    layer = Dense(params['dense_units'], activation='relu')(layer)\n",
    "    layer = Dropout(params['dropout_rate'])(layer)\n",
    "    layer = Dense(6, activation='sigmoid')(layer)\n",
    "    model = Model(inputs=inputs, outputs=layer)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    file_path = 'save_best_model_lstm.keras'\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=1)\n",
    "\n",
    "    history = model.fit(X_train, y_train, batch_size=params['batch_size'], epochs=params['epochs'], validation_split=0.2, callbacks=[checkpoint, early_stop])\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_train, y_test)\n",
    "\n",
    "    return {'loss': val_loss, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(objective, space, algo=tpe.rand.suggest, max_evals=3, trials=trials)\n",
    "\n",
    "print('Best hyperparameters:', best)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T11:29:35.370106Z",
     "start_time": "2024-05-23T11:20:27.368117Z"
    }
   },
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
